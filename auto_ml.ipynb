{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [PRICE]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "\n",
    "test_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\proso\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\data_adapter.py:1699: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 3s 11ms/step - loss: 244434.5312 - val_loss: 268250.6875\n",
      "Epoch 2/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 244432.1719 - val_loss: 268246.1250\n",
      "Epoch 3/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 244422.8125 - val_loss: 268228.9688\n",
      "Epoch 4/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 244392.2188 - val_loss: 268178.4062\n",
      "Epoch 5/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 244310.3281 - val_loss: 268056.7812\n",
      "Epoch 6/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 244130.9688 - val_loss: 267805.5625\n",
      "Epoch 7/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 243780.2344 - val_loss: 267342.3750\n",
      "Epoch 8/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 243161.8594 - val_loss: 266566.2500\n",
      "Epoch 9/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 242165.4688 - val_loss: 265334.0000\n",
      "Epoch 10/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 240648.9375 - val_loss: 263503.8125\n",
      "Epoch 11/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 238453.9531 - val_loss: 260909.0469\n",
      "Epoch 12/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 235555.4844 - val_loss: 257543.1875\n",
      "Epoch 13/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 232075.3438 - val_loss: 253598.8594\n",
      "Epoch 14/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 227974.5000 - val_loss: 248915.6250\n",
      "Epoch 15/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 223063.0156 - val_loss: 243509.0469\n",
      "Epoch 16/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 217839.6094 - val_loss: 237579.0625\n",
      "Epoch 17/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 212001.5625 - val_loss: 231015.4219\n",
      "Epoch 18/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 205202.3594 - val_loss: 223377.8906\n",
      "Epoch 19/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 197248.3125 - val_loss: 214740.2188\n",
      "Epoch 20/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 188603.3750 - val_loss: 204637.1406\n",
      "Epoch 21/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 178749.4844 - val_loss: 193167.8125\n",
      "Epoch 22/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 167771.1562 - val_loss: 181240.7656\n",
      "Epoch 23/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 156003.7188 - val_loss: 169543.9688\n",
      "Epoch 24/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 145149.5938 - val_loss: 157608.7500\n",
      "Epoch 25/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 133347.3125 - val_loss: 145089.6094\n",
      "Epoch 26/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 121514.6719 - val_loss: 132972.4375\n",
      "Epoch 27/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 111150.2578 - val_loss: 122289.8359\n",
      "Epoch 28/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 101965.1484 - val_loss: 114753.5938\n",
      "Epoch 29/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 96474.9766 - val_loss: 109194.5312\n",
      "Epoch 30/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 90329.6328 - val_loss: 104601.9766\n",
      "Epoch 31/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 87253.6016 - val_loss: 101363.1250\n",
      "Epoch 32/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 84479.1484 - val_loss: 99087.8516\n",
      "Epoch 33/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 81837.6641 - val_loss: 97514.1641\n",
      "Epoch 34/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 80235.3672 - val_loss: 96261.1328\n",
      "Epoch 35/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 78567.8438 - val_loss: 95437.0469\n",
      "Epoch 36/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 79134.6797 - val_loss: 94387.8906\n",
      "Epoch 37/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 76709.7812 - val_loss: 93597.0078\n",
      "Epoch 38/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 77052.0703 - val_loss: 93267.6094\n",
      "Epoch 39/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 75146.5469 - val_loss: 92864.1094\n",
      "Epoch 40/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 75441.5156 - val_loss: 92251.9922\n",
      "Epoch 41/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 74999.2812 - val_loss: 91881.4297\n",
      "Epoch 42/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 73715.9609 - val_loss: 91169.1953\n",
      "Epoch 43/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 73699.8359 - val_loss: 90704.2578\n",
      "Epoch 44/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 74156.0781 - val_loss: 90292.6016\n",
      "Epoch 45/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 74028.3281 - val_loss: 90054.9219\n",
      "Epoch 46/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 73449.4375 - val_loss: 89859.0469\n",
      "Epoch 47/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 73075.9531 - val_loss: 89543.8672\n",
      "Epoch 48/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 72073.1172 - val_loss: 89292.2109\n",
      "Epoch 49/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 71773.2578 - val_loss: 89232.2734\n",
      "Epoch 50/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 71563.7969 - val_loss: 88700.6719\n",
      "Epoch 51/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 69814.1719 - val_loss: 88449.6797\n",
      "Epoch 52/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 72203.5000 - val_loss: 88347.5859\n",
      "Epoch 53/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 71858.3359 - val_loss: 87964.2031\n",
      "Epoch 54/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 70505.2891 - val_loss: 87813.4375\n",
      "Epoch 55/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 69826.5781 - val_loss: 87658.5312\n",
      "Epoch 56/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 70341.2422 - val_loss: 87797.8516\n",
      "Epoch 57/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 69375.0078 - val_loss: 87491.6250\n",
      "Epoch 58/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 68797.8672 - val_loss: 86997.4297\n",
      "Epoch 59/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 69092.4062 - val_loss: 86317.1719\n",
      "Epoch 60/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 67449.2422 - val_loss: 86052.1406\n",
      "Epoch 61/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 69517.9062 - val_loss: 86038.2109\n",
      "Epoch 62/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 68967.9688 - val_loss: 86020.1797\n",
      "Epoch 63/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 66732.2422 - val_loss: 85818.1406\n",
      "Epoch 64/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 68302.8047 - val_loss: 85274.1953\n",
      "Epoch 65/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 67858.8750 - val_loss: 85333.5938\n",
      "Epoch 66/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 67217.7891 - val_loss: 85153.1562\n",
      "Epoch 67/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 67572.7188 - val_loss: 84914.6484\n",
      "Epoch 68/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 67442.1953 - val_loss: 84851.5938\n",
      "Epoch 69/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 67498.9453 - val_loss: 84532.7578\n",
      "Epoch 70/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 66478.7500 - val_loss: 84352.1016\n",
      "Epoch 71/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 65408.9023 - val_loss: 84137.4688\n",
      "Epoch 72/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 65530.9844 - val_loss: 83812.3203\n",
      "Epoch 73/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 67041.9766 - val_loss: 83678.5000\n",
      "Epoch 74/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 65758.6016 - val_loss: 83537.4219\n",
      "Epoch 75/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 65359.5273 - val_loss: 83360.9531\n",
      "Epoch 76/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 66856.5312 - val_loss: 83766.2656\n",
      "Epoch 77/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 65762.1172 - val_loss: 83573.4453\n",
      "Epoch 78/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 64941.6992 - val_loss: 82823.5078\n",
      "Epoch 79/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 64938.6875 - val_loss: 82719.5469\n",
      "Epoch 80/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 65576.2891 - val_loss: 82604.4766\n",
      "Epoch 81/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 63424.8164 - val_loss: 82286.5938\n",
      "Epoch 82/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 66382.7578 - val_loss: 82387.1953\n",
      "Epoch 83/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 65138.6758 - val_loss: 82307.2109\n",
      "Epoch 84/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 64577.0312 - val_loss: 81956.7734\n",
      "Epoch 85/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 65711.0312 - val_loss: 81667.0938\n",
      "Epoch 86/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 64077.8867 - val_loss: 81921.6797\n",
      "Epoch 87/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 64256.2930 - val_loss: 81911.0469\n",
      "Epoch 88/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 64926.4883 - val_loss: 81865.2266\n",
      "Epoch 89/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 63873.7500 - val_loss: 81128.0234\n",
      "Epoch 90/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 63726.0352 - val_loss: 80680.4688\n",
      "Epoch 91/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 62151.6836 - val_loss: 80716.9219\n",
      "Epoch 92/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 62552.1914 - val_loss: 80422.3672\n",
      "Epoch 93/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 62339.2344 - val_loss: 80237.1953\n",
      "Epoch 94/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 62423.3672 - val_loss: 79825.3516\n",
      "Epoch 95/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 64429.6797 - val_loss: 80112.6172\n",
      "Epoch 96/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 61917.0703 - val_loss: 79990.2578\n",
      "Epoch 97/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 61387.1680 - val_loss: 79504.8359\n",
      "Epoch 98/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 61597.6992 - val_loss: 79471.6016\n",
      "Epoch 99/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 62869.5938 - val_loss: 79087.9844\n",
      "Epoch 100/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 62213.4141 - val_loss: 78935.9844\n",
      "Epoch 101/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 62824.3047 - val_loss: 78723.0000\n",
      "Epoch 102/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 60658.9688 - val_loss: 78425.5000\n",
      "Epoch 103/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 61920.1562 - val_loss: 78401.7891\n",
      "Epoch 104/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 62456.1445 - val_loss: 78030.5938\n",
      "Epoch 105/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 61307.6016 - val_loss: 77948.4453\n",
      "Epoch 106/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 60804.2422 - val_loss: 78009.0078\n",
      "Epoch 107/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 61134.7539 - val_loss: 77765.0234\n",
      "Epoch 108/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 61491.2539 - val_loss: 77926.2578\n",
      "Epoch 109/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 59997.3555 - val_loss: 77973.7734\n",
      "Epoch 110/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 61478.3125 - val_loss: 77680.8047\n",
      "Epoch 111/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 61211.0352 - val_loss: 77343.4375\n",
      "Epoch 112/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 60018.8633 - val_loss: 77224.7188\n",
      "Epoch 113/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 61159.6250 - val_loss: 77194.3516\n",
      "Epoch 114/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 60081.8281 - val_loss: 77084.1797\n",
      "Epoch 115/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 60701.5234 - val_loss: 77061.0547\n",
      "Epoch 116/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 60076.8945 - val_loss: 76829.9844\n",
      "Epoch 117/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 59960.1992 - val_loss: 76964.1953\n",
      "Epoch 118/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 60280.8945 - val_loss: 76745.4844\n",
      "Epoch 119/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 59812.5781 - val_loss: 76665.6406\n",
      "Epoch 120/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 61647.7070 - val_loss: 76667.8359\n",
      "Epoch 121/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 60363.7500 - val_loss: 76523.0703\n",
      "Epoch 122/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 59229.1641 - val_loss: 76208.9297\n",
      "Epoch 123/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 61068.4414 - val_loss: 76102.1875\n",
      "Epoch 124/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 59904.0000 - val_loss: 75621.8281\n",
      "Epoch 125/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 61042.1016 - val_loss: 75707.9844\n",
      "Epoch 126/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 59961.4922 - val_loss: 75632.2969\n",
      "Epoch 127/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 60674.8359 - val_loss: 75404.9375\n",
      "Epoch 128/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 59286.3750 - val_loss: 75631.5312\n",
      "Epoch 129/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 61320.5039 - val_loss: 75225.2266\n",
      "Epoch 130/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 59604.8828 - val_loss: 75052.3125\n",
      "Epoch 131/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 58581.6875 - val_loss: 74740.7031\n",
      "Epoch 132/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 59126.3750 - val_loss: 74615.1797\n",
      "Epoch 133/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 60285.9297 - val_loss: 74448.9531\n",
      "Epoch 134/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 58913.5547 - val_loss: 74700.4922\n",
      "Epoch 135/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 58853.9023 - val_loss: 74104.0469\n",
      "Epoch 136/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 59790.7852 - val_loss: 73993.0703\n",
      "Epoch 137/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 59494.6016 - val_loss: 73898.7500\n",
      "Epoch 138/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 58560.5781 - val_loss: 73836.5547\n",
      "Epoch 139/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 59205.6992 - val_loss: 73897.1953\n",
      "Epoch 140/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 60258.3750 - val_loss: 74019.1328\n",
      "Epoch 141/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 58871.4883 - val_loss: 73750.0391\n",
      "Epoch 142/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 60198.8164 - val_loss: 73601.8984\n",
      "Epoch 143/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 58669.0273 - val_loss: 73303.3047\n",
      "Epoch 144/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 59044.7578 - val_loss: 73308.4453\n",
      "Epoch 145/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 58063.2539 - val_loss: 73258.3828\n",
      "Epoch 146/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 58433.0508 - val_loss: 73102.5625\n",
      "Epoch 147/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 58171.6562 - val_loss: 73042.3203\n",
      "Epoch 148/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 58064.2930 - val_loss: 72898.1562\n",
      "Epoch 149/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 59576.6406 - val_loss: 72774.4531\n",
      "Epoch 150/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 58588.8516 - val_loss: 72769.7109\n",
      "Epoch 151/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 58950.0703 - val_loss: 72631.7734\n",
      "Epoch 152/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 58175.7500 - val_loss: 72463.4844\n",
      "Epoch 153/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 56605.0508 - val_loss: 72271.0391\n",
      "Epoch 154/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 57831.3984 - val_loss: 72279.5234\n",
      "Epoch 155/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 57829.2578 - val_loss: 72093.7422\n",
      "Epoch 156/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 57677.3828 - val_loss: 71960.5547\n",
      "Epoch 157/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 57387.2227 - val_loss: 71691.1875\n",
      "Epoch 158/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 57493.9961 - val_loss: 71525.1328\n",
      "Epoch 159/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 57155.4141 - val_loss: 71397.8750\n",
      "Epoch 160/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 57422.7539 - val_loss: 71414.3516\n",
      "Epoch 161/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 57471.5039 - val_loss: 71390.7422\n",
      "Epoch 162/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 57496.2422 - val_loss: 71184.1094\n",
      "Epoch 163/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 56609.0273 - val_loss: 71097.8281\n",
      "Epoch 164/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 59432.3789 - val_loss: 71373.4922\n",
      "Epoch 165/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 57281.2695 - val_loss: 71202.7656\n",
      "Epoch 166/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 56978.9414 - val_loss: 71035.3594\n",
      "Epoch 167/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 57862.5938 - val_loss: 71098.2656\n",
      "Epoch 168/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 57213.7031 - val_loss: 70757.5078\n",
      "Epoch 169/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 55573.0586 - val_loss: 70554.6328\n",
      "Epoch 170/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 57340.5469 - val_loss: 70492.9922\n",
      "Epoch 171/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 54320.9453 - val_loss: 70171.1250\n",
      "Epoch 172/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 58474.3281 - val_loss: 70289.9844\n",
      "Epoch 173/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 56974.2891 - val_loss: 69857.8984\n",
      "Epoch 174/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 56310.7734 - val_loss: 69825.1484\n",
      "Epoch 175/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 56325.4258 - val_loss: 69686.4375\n",
      "Epoch 176/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 57300.6953 - val_loss: 69645.8594\n",
      "Epoch 177/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 57385.9609 - val_loss: 69655.7422\n",
      "Epoch 178/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 55380.2930 - val_loss: 69442.3203\n",
      "Epoch 179/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 56053.2734 - val_loss: 69359.5938\n",
      "Epoch 180/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 55405.4727 - val_loss: 69278.0078\n",
      "Epoch 181/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 55325.9766 - val_loss: 69171.0078\n",
      "Epoch 182/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 56091.4453 - val_loss: 68955.5625\n",
      "Epoch 183/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 55322.2227 - val_loss: 68754.5781\n",
      "Epoch 184/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 56540.7773 - val_loss: 68704.2266\n",
      "Epoch 185/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 55812.3555 - val_loss: 68516.2266\n",
      "Epoch 186/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 55070.3906 - val_loss: 68545.4766\n",
      "Epoch 187/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 55263.5508 - val_loss: 68400.7109\n",
      "Epoch 188/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 55332.2070 - val_loss: 68276.0156\n",
      "Epoch 189/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 55441.8594 - val_loss: 68142.2969\n",
      "Epoch 190/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 54399.9922 - val_loss: 68089.8203\n",
      "Epoch 191/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 55427.1992 - val_loss: 68080.7578\n",
      "Epoch 192/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 56706.6250 - val_loss: 68048.3516\n",
      "Epoch 193/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 56095.9922 - val_loss: 67922.8203\n",
      "Epoch 194/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 53919.9141 - val_loss: 67819.0859\n",
      "Epoch 195/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 56380.6641 - val_loss: 67860.6562\n",
      "Epoch 196/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 54184.9648 - val_loss: 67645.0156\n",
      "Epoch 197/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 54999.9922 - val_loss: 67581.2578\n",
      "Epoch 198/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 54192.3125 - val_loss: 67568.7969\n",
      "Epoch 199/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 54236.8789 - val_loss: 67471.3750\n",
      "Epoch 200/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 54152.6797 - val_loss: 67292.6250\n",
      "Epoch 201/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 54597.9531 - val_loss: 67128.8672\n",
      "Epoch 202/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 53506.1719 - val_loss: 66954.1953\n",
      "Epoch 203/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 55314.2070 - val_loss: 66820.8984\n",
      "Epoch 204/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 53696.1250 - val_loss: 66853.9688\n",
      "Epoch 205/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 54862.6016 - val_loss: 66917.9219\n",
      "Epoch 206/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 53124.5586 - val_loss: 66820.5469\n",
      "Epoch 207/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 53671.2539 - val_loss: 66853.2344\n",
      "Epoch 208/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 54782.9492 - val_loss: 66661.2266\n",
      "Epoch 209/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 53576.0977 - val_loss: 66543.2891\n",
      "Epoch 210/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 54896.0000 - val_loss: 66378.3672\n",
      "Epoch 211/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 54153.3867 - val_loss: 66305.1406\n",
      "Epoch 212/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 52992.3594 - val_loss: 66296.7734\n",
      "Epoch 213/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 53998.6133 - val_loss: 66226.4688\n",
      "Epoch 214/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 53481.9414 - val_loss: 66043.3906\n",
      "Epoch 215/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 52920.4805 - val_loss: 66084.2031\n",
      "Epoch 216/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 54780.3594 - val_loss: 65938.5938\n",
      "Epoch 217/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 53916.5586 - val_loss: 65989.9766\n",
      "Epoch 218/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 52527.1719 - val_loss: 65993.7656\n",
      "Epoch 219/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 53651.7031 - val_loss: 65867.4219\n",
      "Epoch 220/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 51522.0117 - val_loss: 65663.2734\n",
      "Epoch 221/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 53032.1562 - val_loss: 65538.4688\n",
      "Epoch 222/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 53520.0078 - val_loss: 65529.3672\n",
      "Epoch 223/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 53033.5195 - val_loss: 65456.1172\n",
      "Epoch 224/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 53728.5859 - val_loss: 65451.4453\n",
      "Epoch 225/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 52456.3906 - val_loss: 65165.1055\n",
      "Epoch 226/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 52692.0547 - val_loss: 65014.1445\n",
      "Epoch 227/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 53186.9062 - val_loss: 65034.7266\n",
      "Epoch 228/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 51880.4609 - val_loss: 64998.5820\n",
      "Epoch 229/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 52120.8906 - val_loss: 64947.6445\n",
      "Epoch 230/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 51938.5547 - val_loss: 64905.8711\n",
      "Epoch 231/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 53130.8984 - val_loss: 64778.3906\n",
      "Epoch 232/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 51960.6875 - val_loss: 64951.7695\n",
      "Epoch 233/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 53367.1406 - val_loss: 64600.1445\n",
      "Epoch 234/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 52608.3750 - val_loss: 64537.3711\n",
      "Epoch 235/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 52363.6953 - val_loss: 64504.4609\n",
      "Epoch 236/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 51485.2656 - val_loss: 64400.0820\n",
      "Epoch 237/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 50889.7227 - val_loss: 64423.4336\n",
      "Epoch 238/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 53034.5117 - val_loss: 64340.5234\n",
      "Epoch 239/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 52715.5586 - val_loss: 64514.6406\n",
      "Epoch 240/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 51170.3984 - val_loss: 64435.6719\n",
      "Epoch 241/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 51699.6250 - val_loss: 64304.8828\n",
      "Epoch 242/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 52201.9531 - val_loss: 64127.2969\n",
      "Epoch 243/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 50704.5664 - val_loss: 63984.2109\n",
      "Epoch 244/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 52932.2617 - val_loss: 64027.1914\n",
      "Epoch 245/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 51721.9180 - val_loss: 63804.9492\n",
      "Epoch 246/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 51843.4102 - val_loss: 63802.4297\n",
      "Epoch 247/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 52313.4258 - val_loss: 63716.7383\n",
      "Epoch 248/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 50262.2227 - val_loss: 63690.5156\n",
      "Epoch 249/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 51613.1211 - val_loss: 63546.5078\n",
      "Epoch 250/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 51698.1719 - val_loss: 63448.6211\n",
      "Epoch 251/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 50658.8320 - val_loss: 63543.3789\n",
      "Epoch 252/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 52274.2773 - val_loss: 63557.3867\n",
      "Epoch 253/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 51891.0703 - val_loss: 63498.7070\n",
      "Epoch 254/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 49881.5625 - val_loss: 63420.0977\n",
      "Epoch 255/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 50673.5039 - val_loss: 63417.4922\n",
      "Epoch 256/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 50782.6016 - val_loss: 63238.9883\n",
      "Epoch 257/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 50073.8711 - val_loss: 63212.1484\n",
      "Epoch 258/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 49973.2148 - val_loss: 63324.6133\n",
      "Epoch 259/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 50146.6484 - val_loss: 63380.0430\n",
      "Epoch 260/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 49644.6992 - val_loss: 63257.7656\n",
      "Epoch 261/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 51084.8906 - val_loss: 63357.6289\n",
      "Epoch 262/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 51479.7109 - val_loss: 63231.7500\n",
      "Epoch 263/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 51158.6367 - val_loss: 63278.7070\n",
      "Epoch 264/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 51403.8125 - val_loss: 63229.0078\n",
      "Epoch 265/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 49988.8945 - val_loss: 63032.9688\n",
      "Epoch 266/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 49912.2070 - val_loss: 62895.5898\n",
      "Epoch 267/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 50193.0391 - val_loss: 62863.0234\n",
      "Epoch 268/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 50030.7188 - val_loss: 63343.0234\n",
      "Epoch 269/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 48999.0664 - val_loss: 62850.2227\n",
      "Epoch 270/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 51121.9023 - val_loss: 62711.1562\n",
      "Epoch 271/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 50841.5234 - val_loss: 62725.4961\n",
      "Epoch 272/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 50312.0469 - val_loss: 62667.0000\n",
      "Epoch 273/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 50018.4922 - val_loss: 62745.3477\n",
      "Epoch 274/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 50382.4648 - val_loss: 62774.9062\n",
      "Epoch 275/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 48893.5664 - val_loss: 62718.9375\n",
      "Epoch 276/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 49323.8633 - val_loss: 62761.2852\n",
      "Epoch 277/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 49045.4531 - val_loss: 62727.4219\n",
      "Epoch 278/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 48460.4414 - val_loss: 62563.1562\n",
      "Epoch 279/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 49137.5078 - val_loss: 62562.6953\n",
      "Epoch 280/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 50107.6094 - val_loss: 62582.9141\n",
      "Epoch 281/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 47590.9492 - val_loss: 62538.3477\n",
      "Epoch 282/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 48867.3867 - val_loss: 62432.8320\n",
      "Epoch 283/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 48670.7539 - val_loss: 62484.6641\n",
      "Epoch 284/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 49053.6680 - val_loss: 62493.9180\n",
      "Epoch 285/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 49213.4570 - val_loss: 62428.7695\n",
      "Epoch 286/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 49781.5000 - val_loss: 62373.1914\n",
      "Epoch 287/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 49515.1992 - val_loss: 62391.2812\n",
      "Epoch 288/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 49265.8750 - val_loss: 62406.0742\n",
      "Epoch 289/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 49564.7109 - val_loss: 62240.4336\n",
      "Epoch 290/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 49629.4414 - val_loss: 62506.8398\n",
      "Epoch 291/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 49642.5547 - val_loss: 62384.7266\n",
      "Epoch 292/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 49491.2148 - val_loss: 62229.5820\n",
      "Epoch 293/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 48466.2344 - val_loss: 62300.6289\n",
      "Epoch 294/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 48932.0273 - val_loss: 62168.2812\n",
      "Epoch 295/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 48421.7070 - val_loss: 62009.6641\n",
      "Epoch 296/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 49136.8398 - val_loss: 62209.7500\n",
      "Epoch 297/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 47678.7148 - val_loss: 62080.3555\n",
      "Epoch 298/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47377.5508 - val_loss: 62089.8320\n",
      "Epoch 299/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47788.2734 - val_loss: 62022.6328\n",
      "Epoch 300/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 49105.2031 - val_loss: 61998.3594\n",
      "Epoch 301/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 49290.2773 - val_loss: 61899.7891\n",
      "Epoch 302/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46463.9180 - val_loss: 61679.2539\n",
      "Epoch 303/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 48809.6094 - val_loss: 61657.4180\n",
      "Epoch 304/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 48468.9531 - val_loss: 61681.0547\n",
      "Epoch 305/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47682.2656 - val_loss: 61740.0312\n",
      "Epoch 306/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47115.3711 - val_loss: 61960.0195\n",
      "Epoch 307/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47956.0977 - val_loss: 62135.3242\n",
      "Epoch 308/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 47620.3047 - val_loss: 61646.9609\n",
      "Epoch 309/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 48527.7617 - val_loss: 61510.7891\n",
      "Epoch 310/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47654.1367 - val_loss: 61544.6523\n",
      "Epoch 311/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 49050.5508 - val_loss: 61523.8516\n",
      "Epoch 312/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 49404.1406 - val_loss: 61654.7461\n",
      "Epoch 313/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47832.9102 - val_loss: 61944.9023\n",
      "Epoch 314/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46624.9609 - val_loss: 61707.6289\n",
      "Epoch 315/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47670.7891 - val_loss: 61499.1367\n",
      "Epoch 316/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47924.2812 - val_loss: 61585.9023\n",
      "Epoch 317/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47349.5352 - val_loss: 61519.5977\n",
      "Epoch 318/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 47258.3984 - val_loss: 61387.9609\n",
      "Epoch 319/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 48744.0195 - val_loss: 61615.0859\n",
      "Epoch 320/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 48138.6641 - val_loss: 61606.2188\n",
      "Epoch 321/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 47569.7734 - val_loss: 61505.2031\n",
      "Epoch 322/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47809.4062 - val_loss: 61402.4180\n",
      "Epoch 323/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 46932.6484 - val_loss: 61325.6602\n",
      "Epoch 324/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 48036.1328 - val_loss: 61482.1758\n",
      "Epoch 325/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 45271.1211 - val_loss: 61448.7188\n",
      "Epoch 326/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47504.0820 - val_loss: 61328.5391\n",
      "Epoch 327/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47891.1758 - val_loss: 61371.6836\n",
      "Epoch 328/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45483.4492 - val_loss: 61435.8086\n",
      "Epoch 329/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46138.5430 - val_loss: 61363.8711\n",
      "Epoch 330/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46306.9023 - val_loss: 61149.8945\n",
      "Epoch 331/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 48067.6797 - val_loss: 61083.5820\n",
      "Epoch 332/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47020.5117 - val_loss: 61073.9062\n",
      "Epoch 333/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47064.5469 - val_loss: 61004.2305\n",
      "Epoch 334/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 46443.5195 - val_loss: 61171.9922\n",
      "Epoch 335/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46046.4453 - val_loss: 61197.3984\n",
      "Epoch 336/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46773.5391 - val_loss: 61035.1133\n",
      "Epoch 337/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47237.2266 - val_loss: 60811.5781\n",
      "Epoch 338/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46107.5977 - val_loss: 60788.3281\n",
      "Epoch 339/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46037.9297 - val_loss: 60920.0391\n",
      "Epoch 340/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46380.0117 - val_loss: 61217.7344\n",
      "Epoch 341/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46894.8320 - val_loss: 61375.2031\n",
      "Epoch 342/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46877.5547 - val_loss: 61102.9023\n",
      "Epoch 343/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 46079.6797 - val_loss: 61226.0312\n",
      "Epoch 344/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 46325.5117 - val_loss: 61214.1992\n",
      "Epoch 345/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47481.1094 - val_loss: 60963.3555\n",
      "Epoch 346/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47645.9414 - val_loss: 60998.8711\n",
      "Epoch 347/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46743.4727 - val_loss: 61196.5469\n",
      "Epoch 348/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 45674.2656 - val_loss: 61257.2969\n",
      "Epoch 349/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46725.3906 - val_loss: 61328.5156\n",
      "Epoch 350/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 47026.1523 - val_loss: 61191.4219\n",
      "Epoch 351/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45892.0273 - val_loss: 60816.5234\n",
      "Epoch 352/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 46069.1758 - val_loss: 60908.1875\n",
      "Epoch 353/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47373.4883 - val_loss: 60673.6523\n",
      "Epoch 354/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 46155.3047 - val_loss: 60584.1992\n",
      "Epoch 355/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47116.0977 - val_loss: 60888.6328\n",
      "Epoch 356/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45482.7031 - val_loss: 60870.6016\n",
      "Epoch 357/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 45050.2656 - val_loss: 60951.0859\n",
      "Epoch 358/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44217.3555 - val_loss: 60864.1758\n",
      "Epoch 359/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46698.0156 - val_loss: 61023.4336\n",
      "Epoch 360/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45276.9453 - val_loss: 61120.5547\n",
      "Epoch 361/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45141.0312 - val_loss: 60888.5391\n",
      "Epoch 362/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 45533.0508 - val_loss: 60763.3477\n",
      "Epoch 363/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46213.3828 - val_loss: 61052.0000\n",
      "Epoch 364/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45423.6094 - val_loss: 60605.0977\n",
      "Epoch 365/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46027.1172 - val_loss: 60912.6836\n",
      "Epoch 366/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45328.1133 - val_loss: 60685.2930\n",
      "Epoch 367/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46307.5039 - val_loss: 60507.9805\n",
      "Epoch 368/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45280.1133 - val_loss: 60555.6328\n",
      "Epoch 369/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47455.7812 - val_loss: 60710.8125\n",
      "Epoch 370/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44722.7578 - val_loss: 60350.3281\n",
      "Epoch 371/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 45946.6953 - val_loss: 60448.3398\n",
      "Epoch 372/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 45727.6602 - val_loss: 61115.8750\n",
      "Epoch 373/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45419.1328 - val_loss: 61043.4766\n",
      "Epoch 374/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45777.6250 - val_loss: 60818.2344\n",
      "Epoch 375/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45958.9062 - val_loss: 60715.2305\n",
      "Epoch 376/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 45376.3750 - val_loss: 60921.2734\n",
      "Epoch 377/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44753.2461 - val_loss: 60643.3984\n",
      "Epoch 378/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45758.2500 - val_loss: 60815.8555\n",
      "Epoch 379/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45290.5273 - val_loss: 60744.5820\n",
      "Epoch 380/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 45084.5117 - val_loss: 60426.9023\n",
      "Epoch 381/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 45834.8672 - val_loss: 60201.6016\n",
      "Epoch 382/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 45793.8828 - val_loss: 59973.3359\n",
      "Epoch 383/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44865.5898 - val_loss: 60206.7812\n",
      "Epoch 384/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 45327.4570 - val_loss: 60461.6016\n",
      "Epoch 385/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46547.0430 - val_loss: 60667.3867\n",
      "Epoch 386/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46052.2539 - val_loss: 60558.0547\n",
      "Epoch 387/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46169.1484 - val_loss: 60255.1445\n",
      "Epoch 388/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46722.3438 - val_loss: 60102.9141\n",
      "Epoch 389/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45012.0938 - val_loss: 60210.4648\n",
      "Epoch 390/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 46327.3594 - val_loss: 60067.7773\n",
      "Epoch 391/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45868.2109 - val_loss: 59774.8867\n",
      "Epoch 392/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 45496.9258 - val_loss: 59631.2500\n",
      "Epoch 393/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44952.7383 - val_loss: 60019.9609\n",
      "Epoch 394/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44823.3320 - val_loss: 60141.8945\n",
      "Epoch 395/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44700.1562 - val_loss: 60026.5273\n",
      "Epoch 396/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45009.7695 - val_loss: 59847.7773\n",
      "Epoch 397/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45089.8711 - val_loss: 60200.5547\n",
      "Epoch 398/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43737.6406 - val_loss: 60073.1445\n",
      "Epoch 399/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45295.5195 - val_loss: 59861.7461\n",
      "Epoch 400/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44125.1875 - val_loss: 59984.5977\n",
      "Epoch 401/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45417.1172 - val_loss: 60267.0391\n",
      "Epoch 402/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44863.7734 - val_loss: 60109.0938\n",
      "Epoch 403/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44412.7539 - val_loss: 59972.3125\n",
      "Epoch 404/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44986.9844 - val_loss: 59872.0820\n",
      "Epoch 405/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45512.8789 - val_loss: 59903.2109\n",
      "Epoch 406/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44498.1328 - val_loss: 59550.2930\n",
      "Epoch 407/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 47279.3398 - val_loss: 59627.1562\n",
      "Epoch 408/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44798.3125 - val_loss: 59637.6328\n",
      "Epoch 409/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44048.7031 - val_loss: 59755.3359\n",
      "Epoch 410/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44651.9531 - val_loss: 59852.0938\n",
      "Epoch 411/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44812.2500 - val_loss: 59853.3164\n",
      "Epoch 412/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44204.8828 - val_loss: 59997.3047\n",
      "Epoch 413/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 45312.5195 - val_loss: 59755.2305\n",
      "Epoch 414/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44057.4258 - val_loss: 59671.3477\n",
      "Epoch 415/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 46339.6719 - val_loss: 59505.4609\n",
      "Epoch 416/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43749.8750 - val_loss: 59567.1680\n",
      "Epoch 417/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43748.1445 - val_loss: 59488.2617\n",
      "Epoch 418/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44253.5430 - val_loss: 59521.0625\n",
      "Epoch 419/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44502.8047 - val_loss: 59791.1602\n",
      "Epoch 420/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44244.0703 - val_loss: 59794.0938\n",
      "Epoch 421/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44727.2031 - val_loss: 59650.6445\n",
      "Epoch 422/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45483.2695 - val_loss: 59497.8867\n",
      "Epoch 423/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43871.7109 - val_loss: 59659.7031\n",
      "Epoch 424/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44205.5664 - val_loss: 59578.0000\n",
      "Epoch 425/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44615.6719 - val_loss: 59525.8828\n",
      "Epoch 426/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44621.5195 - val_loss: 59598.8516\n",
      "Epoch 427/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44002.8164 - val_loss: 59714.6641\n",
      "Epoch 428/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 45346.6641 - val_loss: 59438.7969\n",
      "Epoch 429/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43789.7969 - val_loss: 59493.4922\n",
      "Epoch 430/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44692.7656 - val_loss: 59627.6289\n",
      "Epoch 431/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43978.6211 - val_loss: 59884.3789\n",
      "Epoch 432/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43697.4688 - val_loss: 59672.4453\n",
      "Epoch 433/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43687.8008 - val_loss: 59659.4102\n",
      "Epoch 434/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44390.0391 - val_loss: 59613.1055\n",
      "Epoch 435/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 45504.0664 - val_loss: 59672.8867\n",
      "Epoch 436/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44890.9648 - val_loss: 59472.5781\n",
      "Epoch 437/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43870.3359 - val_loss: 59514.5977\n",
      "Epoch 438/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44622.7578 - val_loss: 59529.6289\n",
      "Epoch 439/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44552.9375 - val_loss: 59521.1484\n",
      "Epoch 440/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44332.2461 - val_loss: 59264.2422\n",
      "Epoch 441/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43750.7656 - val_loss: 59165.3242\n",
      "Epoch 442/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43852.3125 - val_loss: 59324.2617\n",
      "Epoch 443/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43827.6250 - val_loss: 59424.0430\n",
      "Epoch 444/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43384.9609 - val_loss: 59849.1250\n",
      "Epoch 445/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 46296.3594 - val_loss: 59823.4414\n",
      "Epoch 446/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41920.2266 - val_loss: 59274.3711\n",
      "Epoch 447/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44861.0391 - val_loss: 59268.7578\n",
      "Epoch 448/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44586.7109 - val_loss: 60125.2539\n",
      "Epoch 449/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43998.6289 - val_loss: 59741.6836\n",
      "Epoch 450/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44100.9609 - val_loss: 59285.9492\n",
      "Epoch 451/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44153.3672 - val_loss: 59193.7461\n",
      "Epoch 452/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44633.9531 - val_loss: 59354.4766\n",
      "Epoch 453/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44267.8867 - val_loss: 59223.0859\n",
      "Epoch 454/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44664.9453 - val_loss: 59095.1602\n",
      "Epoch 455/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43658.2266 - val_loss: 59797.1289\n",
      "Epoch 456/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43708.7539 - val_loss: 59335.5469\n",
      "Epoch 457/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44986.2773 - val_loss: 59333.4648\n",
      "Epoch 458/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44043.9766 - val_loss: 59209.8086\n",
      "Epoch 459/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43804.5234 - val_loss: 59145.9883\n",
      "Epoch 460/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43572.7188 - val_loss: 59114.6641\n",
      "Epoch 461/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 45237.4922 - val_loss: 58983.6094\n",
      "Epoch 462/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43674.8281 - val_loss: 59045.7383\n",
      "Epoch 463/1200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 44017.1055 - val_loss: 59163.5156\n",
      "Epoch 464/1200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 43781.8203 - val_loss: 59289.1289\n",
      "Epoch 465/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43340.0000 - val_loss: 59121.9062\n",
      "Epoch 466/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43376.1094 - val_loss: 59125.8867\n",
      "Epoch 467/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44209.3438 - val_loss: 58869.9883\n",
      "Epoch 468/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43083.2188 - val_loss: 58945.0625\n",
      "Epoch 469/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43865.2148 - val_loss: 58950.7148\n",
      "Epoch 470/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44249.2344 - val_loss: 59044.1367\n",
      "Epoch 471/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43911.0234 - val_loss: 59003.9141\n",
      "Epoch 472/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44956.3984 - val_loss: 58843.2930\n",
      "Epoch 473/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44198.0664 - val_loss: 58905.2734\n",
      "Epoch 474/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43045.9453 - val_loss: 59063.6953\n",
      "Epoch 475/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43541.3828 - val_loss: 58986.6602\n",
      "Epoch 476/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43813.9688 - val_loss: 59093.4844\n",
      "Epoch 477/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43294.8828 - val_loss: 59090.2734\n",
      "Epoch 478/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42726.2070 - val_loss: 58901.8945\n",
      "Epoch 479/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44659.3711 - val_loss: 59006.9766\n",
      "Epoch 480/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44546.3594 - val_loss: 58915.4609\n",
      "Epoch 481/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43048.9141 - val_loss: 58870.6641\n",
      "Epoch 482/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43521.5703 - val_loss: 59061.5352\n",
      "Epoch 483/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44302.3359 - val_loss: 58987.3047\n",
      "Epoch 484/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 43294.0977 - val_loss: 58980.0508\n",
      "Epoch 485/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42816.4883 - val_loss: 58902.9062\n",
      "Epoch 486/1200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 43873.4375 - val_loss: 58877.3672\n",
      "Epoch 487/1200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 43453.3086 - val_loss: 58802.0938\n",
      "Epoch 488/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44854.6172 - val_loss: 58733.4219\n",
      "Epoch 489/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44106.4180 - val_loss: 58886.5469\n",
      "Epoch 490/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44240.7969 - val_loss: 59091.5352\n",
      "Epoch 491/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43634.3984 - val_loss: 58984.0391\n",
      "Epoch 492/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43336.3242 - val_loss: 58845.8711\n",
      "Epoch 493/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43478.3125 - val_loss: 58900.7656\n",
      "Epoch 494/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42659.0781 - val_loss: 58911.3242\n",
      "Epoch 495/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41940.2500 - val_loss: 58898.8242\n",
      "Epoch 496/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 43583.0391 - val_loss: 58948.2109\n",
      "Epoch 497/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44236.4492 - val_loss: 58919.1367\n",
      "Epoch 498/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43345.0703 - val_loss: 58777.7773\n",
      "Epoch 499/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43983.1523 - val_loss: 58687.9375\n",
      "Epoch 500/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42803.7188 - val_loss: 58733.1562\n",
      "Epoch 501/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44333.9219 - val_loss: 58802.7383\n",
      "Epoch 502/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43068.2656 - val_loss: 58673.4414\n",
      "Epoch 503/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43419.4062 - val_loss: 58733.4336\n",
      "Epoch 504/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43247.6328 - val_loss: 58897.4336\n",
      "Epoch 505/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42835.5273 - val_loss: 58825.8008\n",
      "Epoch 506/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43557.7734 - val_loss: 59012.4922\n",
      "Epoch 507/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43531.4141 - val_loss: 58768.5820\n",
      "Epoch 508/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44112.2852 - val_loss: 58597.2305\n",
      "Epoch 509/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43762.1289 - val_loss: 58723.9180\n",
      "Epoch 510/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44498.3555 - val_loss: 58870.7148\n",
      "Epoch 511/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42720.5430 - val_loss: 58863.7344\n",
      "Epoch 512/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43138.7109 - val_loss: 58930.2617\n",
      "Epoch 513/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44832.6289 - val_loss: 58814.1758\n",
      "Epoch 514/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43824.0820 - val_loss: 58555.9492\n",
      "Epoch 515/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 44164.0898 - val_loss: 58646.2227\n",
      "Epoch 516/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 43188.8047 - val_loss: 58803.0078\n",
      "Epoch 517/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43195.2070 - val_loss: 59317.0078\n",
      "Epoch 518/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42987.1211 - val_loss: 58829.9492\n",
      "Epoch 519/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44645.1836 - val_loss: 58665.0938\n",
      "Epoch 520/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42949.3516 - val_loss: 59080.1602\n",
      "Epoch 521/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43045.9180 - val_loss: 58979.9180\n",
      "Epoch 522/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42840.9648 - val_loss: 58690.3711\n",
      "Epoch 523/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42536.3203 - val_loss: 58618.4844\n",
      "Epoch 524/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43861.4844 - val_loss: 58633.5156\n",
      "Epoch 525/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44026.5039 - val_loss: 58556.5898\n",
      "Epoch 526/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 43875.0469 - val_loss: 58594.1914\n",
      "Epoch 527/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43103.4258 - val_loss: 58980.7461\n",
      "Epoch 528/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 45063.7969 - val_loss: 58709.0820\n",
      "Epoch 529/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42860.8828 - val_loss: 58686.6211\n",
      "Epoch 530/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42295.8906 - val_loss: 58673.9453\n",
      "Epoch 531/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43984.3672 - val_loss: 58554.4609\n",
      "Epoch 532/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41937.7461 - val_loss: 58661.9492\n",
      "Epoch 533/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44634.5547 - val_loss: 59456.4844\n",
      "Epoch 534/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42837.5859 - val_loss: 58719.3672\n",
      "Epoch 535/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44829.5039 - val_loss: 58741.6211\n",
      "Epoch 536/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41448.0117 - val_loss: 58438.9453\n",
      "Epoch 537/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44281.5156 - val_loss: 58577.3164\n",
      "Epoch 538/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44554.4648 - val_loss: 58477.5273\n",
      "Epoch 539/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43261.8633 - val_loss: 58548.1680\n",
      "Epoch 540/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42890.5977 - val_loss: 58374.3281\n",
      "Epoch 541/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 42290.9023 - val_loss: 58798.4609\n",
      "Epoch 542/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43294.4062 - val_loss: 58476.9258\n",
      "Epoch 543/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 42128.8164 - val_loss: 58584.8750\n",
      "Epoch 544/1200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 42874.6758 - val_loss: 58553.1250\n",
      "Epoch 545/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 41861.5781 - val_loss: 58721.3789\n",
      "Epoch 546/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 43821.2188 - val_loss: 58591.0430\n",
      "Epoch 547/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42936.7695 - val_loss: 58654.9453\n",
      "Epoch 548/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44211.2383 - val_loss: 58595.7578\n",
      "Epoch 549/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42978.9141 - val_loss: 58790.3867\n",
      "Epoch 550/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 42257.2305 - val_loss: 58814.9453\n",
      "Epoch 551/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 43335.1523 - val_loss: 58696.4531\n",
      "Epoch 552/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 42551.8477 - val_loss: 58567.1289\n",
      "Epoch 553/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 42411.3086 - val_loss: 58787.1562\n",
      "Epoch 554/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43854.2969 - val_loss: 58696.5391\n",
      "Epoch 555/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 43411.2422 - val_loss: 58728.4414\n",
      "Epoch 556/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44986.9688 - val_loss: 58908.7344\n",
      "Epoch 557/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 43517.4258 - val_loss: 58604.1875\n",
      "Epoch 558/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 42705.4141 - val_loss: 58757.4023\n",
      "Epoch 559/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 43380.2383 - val_loss: 58664.5664\n",
      "Epoch 560/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 43544.2383 - val_loss: 58700.5547\n",
      "Epoch 561/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 43264.8945 - val_loss: 58795.4336\n",
      "Epoch 562/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 42438.5391 - val_loss: 58855.3984\n",
      "Epoch 563/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 43439.9688 - val_loss: 58639.9922\n",
      "Epoch 564/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 42566.4570 - val_loss: 58720.0742\n",
      "Epoch 565/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 43248.2812 - val_loss: 58612.9688\n",
      "Epoch 566/1200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 42551.1445 - val_loss: 58555.6211\n",
      "Epoch 567/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 43320.0312 - val_loss: 58903.4180\n",
      "Epoch 568/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 41830.9062 - val_loss: 59118.5781\n",
      "Epoch 569/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 44827.2109 - val_loss: 58556.3594\n",
      "Epoch 570/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 43753.4922 - val_loss: 58526.1758\n",
      "Epoch 571/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42749.9297 - val_loss: 58252.6094\n",
      "Epoch 572/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42880.7852 - val_loss: 58270.0742\n",
      "Epoch 573/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 43659.4180 - val_loss: 58322.4414\n",
      "Epoch 574/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 42669.6211 - val_loss: 58543.9023\n",
      "Epoch 575/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 42238.4570 - val_loss: 58292.7148\n",
      "Epoch 576/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 43473.9023 - val_loss: 58238.1680\n",
      "Epoch 577/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 42426.2617 - val_loss: 58350.8086\n",
      "Epoch 578/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44338.1641 - val_loss: 58828.6406\n",
      "Epoch 579/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42574.1094 - val_loss: 58381.0391\n",
      "Epoch 580/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42704.8203 - val_loss: 58468.2031\n",
      "Epoch 581/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42742.0977 - val_loss: 58459.2539\n",
      "Epoch 582/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 42892.5469 - val_loss: 58395.3672\n",
      "Epoch 583/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 42947.2539 - val_loss: 58474.3359\n",
      "Epoch 584/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 43728.4531 - val_loss: 59262.2812\n",
      "Epoch 585/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 43579.6094 - val_loss: 58561.7383\n",
      "Epoch 586/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43052.6445 - val_loss: 58267.7500\n",
      "Epoch 587/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43087.4258 - val_loss: 58475.5898\n",
      "Epoch 588/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42831.3633 - val_loss: 58599.7969\n",
      "Epoch 589/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 42618.6914 - val_loss: 58564.2031\n",
      "Epoch 590/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 44599.6875 - val_loss: 58418.6289\n",
      "Epoch 591/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 42995.0508 - val_loss: 58376.9492\n",
      "Epoch 592/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 41657.0195 - val_loss: 58877.9492\n",
      "Epoch 593/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 41934.5117 - val_loss: 59109.4961\n",
      "Epoch 594/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 41935.9531 - val_loss: 58526.1367\n",
      "Epoch 595/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42341.5586 - val_loss: 58837.0859\n",
      "Epoch 596/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43651.6328 - val_loss: 58524.3711\n",
      "Epoch 597/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42003.2461 - val_loss: 58257.7344\n",
      "Epoch 598/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42533.4258 - val_loss: 58127.6875\n",
      "Epoch 599/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 43939.3828 - val_loss: 58217.0977\n",
      "Epoch 600/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 42892.2383 - val_loss: 58241.0117\n",
      "Epoch 601/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 42143.5625 - val_loss: 58225.3047\n",
      "Epoch 602/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 43911.4453 - val_loss: 58354.1680\n",
      "Epoch 603/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42506.8359 - val_loss: 58305.0078\n",
      "Epoch 604/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44701.2695 - val_loss: 58305.7031\n",
      "Epoch 605/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43801.8359 - val_loss: 58648.9336\n",
      "Epoch 606/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43872.4453 - val_loss: 58278.2539\n",
      "Epoch 607/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 42866.6094 - val_loss: 58627.2969\n",
      "Epoch 608/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42625.8633 - val_loss: 58243.2344\n",
      "Epoch 609/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41217.1055 - val_loss: 58021.7461\n",
      "Epoch 610/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42501.4883 - val_loss: 58070.5352\n",
      "Epoch 611/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 42716.4570 - val_loss: 58031.9805\n",
      "Epoch 612/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42185.9492 - val_loss: 58027.2305\n",
      "Epoch 613/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43285.7656 - val_loss: 58180.6875\n",
      "Epoch 614/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43178.0586 - val_loss: 57936.7656\n",
      "Epoch 615/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43701.3320 - val_loss: 57975.0391\n",
      "Epoch 616/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42824.0820 - val_loss: 58214.8633\n",
      "Epoch 617/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43000.0039 - val_loss: 58109.1133\n",
      "Epoch 618/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43470.1484 - val_loss: 58554.9180\n",
      "Epoch 619/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42959.0547 - val_loss: 58274.1562\n",
      "Epoch 620/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43650.0273 - val_loss: 58321.4766\n",
      "Epoch 621/1200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 43812.4336 - val_loss: 58034.6211\n",
      "Epoch 622/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42489.5234 - val_loss: 57957.6328\n",
      "Epoch 623/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41441.8242 - val_loss: 57944.2812\n",
      "Epoch 624/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43071.2812 - val_loss: 58021.5391\n",
      "Epoch 625/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43250.4375 - val_loss: 57964.1367\n",
      "Epoch 626/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43706.9688 - val_loss: 58118.0977\n",
      "Epoch 627/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43345.7461 - val_loss: 58098.7500\n",
      "Epoch 628/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42902.5469 - val_loss: 58600.6875\n",
      "Epoch 629/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42312.6797 - val_loss: 58680.6211\n",
      "Epoch 630/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42430.9414 - val_loss: 58395.9570\n",
      "Epoch 631/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43341.2461 - val_loss: 58253.8203\n",
      "Epoch 632/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42627.1328 - val_loss: 58321.2305\n",
      "Epoch 633/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42883.9336 - val_loss: 57995.9883\n",
      "Epoch 634/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43172.9766 - val_loss: 57981.7148\n",
      "Epoch 635/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43140.0039 - val_loss: 58210.9141\n",
      "Epoch 636/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43152.6758 - val_loss: 58379.3711\n",
      "Epoch 637/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42075.4688 - val_loss: 58297.8633\n",
      "Epoch 638/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43380.3984 - val_loss: 58611.3672\n",
      "Epoch 639/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43164.5117 - val_loss: 58407.1055\n",
      "Epoch 640/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42649.7344 - val_loss: 58057.3672\n",
      "Epoch 641/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41107.0625 - val_loss: 58836.2812\n",
      "Epoch 642/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42363.0352 - val_loss: 58667.3398\n",
      "Epoch 643/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41919.2461 - val_loss: 57948.8242\n",
      "Epoch 644/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42259.6094 - val_loss: 58314.1992\n",
      "Epoch 645/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42329.8242 - val_loss: 57972.1289\n",
      "Epoch 646/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43492.8828 - val_loss: 58010.3477\n",
      "Epoch 647/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41592.9219 - val_loss: 58030.8320\n",
      "Epoch 648/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42384.9492 - val_loss: 58032.1055\n",
      "Epoch 649/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43906.0781 - val_loss: 57852.1172\n",
      "Epoch 650/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43077.2500 - val_loss: 57844.3242\n",
      "Epoch 651/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42320.9961 - val_loss: 57736.9023\n",
      "Epoch 652/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42413.5820 - val_loss: 57839.8867\n",
      "Epoch 653/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41663.2461 - val_loss: 57748.1914\n",
      "Epoch 654/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42365.5938 - val_loss: 57671.3711\n",
      "Epoch 655/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43036.6250 - val_loss: 57909.5156\n",
      "Epoch 656/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42955.6875 - val_loss: 57848.3555\n",
      "Epoch 657/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42905.3750 - val_loss: 58582.0938\n",
      "Epoch 658/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44011.2578 - val_loss: 58070.0508\n",
      "Epoch 659/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43761.9141 - val_loss: 58084.9336\n",
      "Epoch 660/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41828.5273 - val_loss: 58073.9180\n",
      "Epoch 661/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44053.1680 - val_loss: 58249.4531\n",
      "Epoch 662/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43014.7578 - val_loss: 57906.1172\n",
      "Epoch 663/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42918.8477 - val_loss: 58260.6641\n",
      "Epoch 664/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44057.9492 - val_loss: 58420.1289\n",
      "Epoch 665/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42970.4648 - val_loss: 58281.3164\n",
      "Epoch 666/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43501.6133 - val_loss: 58125.7578\n",
      "Epoch 667/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42558.4961 - val_loss: 58067.4727\n",
      "Epoch 668/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43201.7891 - val_loss: 58516.6719\n",
      "Epoch 669/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43366.5508 - val_loss: 57971.1992\n",
      "Epoch 670/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42412.8477 - val_loss: 57816.7031\n",
      "Epoch 671/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42801.7305 - val_loss: 58376.4961\n",
      "Epoch 672/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41860.5586 - val_loss: 58325.1602\n",
      "Epoch 673/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41097.6094 - val_loss: 57788.0508\n",
      "Epoch 674/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43876.9297 - val_loss: 57880.7344\n",
      "Epoch 675/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42265.0586 - val_loss: 58009.1484\n",
      "Epoch 676/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42358.9727 - val_loss: 57746.0117\n",
      "Epoch 677/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43898.3477 - val_loss: 58310.0742\n",
      "Epoch 678/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43398.7812 - val_loss: 57817.6602\n",
      "Epoch 679/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42429.1055 - val_loss: 58888.8750\n",
      "Epoch 680/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43029.9453 - val_loss: 58935.0664\n",
      "Epoch 681/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42527.4297 - val_loss: 58757.6641\n",
      "Epoch 682/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41971.2461 - val_loss: 58035.9023\n",
      "Epoch 683/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44076.3711 - val_loss: 58309.7461\n",
      "Epoch 684/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42568.8438 - val_loss: 58697.2031\n",
      "Epoch 685/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43340.1211 - val_loss: 58341.3125\n",
      "Epoch 686/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43948.1641 - val_loss: 57893.5352\n",
      "Epoch 687/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42291.6445 - val_loss: 58004.8320\n",
      "Epoch 688/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43005.4180 - val_loss: 58309.9570\n",
      "Epoch 689/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43445.9492 - val_loss: 58728.9453\n",
      "Epoch 690/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44215.1680 - val_loss: 58684.1602\n",
      "Epoch 691/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41884.1250 - val_loss: 58232.0312\n",
      "Epoch 692/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42975.7656 - val_loss: 58165.9375\n",
      "Epoch 693/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44479.5859 - val_loss: 58026.8320\n",
      "Epoch 694/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43146.8359 - val_loss: 57959.9258\n",
      "Epoch 695/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43235.1992 - val_loss: 57928.9336\n",
      "Epoch 696/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41660.2930 - val_loss: 58666.3672\n",
      "Epoch 697/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42240.9688 - val_loss: 57906.3047\n",
      "Epoch 698/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43762.5117 - val_loss: 57818.2617\n",
      "Epoch 699/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41967.6445 - val_loss: 58119.0234\n",
      "Epoch 700/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43077.7930 - val_loss: 57867.7266\n",
      "Epoch 701/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42193.2070 - val_loss: 58025.4297\n",
      "Epoch 702/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42007.1992 - val_loss: 58434.2500\n",
      "Epoch 703/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43353.0625 - val_loss: 57911.8516\n",
      "Epoch 704/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43096.8086 - val_loss: 58011.0234\n",
      "Epoch 705/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42111.0039 - val_loss: 57784.8008\n",
      "Epoch 706/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42368.0156 - val_loss: 57574.7031\n",
      "Epoch 707/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43272.3945 - val_loss: 57499.9336\n",
      "Epoch 708/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43353.9922 - val_loss: 58017.0195\n",
      "Epoch 709/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41716.3438 - val_loss: 57845.6289\n",
      "Epoch 710/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42874.4922 - val_loss: 57756.0977\n",
      "Epoch 711/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42587.6719 - val_loss: 58173.2734\n",
      "Epoch 712/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41940.9492 - val_loss: 58612.0820\n",
      "Epoch 713/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42354.0312 - val_loss: 58334.1133\n",
      "Epoch 714/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42431.5273 - val_loss: 58313.8242\n",
      "Epoch 715/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41289.2539 - val_loss: 58334.4102\n",
      "Epoch 716/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42644.7695 - val_loss: 58240.9609\n",
      "Epoch 717/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43613.3711 - val_loss: 57855.7695\n",
      "Epoch 718/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42736.2266 - val_loss: 58251.8086\n",
      "Epoch 719/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42817.5781 - val_loss: 57786.6758\n",
      "Epoch 720/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41614.4414 - val_loss: 57710.2227\n",
      "Epoch 721/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42627.4414 - val_loss: 58242.6328\n",
      "Epoch 722/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42078.1680 - val_loss: 59267.2305\n",
      "Epoch 723/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42540.4531 - val_loss: 58561.8438\n",
      "Epoch 724/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41604.4883 - val_loss: 58101.5352\n",
      "Epoch 725/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43263.4727 - val_loss: 58169.3359\n",
      "Epoch 726/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 40529.7383 - val_loss: 58083.9180\n",
      "Epoch 727/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41644.2969 - val_loss: 58058.7578\n",
      "Epoch 728/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43395.2773 - val_loss: 57851.3711\n",
      "Epoch 729/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42326.5820 - val_loss: 57695.5781\n",
      "Epoch 730/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41326.7188 - val_loss: 57836.7070\n",
      "Epoch 731/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43280.9609 - val_loss: 58215.2305\n",
      "Epoch 732/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42217.5195 - val_loss: 57727.5391\n",
      "Epoch 733/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42728.5508 - val_loss: 57947.8203\n",
      "Epoch 734/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43293.4102 - val_loss: 57621.1797\n",
      "Epoch 735/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43704.6875 - val_loss: 57705.4648\n",
      "Epoch 736/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42716.4805 - val_loss: 57940.6602\n",
      "Epoch 737/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42828.3438 - val_loss: 58317.0625\n",
      "Epoch 738/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42577.3828 - val_loss: 58178.6836\n",
      "Epoch 739/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41872.9648 - val_loss: 58487.6836\n",
      "Epoch 740/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42790.1289 - val_loss: 57848.7500\n",
      "Epoch 741/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43070.2266 - val_loss: 57813.5078\n",
      "Epoch 742/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42962.1211 - val_loss: 57905.9688\n",
      "Epoch 743/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41723.6719 - val_loss: 58301.1172\n",
      "Epoch 744/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42100.8125 - val_loss: 58457.1562\n",
      "Epoch 745/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43258.1641 - val_loss: 58222.0664\n",
      "Epoch 746/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41931.8984 - val_loss: 58650.1133\n",
      "Epoch 747/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41990.0234 - val_loss: 58305.6406\n",
      "Epoch 748/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43886.5195 - val_loss: 58049.9453\n",
      "Epoch 749/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42878.6094 - val_loss: 57979.5391\n",
      "Epoch 750/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43062.6016 - val_loss: 57950.4609\n",
      "Epoch 751/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41631.7070 - val_loss: 58167.7969\n",
      "Epoch 752/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44152.9844 - val_loss: 57998.2539\n",
      "Epoch 753/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43231.5703 - val_loss: 58594.6875\n",
      "Epoch 754/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42276.0547 - val_loss: 58528.1797\n",
      "Epoch 755/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41893.6094 - val_loss: 58354.9609\n",
      "Epoch 756/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44391.0273 - val_loss: 57873.2031\n",
      "Epoch 757/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43044.3125 - val_loss: 58319.2812\n",
      "Epoch 758/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43132.8789 - val_loss: 57929.0117\n",
      "Epoch 759/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43059.0625 - val_loss: 57899.9766\n",
      "Epoch 760/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42263.3242 - val_loss: 57702.2422\n",
      "Epoch 761/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42394.6914 - val_loss: 57857.3984\n",
      "Epoch 762/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42182.5430 - val_loss: 58103.8398\n",
      "Epoch 763/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42673.0625 - val_loss: 57599.2227\n",
      "Epoch 764/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43708.0703 - val_loss: 57538.8438\n",
      "Epoch 765/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42118.4492 - val_loss: 57533.2305\n",
      "Epoch 766/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 40646.2383 - val_loss: 57659.9062\n",
      "Epoch 767/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42686.6562 - val_loss: 57726.6289\n",
      "Epoch 768/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41886.0664 - val_loss: 57890.0938\n",
      "Epoch 769/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42744.9844 - val_loss: 57944.4648\n",
      "Epoch 770/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41480.1523 - val_loss: 57627.2031\n",
      "Epoch 771/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42130.0430 - val_loss: 57576.5703\n",
      "Epoch 772/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41742.4727 - val_loss: 57660.8555\n",
      "Epoch 773/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42132.3281 - val_loss: 58145.0078\n",
      "Epoch 774/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43620.8750 - val_loss: 58285.2656\n",
      "Epoch 775/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42026.0117 - val_loss: 57601.2969\n",
      "Epoch 776/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41884.5195 - val_loss: 57556.3125\n",
      "Epoch 777/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43346.7695 - val_loss: 57487.3242\n",
      "Epoch 778/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42537.7617 - val_loss: 57695.6094\n",
      "Epoch 779/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41374.5469 - val_loss: 57934.3125\n",
      "Epoch 780/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41854.7422 - val_loss: 57739.2852\n",
      "Epoch 781/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41664.0547 - val_loss: 57642.1484\n",
      "Epoch 782/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43415.1719 - val_loss: 58176.9453\n",
      "Epoch 783/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43829.0938 - val_loss: 58544.1562\n",
      "Epoch 784/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 40971.2461 - val_loss: 57882.3789\n",
      "Epoch 785/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42802.0117 - val_loss: 57680.6523\n",
      "Epoch 786/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42123.0898 - val_loss: 57739.6094\n",
      "Epoch 787/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42944.1289 - val_loss: 57502.9492\n",
      "Epoch 788/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42060.6211 - val_loss: 57485.5703\n",
      "Epoch 789/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 40975.5938 - val_loss: 58260.8438\n",
      "Epoch 790/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41616.7500 - val_loss: 58770.2617\n",
      "Epoch 791/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42431.2188 - val_loss: 58540.8555\n",
      "Epoch 792/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41779.4727 - val_loss: 57635.2656\n",
      "Epoch 793/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42265.5391 - val_loss: 57767.6602\n",
      "Epoch 794/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43253.6289 - val_loss: 57598.0625\n",
      "Epoch 795/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42521.6758 - val_loss: 57747.2227\n",
      "Epoch 796/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42624.0859 - val_loss: 57950.3281\n",
      "Epoch 797/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43114.2188 - val_loss: 57611.3242\n",
      "Epoch 798/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42907.8125 - val_loss: 57628.3711\n",
      "Epoch 799/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41999.1367 - val_loss: 57740.7461\n",
      "Epoch 800/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 40907.8711 - val_loss: 58102.0742\n",
      "Epoch 801/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42488.8633 - val_loss: 58231.1875\n",
      "Epoch 802/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42496.2070 - val_loss: 58757.3672\n",
      "Epoch 803/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41784.7383 - val_loss: 58031.9141\n",
      "Epoch 804/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 40520.4062 - val_loss: 57689.3789\n",
      "Epoch 805/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43225.6836 - val_loss: 57804.0195\n",
      "Epoch 806/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42013.3438 - val_loss: 57777.0508\n",
      "Epoch 807/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42687.9102 - val_loss: 57614.3398\n",
      "Epoch 808/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41604.6523 - val_loss: 57938.6016\n",
      "Epoch 809/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41111.4883 - val_loss: 58158.5820\n",
      "Epoch 810/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42817.0898 - val_loss: 57930.6602\n",
      "Epoch 811/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42003.4258 - val_loss: 57716.9570\n",
      "Epoch 812/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41278.7695 - val_loss: 57753.7578\n",
      "Epoch 813/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42264.8945 - val_loss: 57800.8438\n",
      "Epoch 814/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42029.8711 - val_loss: 57740.9141\n",
      "Epoch 815/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42741.3477 - val_loss: 57759.8828\n",
      "Epoch 816/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42757.4844 - val_loss: 57681.7891\n",
      "Epoch 817/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41768.7539 - val_loss: 57773.1055\n",
      "Epoch 818/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43060.2500 - val_loss: 58281.9766\n",
      "Epoch 819/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42035.7344 - val_loss: 58211.5586\n",
      "Epoch 820/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42953.5000 - val_loss: 58223.7891\n",
      "Epoch 821/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42195.0625 - val_loss: 57890.5977\n",
      "Epoch 822/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41778.0312 - val_loss: 58004.5391\n",
      "Epoch 823/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43237.8984 - val_loss: 58322.3906\n",
      "Epoch 824/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41800.0547 - val_loss: 58206.5586\n",
      "Epoch 825/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42810.5078 - val_loss: 58028.7500\n",
      "Epoch 826/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42760.6328 - val_loss: 58626.1445\n",
      "Epoch 827/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43426.9844 - val_loss: 57867.6133\n",
      "Epoch 828/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42600.3672 - val_loss: 58502.5820\n",
      "Epoch 829/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41942.6328 - val_loss: 58742.5039\n",
      "Epoch 830/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42743.4375 - val_loss: 58613.0508\n",
      "Epoch 831/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42855.6211 - val_loss: 58449.2930\n",
      "Epoch 832/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43376.2227 - val_loss: 58325.1172\n",
      "Epoch 833/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41910.5000 - val_loss: 58047.7148\n",
      "Epoch 834/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41963.0703 - val_loss: 58171.1914\n",
      "Epoch 835/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41993.3281 - val_loss: 58114.4297\n",
      "Epoch 836/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42369.1289 - val_loss: 58645.4336\n",
      "Epoch 837/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41684.8008 - val_loss: 58666.2812\n",
      "Epoch 838/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42053.8672 - val_loss: 57711.4766\n",
      "Epoch 839/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42762.1016 - val_loss: 57641.6953\n",
      "Epoch 840/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42493.3047 - val_loss: 57653.0000\n",
      "Epoch 841/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42234.7344 - val_loss: 58356.0820\n",
      "Epoch 842/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42445.0117 - val_loss: 58056.1875\n",
      "Epoch 843/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 40862.7070 - val_loss: 57836.5898\n",
      "Epoch 844/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42990.5273 - val_loss: 57505.4648\n",
      "Epoch 845/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42509.4883 - val_loss: 58187.8203\n",
      "Epoch 846/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42222.8555 - val_loss: 58263.1875\n",
      "Epoch 847/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42644.3828 - val_loss: 57864.9375\n",
      "Epoch 848/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43201.3359 - val_loss: 57814.4961\n",
      "Epoch 849/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43058.5508 - val_loss: 57650.6836\n",
      "Epoch 850/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42473.9102 - val_loss: 57815.7656\n",
      "Epoch 851/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42142.1797 - val_loss: 57634.3555\n",
      "Epoch 852/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42025.8242 - val_loss: 57634.2500\n",
      "Epoch 853/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 40932.3594 - val_loss: 57980.7695\n",
      "Epoch 854/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43896.8672 - val_loss: 57766.8008\n",
      "Epoch 855/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42327.0859 - val_loss: 58363.5898\n",
      "Epoch 856/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41174.3750 - val_loss: 57886.4414\n",
      "Epoch 857/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42128.4219 - val_loss: 57625.2031\n",
      "Epoch 858/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41722.1641 - val_loss: 58217.8438\n",
      "Epoch 859/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41581.9727 - val_loss: 58367.6875\n",
      "Epoch 860/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43300.5820 - val_loss: 58515.3789\n",
      "Epoch 861/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42694.6016 - val_loss: 57994.0430\n",
      "Epoch 862/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41980.3086 - val_loss: 57851.7148\n",
      "Epoch 863/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43137.3828 - val_loss: 57740.1133\n",
      "Epoch 864/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42945.6797 - val_loss: 57779.9180\n",
      "Epoch 865/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43296.1680 - val_loss: 58035.3867\n",
      "Epoch 866/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41151.6523 - val_loss: 58241.8750\n",
      "Epoch 867/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 40601.6562 - val_loss: 57972.4766\n",
      "Epoch 868/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41017.1094 - val_loss: 58321.0391\n",
      "Epoch 869/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42779.9766 - val_loss: 58269.3867\n",
      "Epoch 870/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42979.2891 - val_loss: 57768.7148\n",
      "Epoch 871/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43789.0000 - val_loss: 57668.8711\n",
      "Epoch 872/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41872.4961 - val_loss: 58116.6719\n",
      "Epoch 873/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41836.0430 - val_loss: 58423.3125\n",
      "Epoch 874/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41644.0508 - val_loss: 58252.5586\n",
      "Epoch 875/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42434.6250 - val_loss: 57993.8867\n",
      "Epoch 876/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41705.3867 - val_loss: 57792.1133\n",
      "Epoch 877/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41999.5352 - val_loss: 57670.9805\n",
      "Epoch 878/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42898.6172 - val_loss: 57670.7578\n",
      "Epoch 879/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42683.6289 - val_loss: 57645.7578\n",
      "Epoch 880/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42481.7344 - val_loss: 57600.2109\n",
      "Epoch 881/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43189.4570 - val_loss: 58195.9805\n",
      "Epoch 882/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41388.3008 - val_loss: 57770.9023\n",
      "Epoch 883/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42130.8984 - val_loss: 57897.8320\n",
      "Epoch 884/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43817.6992 - val_loss: 57820.1875\n",
      "Epoch 885/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42430.4688 - val_loss: 57681.6523\n",
      "Epoch 886/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42990.8242 - val_loss: 57973.6875\n",
      "Epoch 887/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42066.6953 - val_loss: 57838.6289\n",
      "Epoch 888/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42767.4336 - val_loss: 57804.3555\n",
      "Epoch 889/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42669.0898 - val_loss: 57864.0391\n",
      "Epoch 890/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41797.1562 - val_loss: 58122.1875\n",
      "Epoch 891/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42599.4492 - val_loss: 57852.5078\n",
      "Epoch 892/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44383.8711 - val_loss: 58049.6641\n",
      "Epoch 893/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42325.5195 - val_loss: 57811.7266\n",
      "Epoch 894/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41858.0742 - val_loss: 58495.3125\n",
      "Epoch 895/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42991.3047 - val_loss: 58359.6875\n",
      "Epoch 896/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41791.1328 - val_loss: 58610.6523\n",
      "Epoch 897/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41824.3906 - val_loss: 58515.0391\n",
      "Epoch 898/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44052.8359 - val_loss: 58447.5352\n",
      "Epoch 899/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41574.6641 - val_loss: 58274.0234\n",
      "Epoch 900/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41934.8945 - val_loss: 57881.1797\n",
      "Epoch 901/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41752.3516 - val_loss: 58342.7656\n",
      "Epoch 902/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41687.3789 - val_loss: 57856.5898\n",
      "Epoch 903/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42346.4531 - val_loss: 57880.2227\n",
      "Epoch 904/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42337.5352 - val_loss: 57665.3672\n",
      "Epoch 905/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42991.8281 - val_loss: 57997.4922\n",
      "Epoch 906/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42340.8398 - val_loss: 58591.6211\n",
      "Epoch 907/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43088.8438 - val_loss: 58328.6719\n",
      "Epoch 908/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42544.1523 - val_loss: 58726.8242\n",
      "Epoch 909/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43478.8477 - val_loss: 58812.8945\n",
      "Epoch 910/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41974.7266 - val_loss: 58303.0938\n",
      "Epoch 911/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42373.9609 - val_loss: 58974.6328\n",
      "Epoch 912/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42429.9883 - val_loss: 58527.0820\n",
      "Epoch 913/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43023.0586 - val_loss: 58507.9062\n",
      "Epoch 914/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42573.0469 - val_loss: 58262.5586\n",
      "Epoch 915/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 40993.0352 - val_loss: 57653.6445\n",
      "Epoch 916/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42247.1367 - val_loss: 57574.0508\n",
      "Epoch 917/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41873.7383 - val_loss: 57472.9688\n",
      "Epoch 918/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44051.7383 - val_loss: 57571.7891\n",
      "Epoch 919/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42578.7422 - val_loss: 58183.2500\n",
      "Epoch 920/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41922.6016 - val_loss: 58136.9688\n",
      "Epoch 921/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42328.5586 - val_loss: 58905.5820\n",
      "Epoch 922/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43556.4180 - val_loss: 58654.7383\n",
      "Epoch 923/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42709.0117 - val_loss: 58404.3906\n",
      "Epoch 924/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42676.9414 - val_loss: 58408.6328\n",
      "Epoch 925/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43790.1094 - val_loss: 58114.2344\n",
      "Epoch 926/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43005.7305 - val_loss: 57774.2344\n",
      "Epoch 927/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42159.1523 - val_loss: 57657.3555\n",
      "Epoch 928/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43129.8281 - val_loss: 57838.1758\n",
      "Epoch 929/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42938.8359 - val_loss: 57753.6406\n",
      "Epoch 930/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 40685.1641 - val_loss: 58304.3398\n",
      "Epoch 931/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42083.2539 - val_loss: 58717.8750\n",
      "Epoch 932/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41714.8984 - val_loss: 58207.1367\n",
      "Epoch 933/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41513.6289 - val_loss: 58164.3477\n",
      "Epoch 934/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41084.6172 - val_loss: 58641.8398\n",
      "Epoch 935/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42277.2188 - val_loss: 57880.1289\n",
      "Epoch 936/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42356.8164 - val_loss: 57890.4453\n",
      "Epoch 937/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42749.0391 - val_loss: 57737.1250\n",
      "Epoch 938/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43171.4453 - val_loss: 57543.2812\n",
      "Epoch 939/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42245.4414 - val_loss: 57439.1172\n",
      "Epoch 940/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42142.8516 - val_loss: 57668.2500\n",
      "Epoch 941/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41359.7930 - val_loss: 57626.9805\n",
      "Epoch 942/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43605.3320 - val_loss: 57677.9922\n",
      "Epoch 943/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42487.0469 - val_loss: 58661.1914\n",
      "Epoch 944/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42114.1133 - val_loss: 58191.5781\n",
      "Epoch 945/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42198.3203 - val_loss: 58017.9375\n",
      "Epoch 946/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43218.9023 - val_loss: 58409.8633\n",
      "Epoch 947/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43263.5508 - val_loss: 57800.3984\n",
      "Epoch 948/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43239.7188 - val_loss: 58052.3555\n",
      "Epoch 949/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42264.2422 - val_loss: 57975.7891\n",
      "Epoch 950/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41250.6602 - val_loss: 57767.2031\n",
      "Epoch 951/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42231.6953 - val_loss: 57614.6289\n",
      "Epoch 952/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41342.6875 - val_loss: 57599.4531\n",
      "Epoch 953/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42346.9492 - val_loss: 57816.8555\n",
      "Epoch 954/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43881.3828 - val_loss: 57809.6602\n",
      "Epoch 955/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42641.5859 - val_loss: 58126.5352\n",
      "Epoch 956/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42713.5508 - val_loss: 57969.6445\n",
      "Epoch 957/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42911.3242 - val_loss: 57789.5078\n",
      "Epoch 958/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42876.4531 - val_loss: 57733.4844\n",
      "Epoch 959/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43030.9688 - val_loss: 57721.0234\n",
      "Epoch 960/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42543.4531 - val_loss: 57614.7070\n",
      "Epoch 961/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41968.4531 - val_loss: 57415.1445\n",
      "Epoch 962/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43066.9414 - val_loss: 57396.8242\n",
      "Epoch 963/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42187.9570 - val_loss: 57522.0312\n",
      "Epoch 964/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41069.2422 - val_loss: 57745.5547\n",
      "Epoch 965/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42696.4531 - val_loss: 58306.4844\n",
      "Epoch 966/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42729.8203 - val_loss: 57763.4102\n",
      "Epoch 967/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44332.3945 - val_loss: 57624.2930\n",
      "Epoch 968/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42470.3008 - val_loss: 57593.7578\n",
      "Epoch 969/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42845.6289 - val_loss: 57909.8008\n",
      "Epoch 970/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42722.8477 - val_loss: 58152.1602\n",
      "Epoch 971/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43317.2188 - val_loss: 57907.0508\n",
      "Epoch 972/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41386.3320 - val_loss: 57827.4727\n",
      "Epoch 973/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42606.9922 - val_loss: 57678.5391\n",
      "Epoch 974/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42511.5703 - val_loss: 58001.1055\n",
      "Epoch 975/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43034.2891 - val_loss: 57957.8945\n",
      "Epoch 976/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42789.9883 - val_loss: 57576.6836\n",
      "Epoch 977/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42270.9023 - val_loss: 57486.8125\n",
      "Epoch 978/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41351.5000 - val_loss: 57654.0547\n",
      "Epoch 979/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42309.1562 - val_loss: 57873.7344\n",
      "Epoch 980/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42760.5430 - val_loss: 58668.2617\n",
      "Epoch 981/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41888.9375 - val_loss: 58104.4727\n",
      "Epoch 982/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41481.7031 - val_loss: 58363.2422\n",
      "Epoch 983/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43690.2930 - val_loss: 58197.8828\n",
      "Epoch 984/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42144.3906 - val_loss: 57754.6094\n",
      "Epoch 985/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42696.2930 - val_loss: 57875.7188\n",
      "Epoch 986/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42552.3164 - val_loss: 57590.0234\n",
      "Epoch 987/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41904.2812 - val_loss: 57632.0312\n",
      "Epoch 988/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41896.9570 - val_loss: 57630.9023\n",
      "Epoch 989/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41862.6914 - val_loss: 57776.2500\n",
      "Epoch 990/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43803.4766 - val_loss: 57740.0859\n",
      "Epoch 991/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41361.5156 - val_loss: 57688.3281\n",
      "Epoch 992/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42875.9766 - val_loss: 57552.6953\n",
      "Epoch 993/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42113.6875 - val_loss: 57670.4102\n",
      "Epoch 994/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42465.4336 - val_loss: 57595.0000\n",
      "Epoch 995/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41096.8633 - val_loss: 57869.7695\n",
      "Epoch 996/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41935.9961 - val_loss: 57604.3242\n",
      "Epoch 997/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41258.6836 - val_loss: 57686.0000\n",
      "Epoch 998/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43841.2031 - val_loss: 58293.0234\n",
      "Epoch 999/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42331.9102 - val_loss: 58402.5547\n",
      "Epoch 1000/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42265.3789 - val_loss: 58490.3984\n",
      "Epoch 1001/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42819.3398 - val_loss: 57892.2852\n",
      "Epoch 1002/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42176.2852 - val_loss: 57770.6523\n",
      "Epoch 1003/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42448.0000 - val_loss: 57938.8516\n",
      "Epoch 1004/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42585.7383 - val_loss: 57806.0742\n",
      "Epoch 1005/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 40966.9844 - val_loss: 57664.1914\n",
      "Epoch 1006/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41590.6484 - val_loss: 57666.7695\n",
      "Epoch 1007/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42748.6523 - val_loss: 58286.5703\n",
      "Epoch 1008/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41585.0508 - val_loss: 57573.1758\n",
      "Epoch 1009/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43191.7656 - val_loss: 58033.3047\n",
      "Epoch 1010/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42748.7539 - val_loss: 58483.9922\n",
      "Epoch 1011/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43293.3984 - val_loss: 58075.3359\n",
      "Epoch 1012/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42828.0742 - val_loss: 57614.4961\n",
      "Epoch 1013/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41444.6484 - val_loss: 57777.9062\n",
      "Epoch 1014/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41578.9414 - val_loss: 58575.9805\n",
      "Epoch 1015/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42034.5742 - val_loss: 58527.8633\n",
      "Epoch 1016/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41847.0664 - val_loss: 58249.3711\n",
      "Epoch 1017/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42053.8477 - val_loss: 57396.5039\n",
      "Epoch 1018/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42436.7734 - val_loss: 57518.6641\n",
      "Epoch 1019/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41697.7188 - val_loss: 58574.4609\n",
      "Epoch 1020/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41171.3867 - val_loss: 58419.0820\n",
      "Epoch 1021/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43830.2500 - val_loss: 57668.3047\n",
      "Epoch 1022/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43125.6289 - val_loss: 57688.9609\n",
      "Epoch 1023/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41677.8711 - val_loss: 58210.3711\n",
      "Epoch 1024/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42715.1992 - val_loss: 58384.1133\n",
      "Epoch 1025/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41660.1836 - val_loss: 57554.4648\n",
      "Epoch 1026/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41287.8242 - val_loss: 57640.2109\n",
      "Epoch 1027/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42102.4609 - val_loss: 57536.0117\n",
      "Epoch 1028/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41520.2227 - val_loss: 57570.6953\n",
      "Epoch 1029/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41858.1641 - val_loss: 57664.9453\n",
      "Epoch 1030/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42558.9492 - val_loss: 57643.9570\n",
      "Epoch 1031/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41064.2969 - val_loss: 57564.6133\n",
      "Epoch 1032/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42649.6055 - val_loss: 57688.9375\n",
      "Epoch 1033/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42586.8594 - val_loss: 57949.4844\n",
      "Epoch 1034/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44117.3672 - val_loss: 57889.8828\n",
      "Epoch 1035/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41475.7305 - val_loss: 57665.5547\n",
      "Epoch 1036/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41097.4883 - val_loss: 58298.7148\n",
      "Epoch 1037/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41930.3320 - val_loss: 58004.8633\n",
      "Epoch 1038/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41552.4453 - val_loss: 57719.6523\n",
      "Epoch 1039/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41726.7383 - val_loss: 57812.3164\n",
      "Epoch 1040/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42040.2383 - val_loss: 57636.1250\n",
      "Epoch 1041/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42524.1914 - val_loss: 57858.4023\n",
      "Epoch 1042/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42895.2305 - val_loss: 57613.5156\n",
      "Epoch 1043/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42044.2461 - val_loss: 58348.6602\n",
      "Epoch 1044/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41921.0820 - val_loss: 58277.1133\n",
      "Epoch 1045/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42271.8086 - val_loss: 57850.2227\n",
      "Epoch 1046/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42849.6836 - val_loss: 57610.5273\n",
      "Epoch 1047/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42478.8242 - val_loss: 57488.8828\n",
      "Epoch 1048/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42734.3633 - val_loss: 57587.3047\n",
      "Epoch 1049/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41122.3789 - val_loss: 57870.4961\n",
      "Epoch 1050/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 44307.3828 - val_loss: 57635.8125\n",
      "Epoch 1051/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42727.4648 - val_loss: 57684.0547\n",
      "Epoch 1052/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43082.7852 - val_loss: 57881.1562\n",
      "Epoch 1053/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 40790.1445 - val_loss: 58055.6289\n",
      "Epoch 1054/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42359.5430 - val_loss: 57825.3047\n",
      "Epoch 1055/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 40281.9844 - val_loss: 57820.0508\n",
      "Epoch 1056/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41799.7578 - val_loss: 58039.0195\n",
      "Epoch 1057/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42100.6797 - val_loss: 58345.8945\n",
      "Epoch 1058/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41399.4336 - val_loss: 58447.3789\n",
      "Epoch 1059/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43044.2148 - val_loss: 58117.1250\n",
      "Epoch 1060/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42293.7500 - val_loss: 58081.2734\n",
      "Epoch 1061/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43237.6484 - val_loss: 58156.9258\n",
      "Epoch 1062/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41256.0469 - val_loss: 57608.0391\n",
      "Epoch 1063/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41729.8789 - val_loss: 58068.1445\n",
      "Epoch 1064/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41735.9062 - val_loss: 58599.8516\n",
      "Epoch 1065/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42701.4766 - val_loss: 57944.5391\n",
      "Epoch 1066/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43521.1797 - val_loss: 57537.2344\n",
      "Epoch 1067/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41561.2578 - val_loss: 57609.6445\n",
      "Epoch 1068/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41654.4805 - val_loss: 57807.9453\n",
      "Epoch 1069/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42688.3516 - val_loss: 58083.8516\n",
      "Epoch 1070/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43557.8945 - val_loss: 57790.4336\n",
      "Epoch 1071/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41323.3008 - val_loss: 58246.8516\n",
      "Epoch 1072/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41121.7031 - val_loss: 57835.1914\n",
      "Epoch 1073/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42261.8828 - val_loss: 57714.6602\n",
      "Epoch 1074/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43243.9453 - val_loss: 57851.5703\n",
      "Epoch 1075/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42805.6641 - val_loss: 57676.4766\n",
      "Epoch 1076/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42998.0859 - val_loss: 57535.5977\n",
      "Epoch 1077/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43168.5547 - val_loss: 57956.4922\n",
      "Epoch 1078/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41996.1016 - val_loss: 58082.1055\n",
      "Epoch 1079/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43423.5234 - val_loss: 58495.0508\n",
      "Epoch 1080/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41664.2812 - val_loss: 58451.5469\n",
      "Epoch 1081/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42477.8633 - val_loss: 58348.7812\n",
      "Epoch 1082/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41852.2383 - val_loss: 57932.4609\n",
      "Epoch 1083/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41500.8594 - val_loss: 57789.1484\n",
      "Epoch 1084/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41646.3008 - val_loss: 57678.1133\n",
      "Epoch 1085/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41924.0898 - val_loss: 57589.8125\n",
      "Epoch 1086/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42553.9766 - val_loss: 57501.8203\n",
      "Epoch 1087/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41564.4570 - val_loss: 58384.3711\n",
      "Epoch 1088/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42086.2734 - val_loss: 58362.7031\n",
      "Epoch 1089/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42617.1602 - val_loss: 57732.1602\n",
      "Epoch 1090/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41620.6445 - val_loss: 57676.4844\n",
      "Epoch 1091/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42315.6836 - val_loss: 57921.0430\n",
      "Epoch 1092/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41485.0156 - val_loss: 57476.0508\n",
      "Epoch 1093/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41441.5938 - val_loss: 57681.8945\n",
      "Epoch 1094/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41461.4766 - val_loss: 57735.4102\n",
      "Epoch 1095/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43480.6953 - val_loss: 57800.8945\n",
      "Epoch 1096/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 44008.5859 - val_loss: 57643.4102\n",
      "Epoch 1097/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41886.0586 - val_loss: 57594.2930\n",
      "Epoch 1098/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43622.0117 - val_loss: 58076.9258\n",
      "Epoch 1099/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42494.6016 - val_loss: 58152.2812\n",
      "Epoch 1100/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42204.5312 - val_loss: 57646.7695\n",
      "Epoch 1101/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42470.9844 - val_loss: 57641.3711\n",
      "Epoch 1102/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42117.9922 - val_loss: 58615.5391\n",
      "Epoch 1103/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 40644.5430 - val_loss: 58046.8633\n",
      "Epoch 1104/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41640.7539 - val_loss: 57964.0391\n",
      "Epoch 1105/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43805.8711 - val_loss: 58073.5352\n",
      "Epoch 1106/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42312.4062 - val_loss: 58516.4766\n",
      "Epoch 1107/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42870.0117 - val_loss: 58395.5391\n",
      "Epoch 1108/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41739.3828 - val_loss: 58045.9922\n",
      "Epoch 1109/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42417.9336 - val_loss: 58094.9805\n",
      "Epoch 1110/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41179.5117 - val_loss: 57656.3359\n",
      "Epoch 1111/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42141.6094 - val_loss: 57648.9805\n",
      "Epoch 1112/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42062.4219 - val_loss: 58547.1133\n",
      "Epoch 1113/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43345.7305 - val_loss: 58149.5078\n",
      "Epoch 1114/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41723.3008 - val_loss: 57898.2500\n",
      "Epoch 1115/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41116.6797 - val_loss: 58326.9609\n",
      "Epoch 1116/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 40441.0430 - val_loss: 59300.2930\n",
      "Epoch 1117/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42657.1914 - val_loss: 58776.4180\n",
      "Epoch 1118/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43442.1016 - val_loss: 58179.3398\n",
      "Epoch 1119/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41740.4648 - val_loss: 57866.2539\n",
      "Epoch 1120/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42812.3281 - val_loss: 58163.9023\n",
      "Epoch 1121/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41966.8867 - val_loss: 57956.3672\n",
      "Epoch 1122/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41217.3398 - val_loss: 57621.0547\n",
      "Epoch 1123/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43061.7188 - val_loss: 57482.4922\n",
      "Epoch 1124/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41891.4883 - val_loss: 57439.4766\n",
      "Epoch 1125/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42039.3477 - val_loss: 57648.4102\n",
      "Epoch 1126/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42136.2969 - val_loss: 58247.7695\n",
      "Epoch 1127/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42449.6055 - val_loss: 58028.7773\n",
      "Epoch 1128/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42453.4570 - val_loss: 58275.2930\n",
      "Epoch 1129/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42079.1914 - val_loss: 57901.3711\n",
      "Epoch 1130/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42590.9844 - val_loss: 57725.9258\n",
      "Epoch 1131/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42654.5117 - val_loss: 57923.7891\n",
      "Epoch 1132/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42678.8711 - val_loss: 57922.7070\n",
      "Epoch 1133/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43061.6836 - val_loss: 57620.0195\n",
      "Epoch 1134/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43258.7969 - val_loss: 58322.1250\n",
      "Epoch 1135/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41693.7148 - val_loss: 58703.5781\n",
      "Epoch 1136/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41107.6016 - val_loss: 58371.7070\n",
      "Epoch 1137/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41090.5352 - val_loss: 58527.1562\n",
      "Epoch 1138/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43463.0664 - val_loss: 57951.0312\n",
      "Epoch 1139/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42681.0781 - val_loss: 57860.5820\n",
      "Epoch 1140/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42784.9805 - val_loss: 58386.8555\n",
      "Epoch 1141/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41630.7305 - val_loss: 57608.4414\n",
      "Epoch 1142/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42162.3672 - val_loss: 57840.9375\n",
      "Epoch 1143/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42794.3438 - val_loss: 57991.6211\n",
      "Epoch 1144/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41743.5547 - val_loss: 58247.7148\n",
      "Epoch 1145/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42667.6602 - val_loss: 58143.2305\n",
      "Epoch 1146/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42857.7617 - val_loss: 57632.2539\n",
      "Epoch 1147/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42621.9414 - val_loss: 57632.0859\n",
      "Epoch 1148/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42474.8164 - val_loss: 57736.1133\n",
      "Epoch 1149/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42502.0547 - val_loss: 57891.3555\n",
      "Epoch 1150/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41597.0898 - val_loss: 57995.4180\n",
      "Epoch 1151/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42770.0898 - val_loss: 57741.6875\n",
      "Epoch 1152/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42062.6328 - val_loss: 58488.8438\n",
      "Epoch 1153/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42322.3984 - val_loss: 58714.8125\n",
      "Epoch 1154/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41308.3594 - val_loss: 57965.0508\n",
      "Epoch 1155/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42072.1914 - val_loss: 57802.1914\n",
      "Epoch 1156/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42216.2500 - val_loss: 57892.3398\n",
      "Epoch 1157/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41750.0547 - val_loss: 57914.5156\n",
      "Epoch 1158/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43404.7617 - val_loss: 57591.6094\n",
      "Epoch 1159/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41217.6328 - val_loss: 57558.1562\n",
      "Epoch 1160/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41576.5664 - val_loss: 57506.1484\n",
      "Epoch 1161/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42694.1602 - val_loss: 57492.1250\n",
      "Epoch 1162/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41901.3398 - val_loss: 57659.1172\n",
      "Epoch 1163/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41205.4336 - val_loss: 58758.5977\n",
      "Epoch 1164/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41811.3789 - val_loss: 58856.1562\n",
      "Epoch 1165/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42308.6484 - val_loss: 58840.8711\n",
      "Epoch 1166/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41903.3242 - val_loss: 58039.7188\n",
      "Epoch 1167/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42626.1211 - val_loss: 57857.6523\n",
      "Epoch 1168/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42923.7383 - val_loss: 57955.8438\n",
      "Epoch 1169/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41344.6016 - val_loss: 57629.0859\n",
      "Epoch 1170/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42059.5547 - val_loss: 57655.6953\n",
      "Epoch 1171/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43583.2539 - val_loss: 57499.0430\n",
      "Epoch 1172/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41920.3281 - val_loss: 58156.6953\n",
      "Epoch 1173/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42391.2422 - val_loss: 57602.6875\n",
      "Epoch 1174/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41522.5117 - val_loss: 57627.3867\n",
      "Epoch 1175/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42209.4336 - val_loss: 57641.8633\n",
      "Epoch 1176/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41502.4648 - val_loss: 57674.7461\n",
      "Epoch 1177/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41936.1406 - val_loss: 58217.9609\n",
      "Epoch 1178/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42870.5938 - val_loss: 57555.4727\n",
      "Epoch 1179/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42474.7266 - val_loss: 57796.3281\n",
      "Epoch 1180/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41758.7305 - val_loss: 58142.6641\n",
      "Epoch 1181/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41945.9922 - val_loss: 57877.5273\n",
      "Epoch 1182/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41416.9844 - val_loss: 58090.8008\n",
      "Epoch 1183/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41832.1211 - val_loss: 58774.9492\n",
      "Epoch 1184/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42307.7617 - val_loss: 57613.4102\n",
      "Epoch 1185/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42215.4414 - val_loss: 57405.0625\n",
      "Epoch 1186/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41969.8086 - val_loss: 57764.0391\n",
      "Epoch 1187/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43277.7812 - val_loss: 58301.6328\n",
      "Epoch 1188/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 41456.6797 - val_loss: 57789.4023\n",
      "Epoch 1189/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42430.6172 - val_loss: 57487.8086\n",
      "Epoch 1190/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42961.2461 - val_loss: 57408.3047\n",
      "Epoch 1191/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 43044.9688 - val_loss: 57432.0664\n",
      "Epoch 1192/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42366.5078 - val_loss: 58103.1445\n",
      "Epoch 1193/1200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 42349.1719 - val_loss: 57937.8633\n",
      "Epoch 1194/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42012.3555 - val_loss: 57727.1562\n",
      "Epoch 1195/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42305.5547 - val_loss: 57584.6133\n",
      "Epoch 1196/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42501.6406 - val_loss: 57612.9023\n",
      "Epoch 1197/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41810.5898 - val_loss: 57967.4844\n",
      "Epoch 1198/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 41346.1797 - val_loss: 57932.7148\n",
      "Epoch 1199/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 42152.8789 - val_loss: 58059.8242\n",
      "Epoch 1200/1200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 43880.3711 - val_loss: 58184.2109\n",
      "INFO:tensorflow:Assets written to: c:\\programowanie\\ml_streamlit\\models\\s_class\\assets\n",
      "Epoch 1/1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\proso\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\data_adapter.py:1699: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 7ms/step - loss: 114676.7891 - val_loss: 126108.8672\n",
      "Epoch 2/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 114652.1250 - val_loss: 126045.7656\n",
      "Epoch 3/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 114490.2188 - val_loss: 125720.1484\n",
      "Epoch 4/1200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 113872.1328 - val_loss: 124661.1016\n",
      "Epoch 5/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 112156.2266 - val_loss: 122060.0234\n",
      "Epoch 6/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 108516.6953 - val_loss: 117109.1719\n",
      "Epoch 7/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 102615.7188 - val_loss: 110245.8281\n",
      "Epoch 8/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 95093.3906 - val_loss: 101774.3125\n",
      "Epoch 9/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 86332.5703 - val_loss: 90489.8828\n",
      "Epoch 10/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 74697.0781 - val_loss: 75619.4375\n",
      "Epoch 11/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 60351.2539 - val_loss: 58261.0117\n",
      "Epoch 12/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 47198.8438 - val_loss: 45767.0664\n",
      "Epoch 13/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 40749.8047 - val_loss: 41039.9883\n",
      "Epoch 14/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 38100.9648 - val_loss: 39046.4805\n",
      "Epoch 15/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 36875.5000 - val_loss: 37494.6562\n",
      "Epoch 16/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 35733.0039 - val_loss: 36391.1250\n",
      "Epoch 17/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 35078.8477 - val_loss: 35504.1797\n",
      "Epoch 18/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 34861.7188 - val_loss: 34832.7188\n",
      "Epoch 19/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 34268.9922 - val_loss: 34239.1055\n",
      "Epoch 20/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 33645.1484 - val_loss: 33817.5508\n",
      "Epoch 21/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 32914.5195 - val_loss: 33211.7188\n",
      "Epoch 22/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 32521.1836 - val_loss: 32812.9805\n",
      "Epoch 23/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 32474.5586 - val_loss: 32482.8320\n",
      "Epoch 24/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 32090.7109 - val_loss: 32144.4512\n",
      "Epoch 25/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 31741.4180 - val_loss: 31855.9141\n",
      "Epoch 26/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 31436.1523 - val_loss: 31552.8809\n",
      "Epoch 27/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 31369.5566 - val_loss: 31342.6094\n",
      "Epoch 28/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 30953.4219 - val_loss: 31138.8320\n",
      "Epoch 29/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 31003.2852 - val_loss: 30931.2070\n",
      "Epoch 30/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 30359.8125 - val_loss: 30756.3066\n",
      "Epoch 31/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 30454.4531 - val_loss: 30575.3594\n",
      "Epoch 32/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 30169.0625 - val_loss: 30372.0918\n",
      "Epoch 33/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 29775.9941 - val_loss: 30195.8750\n",
      "Epoch 34/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 30008.9102 - val_loss: 30075.5234\n",
      "Epoch 35/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 29532.4746 - val_loss: 29913.9473\n",
      "Epoch 36/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 29778.4824 - val_loss: 29772.6250\n",
      "Epoch 37/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 29608.1953 - val_loss: 29627.3457\n",
      "Epoch 38/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 29613.6875 - val_loss: 29479.6836\n",
      "Epoch 39/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 29359.1484 - val_loss: 29371.2441\n",
      "Epoch 40/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 28833.8926 - val_loss: 29276.8613\n",
      "Epoch 41/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 28400.9355 - val_loss: 29239.8887\n",
      "Epoch 42/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 29090.0547 - val_loss: 29021.9863\n",
      "Epoch 43/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 29320.8770 - val_loss: 28971.0254\n",
      "Epoch 44/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 28535.3398 - val_loss: 28903.1621\n",
      "Epoch 45/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 28386.6914 - val_loss: 28790.7695\n",
      "Epoch 46/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 28332.5703 - val_loss: 28717.0371\n",
      "Epoch 47/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 28249.1934 - val_loss: 28613.0820\n",
      "Epoch 48/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 27843.4023 - val_loss: 28590.1094\n",
      "Epoch 49/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 27953.6152 - val_loss: 28468.4004\n",
      "Epoch 50/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 27769.4707 - val_loss: 28387.2871\n",
      "Epoch 51/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 27978.5625 - val_loss: 28321.8984\n",
      "Epoch 52/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 27812.6465 - val_loss: 28240.8652\n",
      "Epoch 53/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 27967.3906 - val_loss: 28192.4082\n",
      "Epoch 54/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 27969.0430 - val_loss: 28132.8223\n",
      "Epoch 55/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 27627.2441 - val_loss: 28073.6055\n",
      "Epoch 56/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 27568.2988 - val_loss: 28021.5684\n",
      "Epoch 57/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 27418.6523 - val_loss: 27970.6445\n",
      "Epoch 58/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 26906.9395 - val_loss: 27890.6816\n",
      "Epoch 59/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 27662.3750 - val_loss: 27821.5332\n",
      "Epoch 60/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 27057.4648 - val_loss: 27735.9082\n",
      "Epoch 61/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 27421.3281 - val_loss: 27687.9805\n",
      "Epoch 62/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26874.6191 - val_loss: 27630.1719\n",
      "Epoch 63/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 27035.6641 - val_loss: 27533.0840\n",
      "Epoch 64/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 27196.5898 - val_loss: 27524.3379\n",
      "Epoch 65/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 27070.3652 - val_loss: 27458.5156\n",
      "Epoch 66/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26779.9492 - val_loss: 27440.8555\n",
      "Epoch 67/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 27434.1660 - val_loss: 27344.9141\n",
      "Epoch 68/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26942.7773 - val_loss: 27266.7988\n",
      "Epoch 69/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26933.1992 - val_loss: 27193.5117\n",
      "Epoch 70/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26812.5098 - val_loss: 27154.2480\n",
      "Epoch 71/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26717.7207 - val_loss: 27123.1680\n",
      "Epoch 72/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26333.8223 - val_loss: 27060.2363\n",
      "Epoch 73/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26474.5117 - val_loss: 27043.0156\n",
      "Epoch 74/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26590.5879 - val_loss: 26962.4961\n",
      "Epoch 75/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26177.7812 - val_loss: 26898.7266\n",
      "Epoch 76/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26186.3359 - val_loss: 26853.2520\n",
      "Epoch 77/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26797.4844 - val_loss: 26812.8750\n",
      "Epoch 78/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26173.7715 - val_loss: 26794.2031\n",
      "Epoch 79/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26295.6113 - val_loss: 26717.9043\n",
      "Epoch 80/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26193.9805 - val_loss: 26698.7578\n",
      "Epoch 81/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26320.5352 - val_loss: 26661.8496\n",
      "Epoch 82/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26443.8281 - val_loss: 26598.6211\n",
      "Epoch 83/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26018.5664 - val_loss: 26643.1973\n",
      "Epoch 84/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26441.8145 - val_loss: 26547.1641\n",
      "Epoch 85/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26648.5918 - val_loss: 26508.6309\n",
      "Epoch 86/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26390.7070 - val_loss: 26467.0059\n",
      "Epoch 87/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25912.2793 - val_loss: 26434.1484\n",
      "Epoch 88/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26247.0371 - val_loss: 26463.1504\n",
      "Epoch 89/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26368.3828 - val_loss: 26345.4219\n",
      "Epoch 90/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26049.6816 - val_loss: 26326.5391\n",
      "Epoch 91/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 26160.0605 - val_loss: 26280.8281\n",
      "Epoch 92/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25814.6504 - val_loss: 26263.5293\n",
      "Epoch 93/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25167.0820 - val_loss: 26217.0371\n",
      "Epoch 94/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25947.8594 - val_loss: 26156.3750\n",
      "Epoch 95/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25728.2969 - val_loss: 26124.3691\n",
      "Epoch 96/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25877.1250 - val_loss: 26083.8730\n",
      "Epoch 97/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25813.9199 - val_loss: 26059.9004\n",
      "Epoch 98/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25181.8203 - val_loss: 26049.4668\n",
      "Epoch 99/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 26176.4922 - val_loss: 26007.0059\n",
      "Epoch 100/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25783.3047 - val_loss: 26006.6797\n",
      "Epoch 101/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25697.7227 - val_loss: 25960.2285\n",
      "Epoch 102/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25496.3789 - val_loss: 25913.9805\n",
      "Epoch 103/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25549.2656 - val_loss: 25894.6074\n",
      "Epoch 104/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25451.4316 - val_loss: 25861.2793\n",
      "Epoch 105/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24884.8301 - val_loss: 25819.9805\n",
      "Epoch 106/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25699.3516 - val_loss: 25777.6699\n",
      "Epoch 107/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25201.3496 - val_loss: 25766.0156\n",
      "Epoch 108/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25299.8242 - val_loss: 25715.3906\n",
      "Epoch 109/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25168.0547 - val_loss: 25705.1543\n",
      "Epoch 110/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25130.8906 - val_loss: 25697.2871\n",
      "Epoch 111/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25244.9395 - val_loss: 25663.1426\n",
      "Epoch 112/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25198.4375 - val_loss: 25604.0293\n",
      "Epoch 113/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25195.8438 - val_loss: 25586.0449\n",
      "Epoch 114/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25105.9414 - val_loss: 25537.1191\n",
      "Epoch 115/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24841.7773 - val_loss: 25503.6406\n",
      "Epoch 116/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25299.6211 - val_loss: 25487.8672\n",
      "Epoch 117/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24966.0645 - val_loss: 25444.3320\n",
      "Epoch 118/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25026.2383 - val_loss: 25420.0020\n",
      "Epoch 119/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 24876.4883 - val_loss: 25393.6816\n",
      "Epoch 120/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25042.3379 - val_loss: 25349.2773\n",
      "Epoch 121/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 25270.4277 - val_loss: 25336.4395\n",
      "Epoch 122/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25067.5625 - val_loss: 25291.7930\n",
      "Epoch 123/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24791.1660 - val_loss: 25281.0977\n",
      "Epoch 124/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25634.5352 - val_loss: 25237.3750\n",
      "Epoch 125/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25139.4121 - val_loss: 25249.0352\n",
      "Epoch 126/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24728.6934 - val_loss: 25200.1855\n",
      "Epoch 127/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25002.7871 - val_loss: 25161.9727\n",
      "Epoch 128/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25148.3828 - val_loss: 25162.9863\n",
      "Epoch 129/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24763.0742 - val_loss: 25112.6016\n",
      "Epoch 130/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24891.2832 - val_loss: 25132.9941\n",
      "Epoch 131/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24862.7637 - val_loss: 25071.7031\n",
      "Epoch 132/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24745.5547 - val_loss: 25027.4043\n",
      "Epoch 133/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 24638.0410 - val_loss: 25041.3164\n",
      "Epoch 134/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 24812.0879 - val_loss: 25014.6934\n",
      "Epoch 135/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24129.9688 - val_loss: 24946.2109\n",
      "Epoch 136/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25070.5449 - val_loss: 24947.4746\n",
      "Epoch 137/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24565.2656 - val_loss: 24999.4629\n",
      "Epoch 138/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 25344.9277 - val_loss: 24907.8555\n",
      "Epoch 139/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24821.4609 - val_loss: 24852.0898\n",
      "Epoch 140/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24732.2148 - val_loss: 24828.4043\n",
      "Epoch 141/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24248.2305 - val_loss: 24794.8340\n",
      "Epoch 142/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24365.8789 - val_loss: 24782.5059\n",
      "Epoch 143/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24596.9004 - val_loss: 24747.4434\n",
      "Epoch 144/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24360.5801 - val_loss: 24750.2344\n",
      "Epoch 145/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24682.2656 - val_loss: 24696.1973\n",
      "Epoch 146/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24252.8496 - val_loss: 24683.8926\n",
      "Epoch 147/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24471.6309 - val_loss: 24664.7090\n",
      "Epoch 148/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24822.5605 - val_loss: 24655.5391\n",
      "Epoch 149/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24848.8574 - val_loss: 24626.4824\n",
      "Epoch 150/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23898.0586 - val_loss: 24598.5332\n",
      "Epoch 151/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24324.2910 - val_loss: 24618.0566\n",
      "Epoch 152/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24386.8691 - val_loss: 24605.6035\n",
      "Epoch 153/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24900.7559 - val_loss: 24560.6484\n",
      "Epoch 154/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 24412.2930 - val_loss: 24522.9297\n",
      "Epoch 155/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24155.0801 - val_loss: 24503.1328\n",
      "Epoch 156/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24376.1836 - val_loss: 24485.9355\n",
      "Epoch 157/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24764.2383 - val_loss: 24466.4609\n",
      "Epoch 158/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24477.6426 - val_loss: 24455.7969\n",
      "Epoch 159/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24626.3086 - val_loss: 24431.4141\n",
      "Epoch 160/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24420.1406 - val_loss: 24415.8633\n",
      "Epoch 161/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23891.6699 - val_loss: 24382.8379\n",
      "Epoch 162/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24717.6133 - val_loss: 24361.1895\n",
      "Epoch 163/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24542.9395 - val_loss: 24346.4277\n",
      "Epoch 164/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24213.4648 - val_loss: 24347.1582\n",
      "Epoch 165/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24400.8496 - val_loss: 24309.7402\n",
      "Epoch 166/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24264.3574 - val_loss: 24299.9746\n",
      "Epoch 167/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24870.0801 - val_loss: 24265.3828\n",
      "Epoch 168/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24308.6797 - val_loss: 24253.8672\n",
      "Epoch 169/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24213.0977 - val_loss: 24246.6406\n",
      "Epoch 170/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24821.1992 - val_loss: 24224.9473\n",
      "Epoch 171/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24733.8613 - val_loss: 24197.6211\n",
      "Epoch 172/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24332.9785 - val_loss: 24176.4473\n",
      "Epoch 173/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24121.4043 - val_loss: 24149.6094\n",
      "Epoch 174/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23539.2480 - val_loss: 24126.1387\n",
      "Epoch 175/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23586.1426 - val_loss: 24144.3906\n",
      "Epoch 176/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 24246.6777 - val_loss: 24094.0000\n",
      "Epoch 177/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24003.5918 - val_loss: 24064.6328\n",
      "Epoch 178/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24189.4766 - val_loss: 24050.1328\n",
      "Epoch 179/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24528.1426 - val_loss: 24054.9590\n",
      "Epoch 180/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24220.2070 - val_loss: 24010.9141\n",
      "Epoch 181/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24111.8359 - val_loss: 23994.1973\n",
      "Epoch 182/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23804.9258 - val_loss: 23973.2754\n",
      "Epoch 183/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24597.7207 - val_loss: 23955.2129\n",
      "Epoch 184/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24104.5234 - val_loss: 23933.0469\n",
      "Epoch 185/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24221.3281 - val_loss: 23973.9785\n",
      "Epoch 186/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23884.0898 - val_loss: 23923.3066\n",
      "Epoch 187/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23954.8594 - val_loss: 23872.0059\n",
      "Epoch 188/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23850.2969 - val_loss: 23845.6719\n",
      "Epoch 189/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24494.0527 - val_loss: 23821.8594\n",
      "Epoch 190/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24220.7930 - val_loss: 23813.8984\n",
      "Epoch 191/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23604.3223 - val_loss: 23797.5410\n",
      "Epoch 192/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23835.4570 - val_loss: 23771.9980\n",
      "Epoch 193/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23698.1270 - val_loss: 23772.5898\n",
      "Epoch 194/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24017.4551 - val_loss: 23719.0156\n",
      "Epoch 195/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24070.0879 - val_loss: 23694.5410\n",
      "Epoch 196/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24057.4648 - val_loss: 23717.6602\n",
      "Epoch 197/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24164.6133 - val_loss: 23700.0566\n",
      "Epoch 198/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24112.3535 - val_loss: 23646.3047\n",
      "Epoch 199/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23900.5762 - val_loss: 23625.7930\n",
      "Epoch 200/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23891.4766 - val_loss: 23600.7910\n",
      "Epoch 201/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24083.7305 - val_loss: 23629.6816\n",
      "Epoch 202/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23975.6875 - val_loss: 23587.9961\n",
      "Epoch 203/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 23443.4492 - val_loss: 23562.1152\n",
      "Epoch 204/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23735.1367 - val_loss: 23569.2266\n",
      "Epoch 205/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23554.8242 - val_loss: 23559.5449\n",
      "Epoch 206/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23816.7832 - val_loss: 23548.1953\n",
      "Epoch 207/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23711.4922 - val_loss: 23507.4609\n",
      "Epoch 208/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24324.8086 - val_loss: 23453.9121\n",
      "Epoch 209/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23713.4180 - val_loss: 23495.2129\n",
      "Epoch 210/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23639.1914 - val_loss: 23457.4961\n",
      "Epoch 211/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23616.6152 - val_loss: 23437.3047\n",
      "Epoch 212/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23733.8125 - val_loss: 23383.4609\n",
      "Epoch 213/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23323.6328 - val_loss: 23359.8320\n",
      "Epoch 214/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23676.8887 - val_loss: 23353.8633\n",
      "Epoch 215/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23456.1191 - val_loss: 23307.6719\n",
      "Epoch 216/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23506.9473 - val_loss: 23344.5742\n",
      "Epoch 217/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24041.1230 - val_loss: 23302.7070\n",
      "Epoch 218/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23412.7363 - val_loss: 23300.3496\n",
      "Epoch 219/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23806.2695 - val_loss: 23282.4160\n",
      "Epoch 220/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23963.8984 - val_loss: 23244.6895\n",
      "Epoch 221/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23515.0234 - val_loss: 23225.4238\n",
      "Epoch 222/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 23827.7598 - val_loss: 23269.2246\n",
      "Epoch 223/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23451.0996 - val_loss: 23206.4961\n",
      "Epoch 224/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23147.4766 - val_loss: 23187.5938\n",
      "Epoch 225/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23519.9102 - val_loss: 23167.8145\n",
      "Epoch 226/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23639.6133 - val_loss: 23139.6309\n",
      "Epoch 227/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23449.6309 - val_loss: 23134.3438\n",
      "Epoch 228/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23822.8203 - val_loss: 23075.5430\n",
      "Epoch 229/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23370.2930 - val_loss: 23068.6660\n",
      "Epoch 230/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23347.7832 - val_loss: 23077.1836\n",
      "Epoch 231/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23508.3965 - val_loss: 23061.5703\n",
      "Epoch 232/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23393.5254 - val_loss: 23049.8984\n",
      "Epoch 233/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23476.7773 - val_loss: 23072.7031\n",
      "Epoch 234/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23189.0293 - val_loss: 23000.5996\n",
      "Epoch 235/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23459.2324 - val_loss: 22968.3301\n",
      "Epoch 236/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22747.5000 - val_loss: 22980.1621\n",
      "Epoch 237/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23329.1855 - val_loss: 23004.6895\n",
      "Epoch 238/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23494.0918 - val_loss: 22977.6836\n",
      "Epoch 239/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23759.7148 - val_loss: 23009.9180\n",
      "Epoch 240/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 24086.1016 - val_loss: 22884.4004\n",
      "Epoch 241/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23139.4238 - val_loss: 22889.7559\n",
      "Epoch 242/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23166.7012 - val_loss: 22866.8457\n",
      "Epoch 243/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23214.6094 - val_loss: 22822.2891\n",
      "Epoch 244/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23308.9941 - val_loss: 22836.8340\n",
      "Epoch 245/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23177.2285 - val_loss: 22793.7891\n",
      "Epoch 246/1200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 23348.1484 - val_loss: 22771.5117\n",
      "Epoch 247/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23051.0703 - val_loss: 22810.1387\n",
      "Epoch 248/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23449.3223 - val_loss: 22732.4805\n",
      "Epoch 249/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22616.2812 - val_loss: 22726.2891\n",
      "Epoch 250/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23133.3887 - val_loss: 22739.4141\n",
      "Epoch 251/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22816.6719 - val_loss: 22733.2988\n",
      "Epoch 252/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22946.2441 - val_loss: 22744.2109\n",
      "Epoch 253/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23694.3496 - val_loss: 22677.2715\n",
      "Epoch 254/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23186.7676 - val_loss: 22658.6367\n",
      "Epoch 255/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23331.9180 - val_loss: 22644.1562\n",
      "Epoch 256/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22707.7402 - val_loss: 22626.8184\n",
      "Epoch 257/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22796.0566 - val_loss: 22569.3516\n",
      "Epoch 258/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23089.6582 - val_loss: 22561.4688\n",
      "Epoch 259/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22834.6094 - val_loss: 22536.3105\n",
      "Epoch 260/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22968.6426 - val_loss: 22544.7930\n",
      "Epoch 261/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22919.7422 - val_loss: 22528.1934\n",
      "Epoch 262/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23408.4043 - val_loss: 22487.0879\n",
      "Epoch 263/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22928.3223 - val_loss: 22464.9121\n",
      "Epoch 264/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23467.5371 - val_loss: 22488.0449\n",
      "Epoch 265/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23183.5508 - val_loss: 22506.3008\n",
      "Epoch 266/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22642.6562 - val_loss: 22450.4160\n",
      "Epoch 267/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22365.8086 - val_loss: 22454.8066\n",
      "Epoch 268/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22700.9180 - val_loss: 22413.2227\n",
      "Epoch 269/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23010.4395 - val_loss: 22393.8223\n",
      "Epoch 270/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23263.8945 - val_loss: 22350.2617\n",
      "Epoch 271/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22835.5430 - val_loss: 22383.8828\n",
      "Epoch 272/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23099.5000 - val_loss: 22329.5703\n",
      "Epoch 273/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23289.0215 - val_loss: 22326.4355\n",
      "Epoch 274/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23253.8672 - val_loss: 22348.2969\n",
      "Epoch 275/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22491.8906 - val_loss: 22303.5742\n",
      "Epoch 276/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23458.7988 - val_loss: 22274.5469\n",
      "Epoch 277/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22844.3730 - val_loss: 22311.7051\n",
      "Epoch 278/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22928.7891 - val_loss: 22273.3945\n",
      "Epoch 279/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22394.9785 - val_loss: 22312.2285\n",
      "Epoch 280/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23106.6836 - val_loss: 22236.3301\n",
      "Epoch 281/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23158.4082 - val_loss: 22238.2559\n",
      "Epoch 282/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22864.1484 - val_loss: 22202.1738\n",
      "Epoch 283/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22781.8750 - val_loss: 22182.9121\n",
      "Epoch 284/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22240.6602 - val_loss: 22174.1387\n",
      "Epoch 285/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22240.3398 - val_loss: 22165.1113\n",
      "Epoch 286/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22142.9727 - val_loss: 22151.0137\n",
      "Epoch 287/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22984.6934 - val_loss: 22145.0293\n",
      "Epoch 288/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22656.2969 - val_loss: 22113.3691\n",
      "Epoch 289/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22574.1230 - val_loss: 22096.1816\n",
      "Epoch 290/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 23176.5762 - val_loss: 22105.9375\n",
      "Epoch 291/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22122.9766 - val_loss: 22081.8340\n",
      "Epoch 292/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22936.4609 - val_loss: 22084.5098\n",
      "Epoch 293/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22422.4004 - val_loss: 22053.6992\n",
      "Epoch 294/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22727.1797 - val_loss: 22021.5508\n",
      "Epoch 295/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22449.1816 - val_loss: 22027.6504\n",
      "Epoch 296/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22922.3965 - val_loss: 22018.2559\n",
      "Epoch 297/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22668.5430 - val_loss: 22011.6641\n",
      "Epoch 298/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22486.0391 - val_loss: 22005.5332\n",
      "Epoch 299/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22842.7266 - val_loss: 21987.9434\n",
      "Epoch 300/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22921.2070 - val_loss: 22031.6738\n",
      "Epoch 301/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22424.7852 - val_loss: 21949.6895\n",
      "Epoch 302/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22324.1992 - val_loss: 21933.9941\n",
      "Epoch 303/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22488.1172 - val_loss: 21909.1738\n",
      "Epoch 304/1200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 22139.6211 - val_loss: 21889.6465\n",
      "Epoch 305/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22489.2520 - val_loss: 21885.2812\n",
      "Epoch 306/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22793.1797 - val_loss: 21871.0957\n",
      "Epoch 307/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22858.8320 - val_loss: 21860.2852\n",
      "Epoch 308/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22285.4805 - val_loss: 21840.6504\n",
      "Epoch 309/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22337.7148 - val_loss: 21828.3770\n",
      "Epoch 310/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22057.4590 - val_loss: 21781.4688\n",
      "Epoch 311/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22455.9629 - val_loss: 21846.9883\n",
      "Epoch 312/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22071.0254 - val_loss: 21781.6914\n",
      "Epoch 313/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22471.7422 - val_loss: 21750.9551\n",
      "Epoch 314/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22001.3750 - val_loss: 21715.2070\n",
      "Epoch 315/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22443.5742 - val_loss: 21722.4941\n",
      "Epoch 316/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22316.7910 - val_loss: 21741.6191\n",
      "Epoch 317/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22757.0312 - val_loss: 21709.2969\n",
      "Epoch 318/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22547.3477 - val_loss: 21710.2637\n",
      "Epoch 319/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22729.4453 - val_loss: 21685.2715\n",
      "Epoch 320/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22173.6152 - val_loss: 21685.2109\n",
      "Epoch 321/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22352.6445 - val_loss: 21724.6465\n",
      "Epoch 322/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22672.1191 - val_loss: 21623.6426\n",
      "Epoch 323/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22349.0996 - val_loss: 21602.5645\n",
      "Epoch 324/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22153.0176 - val_loss: 21830.4941\n",
      "Epoch 325/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22175.2168 - val_loss: 21701.7754\n",
      "Epoch 326/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22131.5078 - val_loss: 21606.8711\n",
      "Epoch 327/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22375.6719 - val_loss: 21547.5059\n",
      "Epoch 328/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22142.0176 - val_loss: 21530.4160\n",
      "Epoch 329/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22487.1582 - val_loss: 21654.1230\n",
      "Epoch 330/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21912.2246 - val_loss: 21535.2168\n",
      "Epoch 331/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22392.5156 - val_loss: 21532.0918\n",
      "Epoch 332/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22179.3281 - val_loss: 21563.1816\n",
      "Epoch 333/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21941.4238 - val_loss: 21496.8164\n",
      "Epoch 334/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22388.9688 - val_loss: 21470.9707\n",
      "Epoch 335/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22132.5723 - val_loss: 21509.8242\n",
      "Epoch 336/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 21633.2812 - val_loss: 21519.1816\n",
      "Epoch 337/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22371.3711 - val_loss: 21585.4941\n",
      "Epoch 338/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22292.8516 - val_loss: 21714.3672\n",
      "Epoch 339/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21969.2422 - val_loss: 21470.8086\n",
      "Epoch 340/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22230.7598 - val_loss: 21463.1270\n",
      "Epoch 341/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22152.9941 - val_loss: 21364.3945\n",
      "Epoch 342/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22039.6777 - val_loss: 21408.8887\n",
      "Epoch 343/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22171.9062 - val_loss: 21365.5977\n",
      "Epoch 344/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22149.2969 - val_loss: 21360.4531\n",
      "Epoch 345/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21859.2793 - val_loss: 21332.0488\n",
      "Epoch 346/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21350.3594 - val_loss: 21347.5898\n",
      "Epoch 347/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21847.5625 - val_loss: 21347.4688\n",
      "Epoch 348/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21884.8574 - val_loss: 21299.1816\n",
      "Epoch 349/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22280.7832 - val_loss: 21288.1680\n",
      "Epoch 350/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22009.7070 - val_loss: 21306.8594\n",
      "Epoch 351/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21697.6328 - val_loss: 21418.8105\n",
      "Epoch 352/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22032.2773 - val_loss: 21219.9043\n",
      "Epoch 353/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22614.6836 - val_loss: 21226.0430\n",
      "Epoch 354/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22148.7363 - val_loss: 21251.8926\n",
      "Epoch 355/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21920.9180 - val_loss: 21243.6738\n",
      "Epoch 356/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21907.1133 - val_loss: 21172.1055\n",
      "Epoch 357/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21951.6543 - val_loss: 21143.7090\n",
      "Epoch 358/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22016.4082 - val_loss: 21217.6074\n",
      "Epoch 359/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21610.3750 - val_loss: 21195.2871\n",
      "Epoch 360/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21513.6250 - val_loss: 21334.0586\n",
      "Epoch 361/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21975.5332 - val_loss: 21218.0625\n",
      "Epoch 362/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22219.2344 - val_loss: 21249.9434\n",
      "Epoch 363/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22000.8555 - val_loss: 21228.0566\n",
      "Epoch 364/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21729.1426 - val_loss: 21095.1523\n",
      "Epoch 365/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21946.1016 - val_loss: 21097.0996\n",
      "Epoch 366/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21826.4492 - val_loss: 21083.9941\n",
      "Epoch 367/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21620.1602 - val_loss: 21152.0605\n",
      "Epoch 368/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21981.8809 - val_loss: 21100.7910\n",
      "Epoch 369/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21775.3945 - val_loss: 21051.0156\n",
      "Epoch 370/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21888.5527 - val_loss: 21089.3125\n",
      "Epoch 371/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21925.1348 - val_loss: 21053.8398\n",
      "Epoch 372/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21551.8145 - val_loss: 21059.0312\n",
      "Epoch 373/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21309.9336 - val_loss: 20967.5156\n",
      "Epoch 374/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21745.9180 - val_loss: 21112.2129\n",
      "Epoch 375/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21371.1660 - val_loss: 20969.2656\n",
      "Epoch 376/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21616.4863 - val_loss: 21100.1562\n",
      "Epoch 377/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21674.0137 - val_loss: 20944.8105\n",
      "Epoch 378/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21815.3594 - val_loss: 21047.2324\n",
      "Epoch 379/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21412.0273 - val_loss: 20962.2754\n",
      "Epoch 380/1200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 21942.7402 - val_loss: 21014.0449\n",
      "Epoch 381/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21357.2227 - val_loss: 20880.1074\n",
      "Epoch 382/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22057.0098 - val_loss: 20938.1016\n",
      "Epoch 383/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21369.7305 - val_loss: 20927.3008\n",
      "Epoch 384/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21155.5020 - val_loss: 20980.0859\n",
      "Epoch 385/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22224.4492 - val_loss: 20924.2441\n",
      "Epoch 386/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21702.8906 - val_loss: 20898.7871\n",
      "Epoch 387/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21673.4414 - val_loss: 20866.5391\n",
      "Epoch 388/1200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 21711.4023 - val_loss: 20811.1348\n",
      "Epoch 389/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21532.7598 - val_loss: 21166.1836\n",
      "Epoch 390/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21771.9824 - val_loss: 20975.1738\n",
      "Epoch 391/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21749.6992 - val_loss: 20806.3125\n",
      "Epoch 392/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21505.7930 - val_loss: 20756.0078\n",
      "Epoch 393/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21845.8926 - val_loss: 20742.6680\n",
      "Epoch 394/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21238.0312 - val_loss: 20705.8086\n",
      "Epoch 395/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21516.6797 - val_loss: 20820.6191\n",
      "Epoch 396/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21993.9258 - val_loss: 20755.2051\n",
      "Epoch 397/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21499.9922 - val_loss: 20661.2910\n",
      "Epoch 398/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21143.6504 - val_loss: 20637.9492\n",
      "Epoch 399/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20921.8008 - val_loss: 20812.8262\n",
      "Epoch 400/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22022.6660 - val_loss: 20709.1484\n",
      "Epoch 401/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21646.2285 - val_loss: 20757.7305\n",
      "Epoch 402/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21526.1855 - val_loss: 20697.5781\n",
      "Epoch 403/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21193.7129 - val_loss: 20602.4492\n",
      "Epoch 404/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21919.1582 - val_loss: 20801.7754\n",
      "Epoch 405/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21863.7207 - val_loss: 20557.0469\n",
      "Epoch 406/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21597.4160 - val_loss: 20600.9824\n",
      "Epoch 407/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 22080.1543 - val_loss: 20626.7910\n",
      "Epoch 408/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21240.1445 - val_loss: 20597.2227\n",
      "Epoch 409/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21455.8359 - val_loss: 20530.1270\n",
      "Epoch 410/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21098.0605 - val_loss: 20620.5371\n",
      "Epoch 411/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21434.9941 - val_loss: 20470.7812\n",
      "Epoch 412/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21569.2637 - val_loss: 20497.5625\n",
      "Epoch 413/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20890.2012 - val_loss: 20542.7754\n",
      "Epoch 414/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21759.6113 - val_loss: 20441.3281\n",
      "Epoch 415/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21555.1777 - val_loss: 20575.9941\n",
      "Epoch 416/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21212.1074 - val_loss: 20452.1914\n",
      "Epoch 417/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21333.6582 - val_loss: 20425.2461\n",
      "Epoch 418/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21302.0898 - val_loss: 20412.6758\n",
      "Epoch 419/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21445.0195 - val_loss: 20421.9434\n",
      "Epoch 420/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20646.4277 - val_loss: 20523.7383\n",
      "Epoch 421/1200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 21107.7168 - val_loss: 20421.8496\n",
      "Epoch 422/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20882.2051 - val_loss: 20360.0879\n",
      "Epoch 423/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21298.2812 - val_loss: 20382.4902\n",
      "Epoch 424/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21287.8828 - val_loss: 20392.4746\n",
      "Epoch 425/1200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 21056.4570 - val_loss: 20419.4941\n",
      "Epoch 426/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21598.1250 - val_loss: 20322.9648\n",
      "Epoch 427/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21169.8301 - val_loss: 20338.9688\n",
      "Epoch 428/1200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 21268.6719 - val_loss: 20335.5371\n",
      "Epoch 429/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20970.5859 - val_loss: 20329.8203\n",
      "Epoch 430/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20707.0859 - val_loss: 20381.5254\n",
      "Epoch 431/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20993.4805 - val_loss: 20339.5879\n",
      "Epoch 432/1200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 21483.6133 - val_loss: 20362.4395\n",
      "Epoch 433/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21464.1875 - val_loss: 20314.0820\n",
      "Epoch 434/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20653.9629 - val_loss: 20267.4883\n",
      "Epoch 435/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21253.1777 - val_loss: 20358.4141\n",
      "Epoch 436/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21321.8359 - val_loss: 20273.8594\n",
      "Epoch 437/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20544.9785 - val_loss: 20325.8906\n",
      "Epoch 438/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21329.0234 - val_loss: 20244.8711\n",
      "Epoch 439/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20885.9727 - val_loss: 20259.9688\n",
      "Epoch 440/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20716.0020 - val_loss: 20216.3496\n",
      "Epoch 441/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21611.8086 - val_loss: 20261.1055\n",
      "Epoch 442/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20912.0410 - val_loss: 20191.0391\n",
      "Epoch 443/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21304.4434 - val_loss: 20187.4805\n",
      "Epoch 444/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20811.3105 - val_loss: 20231.9062\n",
      "Epoch 445/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20939.0938 - val_loss: 20222.9043\n",
      "Epoch 446/1200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 21395.1582 - val_loss: 20239.8926\n",
      "Epoch 447/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21051.4434 - val_loss: 20271.8809\n",
      "Epoch 448/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21260.5098 - val_loss: 20232.1367\n",
      "Epoch 449/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20604.3516 - val_loss: 20192.3691\n",
      "Epoch 450/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20831.9316 - val_loss: 20178.7266\n",
      "Epoch 451/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21327.4473 - val_loss: 20226.9180\n",
      "Epoch 452/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21286.8672 - val_loss: 20323.4902\n",
      "Epoch 453/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20699.7734 - val_loss: 20146.2578\n",
      "Epoch 454/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20723.0215 - val_loss: 20107.3379\n",
      "Epoch 455/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20779.5449 - val_loss: 20116.2520\n",
      "Epoch 456/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20458.3359 - val_loss: 20072.9609\n",
      "Epoch 457/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20641.7109 - val_loss: 20092.1738\n",
      "Epoch 458/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20797.7852 - val_loss: 20101.5996\n",
      "Epoch 459/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20837.7090 - val_loss: 20090.5801\n",
      "Epoch 460/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21021.5566 - val_loss: 20107.1348\n",
      "Epoch 461/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20906.1465 - val_loss: 20089.4648\n",
      "Epoch 462/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21424.6934 - val_loss: 20088.7539\n",
      "Epoch 463/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20970.5449 - val_loss: 20108.5410\n",
      "Epoch 464/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20775.6699 - val_loss: 20085.7012\n",
      "Epoch 465/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20972.9707 - val_loss: 20103.1934\n",
      "Epoch 466/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20414.1406 - val_loss: 20048.4082\n",
      "Epoch 467/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20461.5605 - val_loss: 20064.4746\n",
      "Epoch 468/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21094.2070 - val_loss: 20064.4434\n",
      "Epoch 469/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20502.0586 - val_loss: 20067.2695\n",
      "Epoch 470/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20878.0000 - val_loss: 20054.6855\n",
      "Epoch 471/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21096.1055 - val_loss: 20073.1133\n",
      "Epoch 472/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20855.2930 - val_loss: 20025.8457\n",
      "Epoch 473/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20938.7500 - val_loss: 19972.2188\n",
      "Epoch 474/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20330.9551 - val_loss: 19993.3652\n",
      "Epoch 475/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20997.2207 - val_loss: 20014.4180\n",
      "Epoch 476/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21015.2266 - val_loss: 19933.5000\n",
      "Epoch 477/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20802.0645 - val_loss: 19931.3184\n",
      "Epoch 478/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20758.5352 - val_loss: 20030.2500\n",
      "Epoch 479/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20779.2852 - val_loss: 20017.8262\n",
      "Epoch 480/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20755.9062 - val_loss: 20006.6016\n",
      "Epoch 481/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21186.9688 - val_loss: 19946.8223\n",
      "Epoch 482/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20749.8125 - val_loss: 19950.9043\n",
      "Epoch 483/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21037.8789 - val_loss: 20002.2969\n",
      "Epoch 484/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20583.6055 - val_loss: 20033.0781\n",
      "Epoch 485/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20411.4121 - val_loss: 19994.2754\n",
      "Epoch 486/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20667.6191 - val_loss: 19949.4355\n",
      "Epoch 487/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20662.8672 - val_loss: 19972.7129\n",
      "Epoch 488/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20376.0723 - val_loss: 19940.2285\n",
      "Epoch 489/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20181.0234 - val_loss: 19991.8047\n",
      "Epoch 490/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20320.0176 - val_loss: 19941.8242\n",
      "Epoch 491/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20510.5547 - val_loss: 19904.0410\n",
      "Epoch 492/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20514.0195 - val_loss: 19922.9531\n",
      "Epoch 493/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20757.2246 - val_loss: 19898.1719\n",
      "Epoch 494/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20302.3770 - val_loss: 19865.2246\n",
      "Epoch 495/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20299.1055 - val_loss: 19969.2090\n",
      "Epoch 496/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20595.1523 - val_loss: 19896.4258\n",
      "Epoch 497/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20794.7715 - val_loss: 19958.5039\n",
      "Epoch 498/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20567.1660 - val_loss: 19939.1895\n",
      "Epoch 499/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20298.4277 - val_loss: 19904.4629\n",
      "Epoch 500/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20425.6523 - val_loss: 19887.3223\n",
      "Epoch 501/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20468.2832 - val_loss: 19907.4082\n",
      "Epoch 502/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20231.0762 - val_loss: 19939.7559\n",
      "Epoch 503/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20654.3926 - val_loss: 19896.7969\n",
      "Epoch 504/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20194.6348 - val_loss: 19883.0371\n",
      "Epoch 505/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20585.3066 - val_loss: 19868.7129\n",
      "Epoch 506/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20148.1035 - val_loss: 19866.6953\n",
      "Epoch 507/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20692.4492 - val_loss: 19874.3887\n",
      "Epoch 508/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20967.5430 - val_loss: 19810.3379\n",
      "Epoch 509/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20657.7344 - val_loss: 19847.3555\n",
      "Epoch 510/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20673.7344 - val_loss: 19917.0312\n",
      "Epoch 511/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20357.8984 - val_loss: 19925.1562\n",
      "Epoch 512/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20385.2812 - val_loss: 19853.0840\n",
      "Epoch 513/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21083.3867 - val_loss: 19884.8203\n",
      "Epoch 514/1200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 20166.5078 - val_loss: 19872.0547\n",
      "Epoch 515/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20565.3516 - val_loss: 19861.5996\n",
      "Epoch 516/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20566.3770 - val_loss: 19841.5781\n",
      "Epoch 517/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20167.0703 - val_loss: 19859.2227\n",
      "Epoch 518/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20542.2480 - val_loss: 19952.4160\n",
      "Epoch 519/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20374.6719 - val_loss: 19912.7832\n",
      "Epoch 520/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20444.7363 - val_loss: 19851.0117\n",
      "Epoch 521/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20460.4609 - val_loss: 19876.2812\n",
      "Epoch 522/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20329.8359 - val_loss: 20008.2520\n",
      "Epoch 523/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20422.7969 - val_loss: 19815.9805\n",
      "Epoch 524/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20441.8594 - val_loss: 19908.4727\n",
      "Epoch 525/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20293.5938 - val_loss: 20053.8965\n",
      "Epoch 526/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20318.8242 - val_loss: 20043.1133\n",
      "Epoch 527/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20314.8301 - val_loss: 19887.0586\n",
      "Epoch 528/1200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 20101.6660 - val_loss: 19892.5352\n",
      "Epoch 529/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20285.1875 - val_loss: 19838.1074\n",
      "Epoch 530/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20616.0273 - val_loss: 19817.2676\n",
      "Epoch 531/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20216.7910 - val_loss: 19877.6016\n",
      "Epoch 532/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20479.8652 - val_loss: 19875.0039\n",
      "Epoch 533/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20271.8125 - val_loss: 19847.3809\n",
      "Epoch 534/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20266.9297 - val_loss: 19906.6230\n",
      "Epoch 535/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20427.3496 - val_loss: 19885.3203\n",
      "Epoch 536/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20918.7227 - val_loss: 19927.1855\n",
      "Epoch 537/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20486.1719 - val_loss: 19849.4707\n",
      "Epoch 538/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20707.9824 - val_loss: 19796.3105\n",
      "Epoch 539/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20105.9102 - val_loss: 19756.6152\n",
      "Epoch 540/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20558.6895 - val_loss: 19815.9609\n",
      "Epoch 541/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20353.5801 - val_loss: 19826.7578\n",
      "Epoch 542/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20615.0117 - val_loss: 19780.1758\n",
      "Epoch 543/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20230.0586 - val_loss: 19800.6445\n",
      "Epoch 544/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20269.8105 - val_loss: 19833.2129\n",
      "Epoch 545/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20070.4766 - val_loss: 19801.0977\n",
      "Epoch 546/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20514.3047 - val_loss: 19843.0762\n",
      "Epoch 547/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19912.3262 - val_loss: 19795.7559\n",
      "Epoch 548/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20206.2695 - val_loss: 19798.1875\n",
      "Epoch 549/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20480.6680 - val_loss: 19732.8398\n",
      "Epoch 550/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20639.5469 - val_loss: 19751.5781\n",
      "Epoch 551/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20083.7559 - val_loss: 19748.8574\n",
      "Epoch 552/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20200.3906 - val_loss: 19836.0020\n",
      "Epoch 553/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20576.5977 - val_loss: 19823.3906\n",
      "Epoch 554/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20562.8730 - val_loss: 19899.4609\n",
      "Epoch 555/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20169.9902 - val_loss: 19820.0059\n",
      "Epoch 556/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20427.5605 - val_loss: 19769.2305\n",
      "Epoch 557/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20466.4180 - val_loss: 19747.7012\n",
      "Epoch 558/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20429.1816 - val_loss: 19829.9824\n",
      "Epoch 559/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20825.1055 - val_loss: 19818.8379\n",
      "Epoch 560/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20292.4395 - val_loss: 19808.6367\n",
      "Epoch 561/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20363.8145 - val_loss: 19737.8926\n",
      "Epoch 562/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20435.0020 - val_loss: 19808.3379\n",
      "Epoch 563/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20126.0273 - val_loss: 19840.7031\n",
      "Epoch 564/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19782.9297 - val_loss: 19834.1641\n",
      "Epoch 565/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20212.5156 - val_loss: 19817.1504\n",
      "Epoch 566/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20016.9453 - val_loss: 19826.5762\n",
      "Epoch 567/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20280.2559 - val_loss: 19903.5723\n",
      "Epoch 568/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19905.4805 - val_loss: 19831.3359\n",
      "Epoch 569/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20493.0508 - val_loss: 19816.3926\n",
      "Epoch 570/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20421.1953 - val_loss: 19849.2441\n",
      "Epoch 571/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20396.9785 - val_loss: 19809.1953\n",
      "Epoch 572/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20225.9004 - val_loss: 19828.5254\n",
      "Epoch 573/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20457.7832 - val_loss: 19788.4316\n",
      "Epoch 574/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20591.0957 - val_loss: 19804.9199\n",
      "Epoch 575/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19955.1699 - val_loss: 19752.2070\n",
      "Epoch 576/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20782.8203 - val_loss: 19793.8594\n",
      "Epoch 577/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20512.8418 - val_loss: 19963.3184\n",
      "Epoch 578/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20691.2832 - val_loss: 19812.2051\n",
      "Epoch 579/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20293.7422 - val_loss: 19863.8613\n",
      "Epoch 580/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20077.0938 - val_loss: 19715.6797\n",
      "Epoch 581/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19769.1641 - val_loss: 19864.2969\n",
      "Epoch 582/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20280.1660 - val_loss: 19828.6113\n",
      "Epoch 583/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20592.8574 - val_loss: 19769.9512\n",
      "Epoch 584/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20500.9609 - val_loss: 19796.4219\n",
      "Epoch 585/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20444.7520 - val_loss: 19831.0430\n",
      "Epoch 586/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20791.0195 - val_loss: 19821.5352\n",
      "Epoch 587/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20550.7109 - val_loss: 19808.4082\n",
      "Epoch 588/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19438.7090 - val_loss: 19770.0469\n",
      "Epoch 589/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20557.2754 - val_loss: 19754.0625\n",
      "Epoch 590/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20339.9043 - val_loss: 19758.1875\n",
      "Epoch 591/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20286.5859 - val_loss: 20146.0801\n",
      "Epoch 592/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20849.3809 - val_loss: 19869.5566\n",
      "Epoch 593/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20471.2441 - val_loss: 19901.3691\n",
      "Epoch 594/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19896.2812 - val_loss: 19779.4961\n",
      "Epoch 595/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20277.4160 - val_loss: 19781.3379\n",
      "Epoch 596/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21161.0820 - val_loss: 19903.8281\n",
      "Epoch 597/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20471.9824 - val_loss: 19974.9727\n",
      "Epoch 598/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20047.9980 - val_loss: 19772.4258\n",
      "Epoch 599/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19932.9102 - val_loss: 19860.4316\n",
      "Epoch 600/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20523.1094 - val_loss: 19829.8379\n",
      "Epoch 601/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20092.4297 - val_loss: 19853.2559\n",
      "Epoch 602/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20235.6738 - val_loss: 19812.3945\n",
      "Epoch 603/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19823.1152 - val_loss: 19788.1484\n",
      "Epoch 604/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20020.8965 - val_loss: 19750.4414\n",
      "Epoch 605/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20656.1328 - val_loss: 19781.9707\n",
      "Epoch 606/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20171.2344 - val_loss: 19779.2246\n",
      "Epoch 607/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20289.2930 - val_loss: 19837.4746\n",
      "Epoch 608/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20653.8047 - val_loss: 19855.3594\n",
      "Epoch 609/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20035.8203 - val_loss: 19812.9219\n",
      "Epoch 610/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19965.4980 - val_loss: 19845.4160\n",
      "Epoch 611/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20447.3926 - val_loss: 19900.9980\n",
      "Epoch 612/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19632.8340 - val_loss: 19783.2598\n",
      "Epoch 613/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21056.7676 - val_loss: 19846.1348\n",
      "Epoch 614/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20120.0898 - val_loss: 19744.1465\n",
      "Epoch 615/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20783.3184 - val_loss: 19850.9316\n",
      "Epoch 616/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20368.1582 - val_loss: 19835.9160\n",
      "Epoch 617/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20300.8652 - val_loss: 19823.5664\n",
      "Epoch 618/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19769.0430 - val_loss: 19751.6465\n",
      "Epoch 619/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20249.0879 - val_loss: 19747.3516\n",
      "Epoch 620/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20039.4023 - val_loss: 19755.4609\n",
      "Epoch 621/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20072.9316 - val_loss: 19762.8711\n",
      "Epoch 622/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20167.1621 - val_loss: 19801.2891\n",
      "Epoch 623/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19926.2246 - val_loss: 19768.8320\n",
      "Epoch 624/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20251.1992 - val_loss: 19747.6191\n",
      "Epoch 625/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20309.2969 - val_loss: 19813.7949\n",
      "Epoch 626/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20091.2363 - val_loss: 19747.2031\n",
      "Epoch 627/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20224.6953 - val_loss: 19777.7617\n",
      "Epoch 628/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19988.0332 - val_loss: 19738.9883\n",
      "Epoch 629/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20032.8379 - val_loss: 19790.8047\n",
      "Epoch 630/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20519.3535 - val_loss: 19766.1113\n",
      "Epoch 631/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19985.0527 - val_loss: 19780.6855\n",
      "Epoch 632/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20187.4590 - val_loss: 19824.0449\n",
      "Epoch 633/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20068.8574 - val_loss: 19761.2129\n",
      "Epoch 634/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20353.9707 - val_loss: 19810.5684\n",
      "Epoch 635/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19903.0273 - val_loss: 19843.7012\n",
      "Epoch 636/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20192.6211 - val_loss: 19759.2207\n",
      "Epoch 637/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19956.2129 - val_loss: 19819.9766\n",
      "Epoch 638/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20406.8301 - val_loss: 19830.7988\n",
      "Epoch 639/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19947.0879 - val_loss: 19800.6133\n",
      "Epoch 640/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20308.3047 - val_loss: 19769.0879\n",
      "Epoch 641/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20345.9785 - val_loss: 19762.8145\n",
      "Epoch 642/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20479.4141 - val_loss: 19766.0684\n",
      "Epoch 643/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20183.2383 - val_loss: 19770.4570\n",
      "Epoch 644/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20398.6348 - val_loss: 19711.7949\n",
      "Epoch 645/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20042.1660 - val_loss: 19715.5371\n",
      "Epoch 646/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20520.8418 - val_loss: 19767.9531\n",
      "Epoch 647/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20625.8926 - val_loss: 19742.2188\n",
      "Epoch 648/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20246.2695 - val_loss: 19720.5664\n",
      "Epoch 649/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20735.3359 - val_loss: 19734.4473\n",
      "Epoch 650/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20433.5508 - val_loss: 19740.7129\n",
      "Epoch 651/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19955.4199 - val_loss: 19732.2246\n",
      "Epoch 652/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20321.1816 - val_loss: 19703.4844\n",
      "Epoch 653/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20372.0996 - val_loss: 19759.3574\n",
      "Epoch 654/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20451.0234 - val_loss: 19703.1621\n",
      "Epoch 655/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20506.9824 - val_loss: 19779.1367\n",
      "Epoch 656/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20528.1523 - val_loss: 19694.6914\n",
      "Epoch 657/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19989.3262 - val_loss: 19676.5332\n",
      "Epoch 658/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20202.8320 - val_loss: 19731.2500\n",
      "Epoch 659/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20215.1133 - val_loss: 19673.2285\n",
      "Epoch 660/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20230.6152 - val_loss: 19690.7129\n",
      "Epoch 661/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20783.3262 - val_loss: 19709.3340\n",
      "Epoch 662/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20518.1992 - val_loss: 19732.6133\n",
      "Epoch 663/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20774.7266 - val_loss: 19677.5059\n",
      "Epoch 664/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19850.0410 - val_loss: 19765.4883\n",
      "Epoch 665/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20100.7266 - val_loss: 19704.9316\n",
      "Epoch 666/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20448.8262 - val_loss: 19675.3379\n",
      "Epoch 667/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20545.6035 - val_loss: 19753.9160\n",
      "Epoch 668/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20377.6133 - val_loss: 19747.8457\n",
      "Epoch 669/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19918.2754 - val_loss: 19700.0703\n",
      "Epoch 670/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20457.8105 - val_loss: 19701.5156\n",
      "Epoch 671/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20287.7285 - val_loss: 19667.0312\n",
      "Epoch 672/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20593.3516 - val_loss: 19715.5020\n",
      "Epoch 673/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20487.5371 - val_loss: 19668.4102\n",
      "Epoch 674/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20334.2695 - val_loss: 19689.0586\n",
      "Epoch 675/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20121.1016 - val_loss: 19751.7070\n",
      "Epoch 676/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20314.5762 - val_loss: 19677.9785\n",
      "Epoch 677/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20374.8008 - val_loss: 19726.6543\n",
      "Epoch 678/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20368.8281 - val_loss: 19713.6836\n",
      "Epoch 679/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19937.1328 - val_loss: 19716.5215\n",
      "Epoch 680/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20296.7988 - val_loss: 19710.2891\n",
      "Epoch 681/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20000.1328 - val_loss: 19772.4922\n",
      "Epoch 682/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20243.2441 - val_loss: 19704.1797\n",
      "Epoch 683/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20300.8730 - val_loss: 19817.0137\n",
      "Epoch 684/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20557.6191 - val_loss: 19693.8633\n",
      "Epoch 685/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20397.6660 - val_loss: 19812.7773\n",
      "Epoch 686/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19824.6953 - val_loss: 19674.3281\n",
      "Epoch 687/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20058.0215 - val_loss: 19759.2109\n",
      "Epoch 688/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20181.0000 - val_loss: 19826.3301\n",
      "Epoch 689/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20069.5605 - val_loss: 19768.2891\n",
      "Epoch 690/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20469.8672 - val_loss: 19677.9629\n",
      "Epoch 691/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19638.6641 - val_loss: 19720.0078\n",
      "Epoch 692/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19897.5332 - val_loss: 19691.7852\n",
      "Epoch 693/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19767.1641 - val_loss: 19684.8008\n",
      "Epoch 694/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20073.9922 - val_loss: 19767.9336\n",
      "Epoch 695/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20482.7695 - val_loss: 19693.4707\n",
      "Epoch 696/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20369.6074 - val_loss: 19715.4844\n",
      "Epoch 697/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20448.3066 - val_loss: 19720.1348\n",
      "Epoch 698/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20099.3711 - val_loss: 19692.5840\n",
      "Epoch 699/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19976.5879 - val_loss: 19721.9824\n",
      "Epoch 700/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19612.1387 - val_loss: 19717.5957\n",
      "Epoch 701/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20295.4609 - val_loss: 19711.1719\n",
      "Epoch 702/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20302.4277 - val_loss: 19869.9941\n",
      "Epoch 703/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20306.0684 - val_loss: 19707.1562\n",
      "Epoch 704/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20436.0508 - val_loss: 19732.5156\n",
      "Epoch 705/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20044.0488 - val_loss: 19794.3379\n",
      "Epoch 706/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20622.8730 - val_loss: 19664.5410\n",
      "Epoch 707/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19997.9414 - val_loss: 19650.0723\n",
      "Epoch 708/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19857.8164 - val_loss: 19630.1641\n",
      "Epoch 709/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20000.7656 - val_loss: 19770.6133\n",
      "Epoch 710/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20301.4902 - val_loss: 19671.7129\n",
      "Epoch 711/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20487.3457 - val_loss: 19727.1133\n",
      "Epoch 712/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20527.1387 - val_loss: 19709.1289\n",
      "Epoch 713/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20087.0098 - val_loss: 19700.7070\n",
      "Epoch 714/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20310.1504 - val_loss: 19684.2031\n",
      "Epoch 715/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20753.1387 - val_loss: 19688.8867\n",
      "Epoch 716/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20547.8906 - val_loss: 19704.7012\n",
      "Epoch 717/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20488.4766 - val_loss: 19769.9395\n",
      "Epoch 718/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20307.3281 - val_loss: 19686.4844\n",
      "Epoch 719/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19755.7930 - val_loss: 19677.5527\n",
      "Epoch 720/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20134.6719 - val_loss: 19713.9434\n",
      "Epoch 721/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20315.2812 - val_loss: 19688.7754\n",
      "Epoch 722/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20026.0430 - val_loss: 19702.8633\n",
      "Epoch 723/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19881.6504 - val_loss: 19698.1523\n",
      "Epoch 724/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19627.3398 - val_loss: 19704.5566\n",
      "Epoch 725/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20061.8301 - val_loss: 19681.5332\n",
      "Epoch 726/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20512.6367 - val_loss: 19728.2168\n",
      "Epoch 727/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19676.4746 - val_loss: 19680.3496\n",
      "Epoch 728/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20048.0410 - val_loss: 19678.7969\n",
      "Epoch 729/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19964.9199 - val_loss: 19700.6328\n",
      "Epoch 730/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20318.0371 - val_loss: 19721.6504\n",
      "Epoch 731/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20175.3281 - val_loss: 19692.5117\n",
      "Epoch 732/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19836.7598 - val_loss: 19719.6621\n",
      "Epoch 733/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20309.9082 - val_loss: 19792.4863\n",
      "Epoch 734/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20611.0977 - val_loss: 19755.6621\n",
      "Epoch 735/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20578.8184 - val_loss: 19714.3242\n",
      "Epoch 736/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20001.2285 - val_loss: 19763.9648\n",
      "Epoch 737/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20576.2266 - val_loss: 19739.4043\n",
      "Epoch 738/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20207.2969 - val_loss: 19708.9785\n",
      "Epoch 739/1200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 20423.6641 - val_loss: 19717.9902\n",
      "Epoch 740/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20370.9043 - val_loss: 19721.9004\n",
      "Epoch 741/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20301.7715 - val_loss: 19811.7012\n",
      "Epoch 742/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20544.4062 - val_loss: 19692.6621\n",
      "Epoch 743/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20118.2285 - val_loss: 19756.6543\n",
      "Epoch 744/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19940.2637 - val_loss: 19851.9238\n",
      "Epoch 745/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20479.3594 - val_loss: 19735.8633\n",
      "Epoch 746/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19868.3984 - val_loss: 19741.3672\n",
      "Epoch 747/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20292.1113 - val_loss: 19667.6895\n",
      "Epoch 748/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20179.2617 - val_loss: 19708.1719\n",
      "Epoch 749/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20257.0000 - val_loss: 19732.7891\n",
      "Epoch 750/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20111.8867 - val_loss: 19714.0879\n",
      "Epoch 751/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20152.9668 - val_loss: 19737.9199\n",
      "Epoch 752/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20053.4355 - val_loss: 19733.5371\n",
      "Epoch 753/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20384.6621 - val_loss: 19725.4863\n",
      "Epoch 754/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20142.9746 - val_loss: 19744.8320\n",
      "Epoch 755/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20462.8496 - val_loss: 19720.9238\n",
      "Epoch 756/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20100.8789 - val_loss: 19835.4746\n",
      "Epoch 757/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20268.4238 - val_loss: 19880.4395\n",
      "Epoch 758/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20361.9473 - val_loss: 19708.2969\n",
      "Epoch 759/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20888.3613 - val_loss: 19757.5059\n",
      "Epoch 760/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 21175.7539 - val_loss: 19706.0098\n",
      "Epoch 761/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20306.0586 - val_loss: 19693.8066\n",
      "Epoch 762/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20139.1660 - val_loss: 19740.1777\n",
      "Epoch 763/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20227.9531 - val_loss: 19666.4570\n",
      "Epoch 764/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20446.7246 - val_loss: 19716.6309\n",
      "Epoch 765/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20130.8398 - val_loss: 19684.5176\n",
      "Epoch 766/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19865.7188 - val_loss: 19730.9609\n",
      "Epoch 767/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20564.8516 - val_loss: 19694.5645\n",
      "Epoch 768/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19985.3750 - val_loss: 19721.2246\n",
      "Epoch 769/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19868.4004 - val_loss: 19747.1484\n",
      "Epoch 770/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20038.0703 - val_loss: 19772.6973\n",
      "Epoch 771/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20485.7598 - val_loss: 19747.1738\n",
      "Epoch 772/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20341.0723 - val_loss: 19766.4590\n",
      "Epoch 773/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20032.1680 - val_loss: 19728.2090\n",
      "Epoch 774/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19993.2012 - val_loss: 19753.1680\n",
      "Epoch 775/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20195.5742 - val_loss: 19778.7578\n",
      "Epoch 776/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19888.5117 - val_loss: 19697.0879\n",
      "Epoch 777/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19728.7637 - val_loss: 19689.2695\n",
      "Epoch 778/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20113.1328 - val_loss: 19722.4160\n",
      "Epoch 779/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20286.2422 - val_loss: 19676.0449\n",
      "Epoch 780/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20340.7031 - val_loss: 19679.0918\n",
      "Epoch 781/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20379.0547 - val_loss: 19693.5000\n",
      "Epoch 782/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20107.6758 - val_loss: 19694.4629\n",
      "Epoch 783/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20113.4355 - val_loss: 19731.2559\n",
      "Epoch 784/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20133.9941 - val_loss: 19709.4141\n",
      "Epoch 785/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19750.0801 - val_loss: 19697.4492\n",
      "Epoch 786/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19622.8223 - val_loss: 19673.4648\n",
      "Epoch 787/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19992.0156 - val_loss: 19683.6582\n",
      "Epoch 788/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19376.5039 - val_loss: 19704.3828\n",
      "Epoch 789/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19681.9355 - val_loss: 19715.2637\n",
      "Epoch 790/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20405.3418 - val_loss: 19686.3340\n",
      "Epoch 791/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20476.2598 - val_loss: 19704.8066\n",
      "Epoch 792/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20163.5879 - val_loss: 19697.6562\n",
      "Epoch 793/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19996.7910 - val_loss: 19688.6504\n",
      "Epoch 794/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20805.5469 - val_loss: 19660.2715\n",
      "Epoch 795/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20319.0898 - val_loss: 19718.9805\n",
      "Epoch 796/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20111.0645 - val_loss: 19760.2559\n",
      "Epoch 797/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19798.8984 - val_loss: 19747.0039\n",
      "Epoch 798/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20036.6270 - val_loss: 19669.3750\n",
      "Epoch 799/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20013.7598 - val_loss: 19667.5645\n",
      "Epoch 800/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19905.6934 - val_loss: 19776.0918\n",
      "Epoch 801/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20002.2480 - val_loss: 19730.6719\n",
      "Epoch 802/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20380.7676 - val_loss: 19871.2422\n",
      "Epoch 803/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20386.0371 - val_loss: 19717.0410\n",
      "Epoch 804/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20073.3984 - val_loss: 19725.1914\n",
      "Epoch 805/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20024.2090 - val_loss: 19743.8438\n",
      "Epoch 806/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20351.2012 - val_loss: 19816.6348\n",
      "Epoch 807/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20474.4941 - val_loss: 19740.7969\n",
      "Epoch 808/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20140.0449 - val_loss: 19681.8320\n",
      "Epoch 809/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20709.4004 - val_loss: 19717.1094\n",
      "Epoch 810/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20254.0176 - val_loss: 19694.0742\n",
      "Epoch 811/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20248.6523 - val_loss: 19691.9551\n",
      "Epoch 812/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19665.5879 - val_loss: 19689.7422\n",
      "Epoch 813/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19799.0684 - val_loss: 19713.5781\n",
      "Epoch 814/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19969.8262 - val_loss: 19750.9004\n",
      "Epoch 815/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20385.6445 - val_loss: 19749.3789\n",
      "Epoch 816/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19797.3418 - val_loss: 19755.6016\n",
      "Epoch 817/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20770.6973 - val_loss: 19832.8809\n",
      "Epoch 818/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19907.1699 - val_loss: 19714.0391\n",
      "Epoch 819/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19862.9258 - val_loss: 19741.9707\n",
      "Epoch 820/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20415.8008 - val_loss: 19717.2461\n",
      "Epoch 821/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20252.5449 - val_loss: 19686.3418\n",
      "Epoch 822/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19656.6250 - val_loss: 19708.1816\n",
      "Epoch 823/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20192.2715 - val_loss: 19762.6074\n",
      "Epoch 824/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19888.1895 - val_loss: 19670.4941\n",
      "Epoch 825/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20730.4180 - val_loss: 19666.6094\n",
      "Epoch 826/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20316.5605 - val_loss: 19652.4941\n",
      "Epoch 827/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20413.0000 - val_loss: 19699.6895\n",
      "Epoch 828/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20264.9453 - val_loss: 19647.4531\n",
      "Epoch 829/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20119.1172 - val_loss: 19703.5840\n",
      "Epoch 830/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20290.1465 - val_loss: 19687.9590\n",
      "Epoch 831/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20147.9980 - val_loss: 19708.1680\n",
      "Epoch 832/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19660.3867 - val_loss: 19689.2246\n",
      "Epoch 833/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20028.0254 - val_loss: 19660.3145\n",
      "Epoch 834/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20114.3496 - val_loss: 19668.4570\n",
      "Epoch 835/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19988.0918 - val_loss: 20028.2441\n",
      "Epoch 836/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20463.6504 - val_loss: 19658.6016\n",
      "Epoch 837/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20532.9102 - val_loss: 19718.3281\n",
      "Epoch 838/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20133.7227 - val_loss: 19803.7773\n",
      "Epoch 839/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20212.2266 - val_loss: 19686.7422\n",
      "Epoch 840/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20021.4688 - val_loss: 19796.7363\n",
      "Epoch 841/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19663.4453 - val_loss: 19792.9434\n",
      "Epoch 842/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20045.0234 - val_loss: 19668.5938\n",
      "Epoch 843/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20254.5977 - val_loss: 19662.4316\n",
      "Epoch 844/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19571.7227 - val_loss: 19687.8184\n",
      "Epoch 845/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20218.2617 - val_loss: 19819.1875\n",
      "Epoch 846/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20255.8223 - val_loss: 19705.3066\n",
      "Epoch 847/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19773.8828 - val_loss: 19695.0742\n",
      "Epoch 848/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20543.3848 - val_loss: 19777.4004\n",
      "Epoch 849/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20565.4023 - val_loss: 19671.7871\n",
      "Epoch 850/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19794.7637 - val_loss: 19704.9805\n",
      "Epoch 851/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20684.2793 - val_loss: 19667.5078\n",
      "Epoch 852/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20130.7754 - val_loss: 19688.2871\n",
      "Epoch 853/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19813.8789 - val_loss: 19667.0156\n",
      "Epoch 854/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20109.2910 - val_loss: 19645.2422\n",
      "Epoch 855/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20059.1641 - val_loss: 19648.8789\n",
      "Epoch 856/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20163.0645 - val_loss: 19652.1055\n",
      "Epoch 857/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20011.7520 - val_loss: 19650.8105\n",
      "Epoch 858/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19962.8828 - val_loss: 19669.3535\n",
      "Epoch 859/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20686.8848 - val_loss: 19689.0469\n",
      "Epoch 860/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20511.7480 - val_loss: 19769.6660\n",
      "Epoch 861/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20731.2969 - val_loss: 19700.7148\n",
      "Epoch 862/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20241.0312 - val_loss: 19647.2969\n",
      "Epoch 863/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20264.9902 - val_loss: 19680.9824\n",
      "Epoch 864/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19990.1895 - val_loss: 19652.4219\n",
      "Epoch 865/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20219.0742 - val_loss: 19668.6035\n",
      "Epoch 866/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20555.0215 - val_loss: 19659.8203\n",
      "Epoch 867/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20218.5000 - val_loss: 19653.6309\n",
      "Epoch 868/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20343.6230 - val_loss: 19667.0234\n",
      "Epoch 869/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20209.1172 - val_loss: 19648.4160\n",
      "Epoch 870/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20405.4609 - val_loss: 19703.2246\n",
      "Epoch 871/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20138.3047 - val_loss: 19692.9473\n",
      "Epoch 872/1200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 20180.2227 - val_loss: 19685.5605\n",
      "Epoch 873/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20416.2012 - val_loss: 19670.1621\n",
      "Epoch 874/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20119.8398 - val_loss: 19712.4805\n",
      "Epoch 875/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19923.3379 - val_loss: 19613.4648\n",
      "Epoch 876/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20138.6074 - val_loss: 19655.3711\n",
      "Epoch 877/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20578.5137 - val_loss: 19678.7969\n",
      "Epoch 878/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19950.3262 - val_loss: 19678.9531\n",
      "Epoch 879/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20742.7891 - val_loss: 19732.9277\n",
      "Epoch 880/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20535.8457 - val_loss: 19728.9590\n",
      "Epoch 881/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19998.2188 - val_loss: 19685.2266\n",
      "Epoch 882/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19586.7871 - val_loss: 19625.9043\n",
      "Epoch 883/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20507.6992 - val_loss: 19641.5098\n",
      "Epoch 884/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19986.6445 - val_loss: 19781.9570\n",
      "Epoch 885/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20212.3125 - val_loss: 19685.8418\n",
      "Epoch 886/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19928.1797 - val_loss: 19636.7168\n",
      "Epoch 887/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20115.6211 - val_loss: 19634.5723\n",
      "Epoch 888/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20021.5957 - val_loss: 19681.3828\n",
      "Epoch 889/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20340.4199 - val_loss: 19625.1094\n",
      "Epoch 890/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20199.2383 - val_loss: 19630.0059\n",
      "Epoch 891/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20187.5391 - val_loss: 19649.0020\n",
      "Epoch 892/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19818.6621 - val_loss: 19633.7559\n",
      "Epoch 893/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20567.3340 - val_loss: 19673.5684\n",
      "Epoch 894/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20293.0645 - val_loss: 19647.8105\n",
      "Epoch 895/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20347.7480 - val_loss: 19665.7988\n",
      "Epoch 896/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19837.4980 - val_loss: 19694.5371\n",
      "Epoch 897/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19806.6758 - val_loss: 19647.0566\n",
      "Epoch 898/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19688.2637 - val_loss: 19625.8555\n",
      "Epoch 899/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20141.4336 - val_loss: 19696.4883\n",
      "Epoch 900/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20035.7305 - val_loss: 19641.6973\n",
      "Epoch 901/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20410.6250 - val_loss: 19644.0391\n",
      "Epoch 902/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20348.0938 - val_loss: 19681.0879\n",
      "Epoch 903/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19949.5508 - val_loss: 19623.4512\n",
      "Epoch 904/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20265.5918 - val_loss: 19655.1328\n",
      "Epoch 905/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20040.9375 - val_loss: 19766.2754\n",
      "Epoch 906/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20053.0137 - val_loss: 19655.9277\n",
      "Epoch 907/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19888.1289 - val_loss: 19676.6719\n",
      "Epoch 908/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20333.4102 - val_loss: 19748.7441\n",
      "Epoch 909/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20523.9629 - val_loss: 19656.8203\n",
      "Epoch 910/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20261.5156 - val_loss: 19696.4609\n",
      "Epoch 911/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20112.5586 - val_loss: 19707.0918\n",
      "Epoch 912/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20423.2598 - val_loss: 19700.1582\n",
      "Epoch 913/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19578.7324 - val_loss: 19744.5625\n",
      "Epoch 914/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20148.5938 - val_loss: 19665.3945\n",
      "Epoch 915/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19981.0586 - val_loss: 19652.9648\n",
      "Epoch 916/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20297.0625 - val_loss: 19676.7637\n",
      "Epoch 917/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20411.3574 - val_loss: 19683.5723\n",
      "Epoch 918/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20400.1758 - val_loss: 19699.2520\n",
      "Epoch 919/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19673.4648 - val_loss: 19739.1504\n",
      "Epoch 920/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20142.0176 - val_loss: 19666.3340\n",
      "Epoch 921/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20063.0312 - val_loss: 19661.2031\n",
      "Epoch 922/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19871.1230 - val_loss: 19613.8633\n",
      "Epoch 923/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20094.0273 - val_loss: 19635.1211\n",
      "Epoch 924/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19841.7676 - val_loss: 19745.1152\n",
      "Epoch 925/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20445.7520 - val_loss: 19740.0156\n",
      "Epoch 926/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19840.5215 - val_loss: 19726.1719\n",
      "Epoch 927/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20151.3809 - val_loss: 19904.8125\n",
      "Epoch 928/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19759.9199 - val_loss: 19662.2168\n",
      "Epoch 929/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20470.5234 - val_loss: 19661.3906\n",
      "Epoch 930/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19876.2012 - val_loss: 19691.8594\n",
      "Epoch 931/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20509.4766 - val_loss: 19679.5156\n",
      "Epoch 932/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20017.1387 - val_loss: 19648.9688\n",
      "Epoch 933/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19753.8379 - val_loss: 19643.2754\n",
      "Epoch 934/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20124.8848 - val_loss: 19610.6699\n",
      "Epoch 935/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19931.6719 - val_loss: 19621.2480\n",
      "Epoch 936/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20261.1973 - val_loss: 19663.5000\n",
      "Epoch 937/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20003.3652 - val_loss: 19673.0469\n",
      "Epoch 938/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19838.5977 - val_loss: 19666.6035\n",
      "Epoch 939/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20148.1094 - val_loss: 19684.3965\n",
      "Epoch 940/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20169.9785 - val_loss: 19634.8340\n",
      "Epoch 941/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20456.8320 - val_loss: 19639.1582\n",
      "Epoch 942/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20190.1465 - val_loss: 19631.1680\n",
      "Epoch 943/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20642.6895 - val_loss: 19644.7305\n",
      "Epoch 944/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20483.8887 - val_loss: 19616.9746\n",
      "Epoch 945/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20177.7949 - val_loss: 19677.3633\n",
      "Epoch 946/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19784.0059 - val_loss: 19657.8496\n",
      "Epoch 947/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19799.6641 - val_loss: 19659.7559\n",
      "Epoch 948/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20019.0762 - val_loss: 19748.6074\n",
      "Epoch 949/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20161.0586 - val_loss: 19690.1133\n",
      "Epoch 950/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20160.8477 - val_loss: 19815.7656\n",
      "Epoch 951/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19756.9316 - val_loss: 19638.0098\n",
      "Epoch 952/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19534.3047 - val_loss: 19627.5020\n",
      "Epoch 953/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20206.1328 - val_loss: 19618.7930\n",
      "Epoch 954/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20297.9668 - val_loss: 19713.1895\n",
      "Epoch 955/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19846.7148 - val_loss: 19700.0996\n",
      "Epoch 956/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20173.9023 - val_loss: 19686.6191\n",
      "Epoch 957/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20534.9160 - val_loss: 19747.8906\n",
      "Epoch 958/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19996.2188 - val_loss: 19792.8086\n",
      "Epoch 959/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20532.7051 - val_loss: 19771.7891\n",
      "Epoch 960/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19988.5234 - val_loss: 19700.3301\n",
      "Epoch 961/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19856.4414 - val_loss: 19770.6504\n",
      "Epoch 962/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20187.4238 - val_loss: 19712.3340\n",
      "Epoch 963/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19928.7812 - val_loss: 19702.0430\n",
      "Epoch 964/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19824.7285 - val_loss: 19676.8633\n",
      "Epoch 965/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19569.7383 - val_loss: 19637.0176\n",
      "Epoch 966/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19647.9746 - val_loss: 19627.4082\n",
      "Epoch 967/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20183.2559 - val_loss: 19646.1133\n",
      "Epoch 968/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20372.7461 - val_loss: 19739.3535\n",
      "Epoch 969/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20097.6836 - val_loss: 19683.3848\n",
      "Epoch 970/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19668.8887 - val_loss: 19703.3691\n",
      "Epoch 971/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20022.2148 - val_loss: 19682.2793\n",
      "Epoch 972/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20187.1914 - val_loss: 19724.1621\n",
      "Epoch 973/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19765.7617 - val_loss: 19648.9434\n",
      "Epoch 974/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20650.8555 - val_loss: 19670.9980\n",
      "Epoch 975/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20325.1562 - val_loss: 19710.6914\n",
      "Epoch 976/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19766.2285 - val_loss: 19744.6172\n",
      "Epoch 977/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20596.8203 - val_loss: 19676.7754\n",
      "Epoch 978/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20557.0723 - val_loss: 19697.7773\n",
      "Epoch 979/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20076.9141 - val_loss: 19658.0566\n",
      "Epoch 980/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20036.6172 - val_loss: 19704.1582\n",
      "Epoch 981/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20195.8789 - val_loss: 19696.6113\n",
      "Epoch 982/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19714.2070 - val_loss: 19642.5273\n",
      "Epoch 983/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20179.3613 - val_loss: 19646.3379\n",
      "Epoch 984/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19752.3867 - val_loss: 19660.6738\n",
      "Epoch 985/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20540.9727 - val_loss: 19649.0625\n",
      "Epoch 986/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20231.7832 - val_loss: 19671.0723\n",
      "Epoch 987/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19903.1562 - val_loss: 19700.3750\n",
      "Epoch 988/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20437.7812 - val_loss: 19674.6133\n",
      "Epoch 989/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19903.2188 - val_loss: 19699.3496\n",
      "Epoch 990/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20600.3418 - val_loss: 19685.2109\n",
      "Epoch 991/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19955.4805 - val_loss: 19654.7148\n",
      "Epoch 992/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20344.7559 - val_loss: 19685.4531\n",
      "Epoch 993/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20142.2734 - val_loss: 19687.9395\n",
      "Epoch 994/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20096.7148 - val_loss: 19778.7363\n",
      "Epoch 995/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20001.8457 - val_loss: 19722.1055\n",
      "Epoch 996/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20346.5801 - val_loss: 19677.8379\n",
      "Epoch 997/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19641.5781 - val_loss: 19758.8340\n",
      "Epoch 998/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20343.3301 - val_loss: 19767.8711\n",
      "Epoch 999/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19949.2012 - val_loss: 19670.8184\n",
      "Epoch 1000/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19940.3555 - val_loss: 19638.1250\n",
      "Epoch 1001/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20046.7891 - val_loss: 19711.4590\n",
      "Epoch 1002/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20202.1738 - val_loss: 19680.1797\n",
      "Epoch 1003/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20168.1211 - val_loss: 19658.9551\n",
      "Epoch 1004/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20367.6562 - val_loss: 19687.8574\n",
      "Epoch 1005/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19641.0254 - val_loss: 19682.5059\n",
      "Epoch 1006/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19769.7051 - val_loss: 19720.8770\n",
      "Epoch 1007/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19708.8535 - val_loss: 19662.4531\n",
      "Epoch 1008/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20745.8379 - val_loss: 19693.6113\n",
      "Epoch 1009/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19849.0430 - val_loss: 19671.7832\n",
      "Epoch 1010/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20282.2168 - val_loss: 19666.4512\n",
      "Epoch 1011/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19942.4336 - val_loss: 19732.6152\n",
      "Epoch 1012/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20237.5215 - val_loss: 19684.4648\n",
      "Epoch 1013/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20062.3770 - val_loss: 19680.9277\n",
      "Epoch 1014/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20419.2852 - val_loss: 19640.8262\n",
      "Epoch 1015/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19966.4492 - val_loss: 19692.2754\n",
      "Epoch 1016/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20373.1055 - val_loss: 19643.7715\n",
      "Epoch 1017/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19722.5605 - val_loss: 19642.0371\n",
      "Epoch 1018/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20390.8574 - val_loss: 19676.3926\n",
      "Epoch 1019/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19885.1484 - val_loss: 19723.7793\n",
      "Epoch 1020/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19999.9648 - val_loss: 19664.4922\n",
      "Epoch 1021/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19849.3730 - val_loss: 19693.4492\n",
      "Epoch 1022/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20052.2383 - val_loss: 19707.2891\n",
      "Epoch 1023/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20168.3555 - val_loss: 19664.5801\n",
      "Epoch 1024/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20050.5547 - val_loss: 19621.9746\n",
      "Epoch 1025/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20147.2246 - val_loss: 19641.2383\n",
      "Epoch 1026/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20155.1934 - val_loss: 19695.3926\n",
      "Epoch 1027/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20213.1758 - val_loss: 19750.3691\n",
      "Epoch 1028/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19910.7520 - val_loss: 19717.6191\n",
      "Epoch 1029/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19681.3496 - val_loss: 19671.3105\n",
      "Epoch 1030/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19618.4258 - val_loss: 19647.3516\n",
      "Epoch 1031/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19927.4355 - val_loss: 19692.7285\n",
      "Epoch 1032/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20042.7832 - val_loss: 19646.1797\n",
      "Epoch 1033/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19482.7090 - val_loss: 19686.6055\n",
      "Epoch 1034/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20129.4160 - val_loss: 19698.8691\n",
      "Epoch 1035/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20369.3867 - val_loss: 19730.6621\n",
      "Epoch 1036/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20298.7988 - val_loss: 19756.3320\n",
      "Epoch 1037/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19833.3770 - val_loss: 19697.5156\n",
      "Epoch 1038/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19605.7930 - val_loss: 19767.3047\n",
      "Epoch 1039/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20432.4922 - val_loss: 19758.4512\n",
      "Epoch 1040/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20627.8574 - val_loss: 19678.1055\n",
      "Epoch 1041/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19925.7539 - val_loss: 19685.1836\n",
      "Epoch 1042/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20152.4688 - val_loss: 19691.6035\n",
      "Epoch 1043/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19714.7305 - val_loss: 19671.8438\n",
      "Epoch 1044/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20086.6367 - val_loss: 19723.0273\n",
      "Epoch 1045/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20021.1113 - val_loss: 19626.2793\n",
      "Epoch 1046/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20371.9199 - val_loss: 19644.9316\n",
      "Epoch 1047/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19993.9746 - val_loss: 19678.9961\n",
      "Epoch 1048/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20102.1641 - val_loss: 19673.2832\n",
      "Epoch 1049/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19991.2441 - val_loss: 19714.8828\n",
      "Epoch 1050/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20309.2852 - val_loss: 19711.6504\n",
      "Epoch 1051/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20529.5781 - val_loss: 19665.3008\n",
      "Epoch 1052/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19911.9453 - val_loss: 19687.1992\n",
      "Epoch 1053/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19748.6504 - val_loss: 19724.4902\n",
      "Epoch 1054/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20065.5957 - val_loss: 19682.1816\n",
      "Epoch 1055/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19840.5723 - val_loss: 19749.5508\n",
      "Epoch 1056/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20169.5352 - val_loss: 19624.0469\n",
      "Epoch 1057/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19512.2852 - val_loss: 19652.1797\n",
      "Epoch 1058/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20103.7344 - val_loss: 19743.7871\n",
      "Epoch 1059/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19965.2617 - val_loss: 19689.0059\n",
      "Epoch 1060/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20059.9492 - val_loss: 19670.5117\n",
      "Epoch 1061/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20046.8105 - val_loss: 19670.0254\n",
      "Epoch 1062/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20080.6406 - val_loss: 19719.2656\n",
      "Epoch 1063/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20408.2715 - val_loss: 19739.7559\n",
      "Epoch 1064/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20620.6836 - val_loss: 19757.2402\n",
      "Epoch 1065/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20045.7012 - val_loss: 19675.8887\n",
      "Epoch 1066/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20687.2441 - val_loss: 19639.9688\n",
      "Epoch 1067/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19980.7188 - val_loss: 19690.7930\n",
      "Epoch 1068/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20159.4453 - val_loss: 19632.9746\n",
      "Epoch 1069/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20145.3125 - val_loss: 19651.3652\n",
      "Epoch 1070/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19942.3789 - val_loss: 19892.3594\n",
      "Epoch 1071/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19894.6406 - val_loss: 19779.5938\n",
      "Epoch 1072/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19940.8574 - val_loss: 19683.1211\n",
      "Epoch 1073/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19762.6973 - val_loss: 19649.4453\n",
      "Epoch 1074/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20085.6680 - val_loss: 19666.1621\n",
      "Epoch 1075/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19628.3828 - val_loss: 19649.0176\n",
      "Epoch 1076/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20129.1484 - val_loss: 19686.2969\n",
      "Epoch 1077/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20220.6484 - val_loss: 19622.6621\n",
      "Epoch 1078/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19964.9102 - val_loss: 19613.6074\n",
      "Epoch 1079/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19877.5723 - val_loss: 19645.9160\n",
      "Epoch 1080/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20526.8066 - val_loss: 19677.8125\n",
      "Epoch 1081/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19760.6230 - val_loss: 19675.9531\n",
      "Epoch 1082/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20937.5059 - val_loss: 19649.7871\n",
      "Epoch 1083/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20548.6699 - val_loss: 19661.8281\n",
      "Epoch 1084/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20113.0117 - val_loss: 19752.4082\n",
      "Epoch 1085/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20250.5488 - val_loss: 19679.4062\n",
      "Epoch 1086/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19970.5020 - val_loss: 19758.4180\n",
      "Epoch 1087/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19703.1230 - val_loss: 19685.9082\n",
      "Epoch 1088/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19883.1133 - val_loss: 19753.3730\n",
      "Epoch 1089/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19930.2383 - val_loss: 19710.0820\n",
      "Epoch 1090/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19875.6621 - val_loss: 19656.7734\n",
      "Epoch 1091/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20426.6484 - val_loss: 19671.3887\n",
      "Epoch 1092/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20080.1289 - val_loss: 19674.9941\n",
      "Epoch 1093/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19995.6582 - val_loss: 19696.3926\n",
      "Epoch 1094/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19865.1875 - val_loss: 19648.3359\n",
      "Epoch 1095/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20081.3184 - val_loss: 19632.4844\n",
      "Epoch 1096/1200\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 19872.1113 - val_loss: 19656.6543\n",
      "Epoch 1097/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19683.5371 - val_loss: 19658.6406\n",
      "Epoch 1098/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20300.0430 - val_loss: 19679.1172\n",
      "Epoch 1099/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19994.9043 - val_loss: 19627.3379\n",
      "Epoch 1100/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20647.4316 - val_loss: 19591.2734\n",
      "Epoch 1101/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20151.8359 - val_loss: 19737.1504\n",
      "Epoch 1102/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20078.8203 - val_loss: 19664.6016\n",
      "Epoch 1103/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19809.1855 - val_loss: 19628.5527\n",
      "Epoch 1104/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19607.7910 - val_loss: 19632.1270\n",
      "Epoch 1105/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20038.6895 - val_loss: 19690.1816\n",
      "Epoch 1106/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19929.2754 - val_loss: 19638.1641\n",
      "Epoch 1107/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19922.5664 - val_loss: 19682.6758\n",
      "Epoch 1108/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19918.8516 - val_loss: 19618.5684\n",
      "Epoch 1109/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20009.2500 - val_loss: 19627.4688\n",
      "Epoch 1110/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19638.5859 - val_loss: 19725.2832\n",
      "Epoch 1111/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19965.4375 - val_loss: 19685.5723\n",
      "Epoch 1112/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20153.8594 - val_loss: 19733.8281\n",
      "Epoch 1113/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20793.2461 - val_loss: 19697.1055\n",
      "Epoch 1114/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20399.9316 - val_loss: 19636.0645\n",
      "Epoch 1115/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20234.4961 - val_loss: 19849.1191\n",
      "Epoch 1116/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20277.6934 - val_loss: 19652.5371\n",
      "Epoch 1117/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20224.6309 - val_loss: 19634.4453\n",
      "Epoch 1118/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19934.7617 - val_loss: 19721.3398\n",
      "Epoch 1119/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20024.5664 - val_loss: 19742.5371\n",
      "Epoch 1120/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20316.6191 - val_loss: 19629.6426\n",
      "Epoch 1121/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19882.4434 - val_loss: 19624.6973\n",
      "Epoch 1122/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19722.3711 - val_loss: 19633.1914\n",
      "Epoch 1123/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20194.6934 - val_loss: 19642.6172\n",
      "Epoch 1124/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19886.5176 - val_loss: 19628.0820\n",
      "Epoch 1125/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20464.6719 - val_loss: 19611.1309\n",
      "Epoch 1126/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20159.3613 - val_loss: 19642.9629\n",
      "Epoch 1127/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20260.9121 - val_loss: 19604.5996\n",
      "Epoch 1128/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20061.4238 - val_loss: 19627.4941\n",
      "Epoch 1129/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20326.4180 - val_loss: 19634.7852\n",
      "Epoch 1130/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19780.1777 - val_loss: 19686.5879\n",
      "Epoch 1131/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20449.4746 - val_loss: 19792.9004\n",
      "Epoch 1132/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20383.3105 - val_loss: 19662.5371\n",
      "Epoch 1133/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20023.6582 - val_loss: 19637.8184\n",
      "Epoch 1134/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20183.7695 - val_loss: 19735.4648\n",
      "Epoch 1135/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20179.4551 - val_loss: 19645.7754\n",
      "Epoch 1136/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19940.8301 - val_loss: 19680.6543\n",
      "Epoch 1137/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20022.4316 - val_loss: 19629.7402\n",
      "Epoch 1138/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19620.5625 - val_loss: 19662.1270\n",
      "Epoch 1139/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19933.3730 - val_loss: 19690.9355\n",
      "Epoch 1140/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19999.1484 - val_loss: 19662.0781\n",
      "Epoch 1141/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20383.2129 - val_loss: 19657.9453\n",
      "Epoch 1142/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20474.6621 - val_loss: 19610.2637\n",
      "Epoch 1143/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19511.7109 - val_loss: 19666.9102\n",
      "Epoch 1144/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19844.4922 - val_loss: 19735.6309\n",
      "Epoch 1145/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20270.8594 - val_loss: 19624.1465\n",
      "Epoch 1146/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19674.4277 - val_loss: 19637.0879\n",
      "Epoch 1147/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20369.0566 - val_loss: 19640.3613\n",
      "Epoch 1148/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19992.3652 - val_loss: 19663.8691\n",
      "Epoch 1149/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20268.7500 - val_loss: 19676.2754\n",
      "Epoch 1150/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19950.5762 - val_loss: 19659.2363\n",
      "Epoch 1151/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19957.9121 - val_loss: 19706.8887\n",
      "Epoch 1152/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19827.9375 - val_loss: 19656.8711\n",
      "Epoch 1153/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20099.6465 - val_loss: 19645.3086\n",
      "Epoch 1154/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19722.6484 - val_loss: 19610.2168\n",
      "Epoch 1155/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 20067.2969 - val_loss: 19583.4238\n",
      "Epoch 1156/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19974.5273 - val_loss: 19642.5918\n",
      "Epoch 1157/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19469.3711 - val_loss: 19652.2168\n",
      "Epoch 1158/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19839.7578 - val_loss: 19625.2930\n",
      "Epoch 1159/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20041.3594 - val_loss: 19609.9121\n",
      "Epoch 1160/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19756.6816 - val_loss: 19679.0996\n",
      "Epoch 1161/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20119.8379 - val_loss: 19626.6680\n",
      "Epoch 1162/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19843.0586 - val_loss: 19645.4883\n",
      "Epoch 1163/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20312.5684 - val_loss: 19613.0977\n",
      "Epoch 1164/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19985.2910 - val_loss: 19612.2617\n",
      "Epoch 1165/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20062.0059 - val_loss: 19607.3730\n",
      "Epoch 1166/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19810.1035 - val_loss: 19626.6719\n",
      "Epoch 1167/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19763.7539 - val_loss: 19601.8203\n",
      "Epoch 1168/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20061.6113 - val_loss: 19643.8477\n",
      "Epoch 1169/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19555.0879 - val_loss: 19650.4980\n",
      "Epoch 1170/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20078.5234 - val_loss: 19621.3613\n",
      "Epoch 1171/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20622.6973 - val_loss: 19636.1582\n",
      "Epoch 1172/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19930.1641 - val_loss: 19663.8477\n",
      "Epoch 1173/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19999.0234 - val_loss: 19795.6523\n",
      "Epoch 1174/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19622.9746 - val_loss: 19698.8691\n",
      "Epoch 1175/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19626.6797 - val_loss: 19619.4297\n",
      "Epoch 1176/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19740.6621 - val_loss: 19575.0684\n",
      "Epoch 1177/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19513.0527 - val_loss: 19582.2012\n",
      "Epoch 1178/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20002.5586 - val_loss: 19656.3828\n",
      "Epoch 1179/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19811.3594 - val_loss: 19607.5664\n",
      "Epoch 1180/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19782.5820 - val_loss: 19601.0566\n",
      "Epoch 1181/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20027.0352 - val_loss: 19691.3418\n",
      "Epoch 1182/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19691.0977 - val_loss: 19615.7422\n",
      "Epoch 1183/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20240.6719 - val_loss: 19574.7559\n",
      "Epoch 1184/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20203.9512 - val_loss: 19609.4238\n",
      "Epoch 1185/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19967.0098 - val_loss: 19625.9141\n",
      "Epoch 1186/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19836.5156 - val_loss: 19636.0078\n",
      "Epoch 1187/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20251.4492 - val_loss: 19613.5918\n",
      "Epoch 1188/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20090.8066 - val_loss: 19566.4531\n",
      "Epoch 1189/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20098.7402 - val_loss: 19608.3359\n",
      "Epoch 1190/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19635.0469 - val_loss: 19593.5195\n",
      "Epoch 1191/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20170.0781 - val_loss: 19617.0938\n",
      "Epoch 1192/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20322.1113 - val_loss: 19623.9355\n",
      "Epoch 1193/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19828.6348 - val_loss: 19620.6152\n",
      "Epoch 1194/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19668.5879 - val_loss: 19620.5098\n",
      "Epoch 1195/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 20464.2891 - val_loss: 19703.6348\n",
      "Epoch 1196/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19725.9629 - val_loss: 19654.2246\n",
      "Epoch 1197/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19966.2910 - val_loss: 19637.0000\n",
      "Epoch 1198/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19535.9336 - val_loss: 19613.0566\n",
      "Epoch 1199/1200\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 19908.8203 - val_loss: 19609.6191\n",
      "Epoch 1200/1200\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 19940.6621 - val_loss: 19564.6582\n",
      "INFO:tensorflow:Assets written to: c:\\programowanie\\ml_streamlit\\models\\e_class\\assets\n",
      "Epoch 1/1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\proso\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\data_adapter.py:1699: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 1s 5ms/step - loss: 68736.7656 - val_loss: 72136.2344\n",
      "Epoch 2/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 68483.4844 - val_loss: 71418.4844\n",
      "Epoch 3/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 66436.9062 - val_loss: 67340.5469\n",
      "Epoch 4/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 59487.6016 - val_loss: 57201.7461\n",
      "Epoch 5/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 47574.8555 - val_loss: 42606.4219\n",
      "Epoch 6/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 33566.3438 - val_loss: 28100.8633\n",
      "Epoch 7/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 24433.2598 - val_loss: 22197.6387\n",
      "Epoch 8/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 21346.7109 - val_loss: 20718.6270\n",
      "Epoch 9/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 20583.8828 - val_loss: 20130.1641\n",
      "Epoch 10/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 19981.7344 - val_loss: 19641.4824\n",
      "Epoch 11/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 19705.7012 - val_loss: 19226.3887\n",
      "Epoch 12/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 19405.1680 - val_loss: 18830.2051\n",
      "Epoch 13/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 19081.2773 - val_loss: 18546.5879\n",
      "Epoch 14/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 18635.8418 - val_loss: 18216.6523\n",
      "Epoch 15/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 18467.2129 - val_loss: 18007.5957\n",
      "Epoch 16/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 18390.8086 - val_loss: 17805.6211\n",
      "Epoch 17/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 18182.0547 - val_loss: 17635.2578\n",
      "Epoch 18/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 18264.9512 - val_loss: 17440.5859\n",
      "Epoch 19/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17740.6074 - val_loss: 17277.2773\n",
      "Epoch 20/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17368.4668 - val_loss: 17148.3184\n",
      "Epoch 21/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17422.9629 - val_loss: 16972.6211\n",
      "Epoch 22/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17422.3145 - val_loss: 16807.1562\n",
      "Epoch 23/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17626.6074 - val_loss: 16683.3711\n",
      "Epoch 24/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17147.6699 - val_loss: 16596.9336\n",
      "Epoch 25/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17097.4766 - val_loss: 16495.7695\n",
      "Epoch 26/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 17387.4844 - val_loss: 16393.1875\n",
      "Epoch 27/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16967.8496 - val_loss: 16305.6328\n",
      "Epoch 28/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16811.4277 - val_loss: 16191.5068\n",
      "Epoch 29/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16710.7500 - val_loss: 16113.2529\n",
      "Epoch 30/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16639.8301 - val_loss: 16014.5410\n",
      "Epoch 31/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16843.4590 - val_loss: 15924.6143\n",
      "Epoch 32/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16636.5273 - val_loss: 15884.5264\n",
      "Epoch 33/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16487.1621 - val_loss: 15765.7500\n",
      "Epoch 34/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16338.3721 - val_loss: 15678.6016\n",
      "Epoch 35/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16489.8984 - val_loss: 15653.8975\n",
      "Epoch 36/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16389.0977 - val_loss: 15542.2988\n",
      "Epoch 37/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16383.6748 - val_loss: 15523.5703\n",
      "Epoch 38/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16231.9170 - val_loss: 15377.9756\n",
      "Epoch 39/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16067.6416 - val_loss: 15340.1484\n",
      "Epoch 40/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16160.7012 - val_loss: 15246.0381\n",
      "Epoch 41/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15964.4902 - val_loss: 15159.4492\n",
      "Epoch 42/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15687.5703 - val_loss: 15088.2900\n",
      "Epoch 43/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15891.4160 - val_loss: 15072.7412\n",
      "Epoch 44/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 16060.6338 - val_loss: 14973.3975\n",
      "Epoch 45/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15832.2676 - val_loss: 14936.2393\n",
      "Epoch 46/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15672.4150 - val_loss: 14841.9121\n",
      "Epoch 47/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15576.4131 - val_loss: 14836.1182\n",
      "Epoch 48/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15593.8008 - val_loss: 14784.1279\n",
      "Epoch 49/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15460.4170 - val_loss: 14702.7793\n",
      "Epoch 50/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15557.7148 - val_loss: 14620.6543\n",
      "Epoch 51/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15251.9961 - val_loss: 14671.4521\n",
      "Epoch 52/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15273.1221 - val_loss: 14531.1104\n",
      "Epoch 53/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15624.2881 - val_loss: 14482.0742\n",
      "Epoch 54/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15387.6445 - val_loss: 14421.0693\n",
      "Epoch 55/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15261.2402 - val_loss: 14416.8037\n",
      "Epoch 56/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15409.0078 - val_loss: 14353.9795\n",
      "Epoch 57/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15221.9590 - val_loss: 14383.9941\n",
      "Epoch 58/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14973.2852 - val_loss: 14274.7861\n",
      "Epoch 59/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15192.6807 - val_loss: 14274.8906\n",
      "Epoch 60/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15042.9736 - val_loss: 14181.6357\n",
      "Epoch 61/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15155.8867 - val_loss: 14190.4678\n",
      "Epoch 62/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 15051.8633 - val_loss: 14129.0566\n",
      "Epoch 63/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14937.9619 - val_loss: 14092.0420\n",
      "Epoch 64/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14890.6338 - val_loss: 14092.2861\n",
      "Epoch 65/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14851.5342 - val_loss: 14031.0176\n",
      "Epoch 66/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14743.0996 - val_loss: 14043.8643\n",
      "Epoch 67/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14736.8428 - val_loss: 13957.1562\n",
      "Epoch 68/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14708.5254 - val_loss: 13945.9766\n",
      "Epoch 69/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14738.6680 - val_loss: 13955.7090\n",
      "Epoch 70/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14504.3545 - val_loss: 13933.4609\n",
      "Epoch 71/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14649.0420 - val_loss: 13895.5205\n",
      "Epoch 72/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14866.1875 - val_loss: 13803.6807\n",
      "Epoch 73/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14572.7881 - val_loss: 13802.9307\n",
      "Epoch 74/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14699.9756 - val_loss: 13684.5654\n",
      "Epoch 75/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14594.1953 - val_loss: 13766.6934\n",
      "Epoch 76/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14607.7939 - val_loss: 13669.4062\n",
      "Epoch 77/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14303.5771 - val_loss: 13667.0889\n",
      "Epoch 78/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14629.0635 - val_loss: 13610.3652\n",
      "Epoch 79/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14341.8701 - val_loss: 13650.0078\n",
      "Epoch 80/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14345.0186 - val_loss: 13503.6211\n",
      "Epoch 81/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14471.5420 - val_loss: 13518.0225\n",
      "Epoch 82/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14320.8965 - val_loss: 13618.5957\n",
      "Epoch 83/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14521.0869 - val_loss: 13441.9355\n",
      "Epoch 84/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14085.2139 - val_loss: 13443.9248\n",
      "Epoch 85/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14367.1748 - val_loss: 13415.1514\n",
      "Epoch 86/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14377.5615 - val_loss: 13470.7100\n",
      "Epoch 87/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14320.5869 - val_loss: 13401.3271\n",
      "Epoch 88/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14111.5732 - val_loss: 13517.8945\n",
      "Epoch 89/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14252.8193 - val_loss: 13286.7305\n",
      "Epoch 90/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14232.5107 - val_loss: 13327.9902\n",
      "Epoch 91/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14229.1943 - val_loss: 13318.2305\n",
      "Epoch 92/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14384.5400 - val_loss: 13253.0605\n",
      "Epoch 93/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14383.3809 - val_loss: 13295.3867\n",
      "Epoch 94/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14045.8203 - val_loss: 13194.5508\n",
      "Epoch 95/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14100.5537 - val_loss: 13152.9736\n",
      "Epoch 96/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14153.1865 - val_loss: 13114.7061\n",
      "Epoch 97/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14243.1709 - val_loss: 13131.5498\n",
      "Epoch 98/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14081.1816 - val_loss: 13167.9443\n",
      "Epoch 99/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 14001.5371 - val_loss: 13061.2139\n",
      "Epoch 100/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14021.6865 - val_loss: 13073.4893\n",
      "Epoch 101/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14088.0557 - val_loss: 13049.3232\n",
      "Epoch 102/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13936.9785 - val_loss: 12992.5986\n",
      "Epoch 103/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14151.5410 - val_loss: 13142.7041\n",
      "Epoch 104/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14073.4844 - val_loss: 13092.7773\n",
      "Epoch 105/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13998.0977 - val_loss: 13043.8281\n",
      "Epoch 106/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13904.9199 - val_loss: 12986.5303\n",
      "Epoch 107/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13740.9414 - val_loss: 12952.1006\n",
      "Epoch 108/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13946.5879 - val_loss: 13035.3955\n",
      "Epoch 109/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13952.1514 - val_loss: 12878.0254\n",
      "Epoch 110/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13980.3047 - val_loss: 12920.7158\n",
      "Epoch 111/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14251.4775 - val_loss: 12955.7959\n",
      "Epoch 112/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 14043.4072 - val_loss: 12908.0371\n",
      "Epoch 113/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13598.5967 - val_loss: 13025.0508\n",
      "Epoch 114/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13901.5322 - val_loss: 12870.3369\n",
      "Epoch 115/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13979.2148 - val_loss: 12975.1279\n",
      "Epoch 116/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13959.6523 - val_loss: 12855.4170\n",
      "Epoch 117/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13569.5312 - val_loss: 12810.4014\n",
      "Epoch 118/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13881.5537 - val_loss: 12842.5098\n",
      "Epoch 119/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13949.5791 - val_loss: 12792.3643\n",
      "Epoch 120/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13692.6660 - val_loss: 12753.0830\n",
      "Epoch 121/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13917.0039 - val_loss: 12755.8730\n",
      "Epoch 122/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13694.5537 - val_loss: 12804.9834\n",
      "Epoch 123/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13716.3672 - val_loss: 12746.0752\n",
      "Epoch 124/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13745.2158 - val_loss: 12692.9102\n",
      "Epoch 125/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13900.7393 - val_loss: 12848.7061\n",
      "Epoch 126/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13698.5723 - val_loss: 12731.5098\n",
      "Epoch 127/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13782.0117 - val_loss: 12682.3105\n",
      "Epoch 128/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13824.9775 - val_loss: 12639.9219\n",
      "Epoch 129/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13964.6270 - val_loss: 12779.6465\n",
      "Epoch 130/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13790.4209 - val_loss: 12758.3867\n",
      "Epoch 131/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13811.9492 - val_loss: 12652.1445\n",
      "Epoch 132/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13612.6934 - val_loss: 12631.7236\n",
      "Epoch 133/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13554.8477 - val_loss: 12625.1953\n",
      "Epoch 134/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13611.6416 - val_loss: 12734.3203\n",
      "Epoch 135/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13764.6816 - val_loss: 12720.4043\n",
      "Epoch 136/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13603.5400 - val_loss: 12642.7480\n",
      "Epoch 137/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13756.4980 - val_loss: 12601.5898\n",
      "Epoch 138/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13688.8477 - val_loss: 12636.9980\n",
      "Epoch 139/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13680.5693 - val_loss: 12572.2686\n",
      "Epoch 140/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13385.4688 - val_loss: 12611.3770\n",
      "Epoch 141/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13892.2734 - val_loss: 12619.2803\n",
      "Epoch 142/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13595.3721 - val_loss: 12540.4600\n",
      "Epoch 143/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13681.7812 - val_loss: 12493.0020\n",
      "Epoch 144/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13653.4727 - val_loss: 12563.9297\n",
      "Epoch 145/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13626.0488 - val_loss: 12535.7627\n",
      "Epoch 146/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13547.0801 - val_loss: 12593.0967\n",
      "Epoch 147/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13452.1055 - val_loss: 12568.5029\n",
      "Epoch 148/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13711.5205 - val_loss: 12579.8975\n",
      "Epoch 149/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13398.6494 - val_loss: 12534.1621\n",
      "Epoch 150/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13749.1914 - val_loss: 12519.0215\n",
      "Epoch 151/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13723.5020 - val_loss: 12592.8691\n",
      "Epoch 152/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13603.0781 - val_loss: 12504.7764\n",
      "Epoch 153/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13723.3555 - val_loss: 12493.7539\n",
      "Epoch 154/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13719.9922 - val_loss: 12466.8711\n",
      "Epoch 155/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13697.2734 - val_loss: 12618.7998\n",
      "Epoch 156/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13798.2998 - val_loss: 12468.0342\n",
      "Epoch 157/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13295.2949 - val_loss: 12464.4160\n",
      "Epoch 158/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13484.2900 - val_loss: 12453.2285\n",
      "Epoch 159/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13701.1553 - val_loss: 12427.8447\n",
      "Epoch 160/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13411.2441 - val_loss: 12424.2090\n",
      "Epoch 161/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13464.0322 - val_loss: 12372.5518\n",
      "Epoch 162/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13564.6123 - val_loss: 12538.0273\n",
      "Epoch 163/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13573.4570 - val_loss: 12341.6299\n",
      "Epoch 164/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13503.8291 - val_loss: 12422.4326\n",
      "Epoch 165/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13445.9551 - val_loss: 12366.9922\n",
      "Epoch 166/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13691.8857 - val_loss: 12348.5088\n",
      "Epoch 167/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13883.1104 - val_loss: 12312.4932\n",
      "Epoch 168/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13478.7471 - val_loss: 12297.0410\n",
      "Epoch 169/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13529.5654 - val_loss: 12399.9795\n",
      "Epoch 170/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13368.4297 - val_loss: 12422.1855\n",
      "Epoch 171/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13542.9434 - val_loss: 12463.0127\n",
      "Epoch 172/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13610.1191 - val_loss: 12357.6553\n",
      "Epoch 173/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13814.9971 - val_loss: 12415.9062\n",
      "Epoch 174/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13548.7305 - val_loss: 12340.8408\n",
      "Epoch 175/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13771.9434 - val_loss: 12313.1387\n",
      "Epoch 176/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13482.7588 - val_loss: 12326.5010\n",
      "Epoch 177/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13438.6465 - val_loss: 12325.7031\n",
      "Epoch 178/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13580.6914 - val_loss: 12286.8389\n",
      "Epoch 179/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13370.2080 - val_loss: 12590.6582\n",
      "Epoch 180/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13587.0352 - val_loss: 12248.5752\n",
      "Epoch 181/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13453.9805 - val_loss: 12231.0049\n",
      "Epoch 182/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13427.1357 - val_loss: 12377.1943\n",
      "Epoch 183/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13355.0283 - val_loss: 12270.7344\n",
      "Epoch 184/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13352.6182 - val_loss: 12418.1797\n",
      "Epoch 185/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13455.0098 - val_loss: 12351.1748\n",
      "Epoch 186/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13588.9902 - val_loss: 12248.6338\n",
      "Epoch 187/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13156.0479 - val_loss: 12204.8789\n",
      "Epoch 188/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13362.7197 - val_loss: 12286.3330\n",
      "Epoch 189/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13399.6289 - val_loss: 12283.2920\n",
      "Epoch 190/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13337.7041 - val_loss: 12160.3535\n",
      "Epoch 191/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13439.4902 - val_loss: 12215.1436\n",
      "Epoch 192/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13715.5498 - val_loss: 12228.8486\n",
      "Epoch 193/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13548.9766 - val_loss: 12192.9023\n",
      "Epoch 194/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13442.4443 - val_loss: 12273.6504\n",
      "Epoch 195/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13593.0918 - val_loss: 12167.3193\n",
      "Epoch 196/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13653.6172 - val_loss: 12430.7158\n",
      "Epoch 197/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13593.2441 - val_loss: 12237.6494\n",
      "Epoch 198/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13297.7480 - val_loss: 12162.0566\n",
      "Epoch 199/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13356.8359 - val_loss: 12185.6719\n",
      "Epoch 200/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13567.5254 - val_loss: 12188.1260\n",
      "Epoch 201/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13545.8369 - val_loss: 12398.4043\n",
      "Epoch 202/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13713.8164 - val_loss: 12136.6475\n",
      "Epoch 203/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13200.7139 - val_loss: 12229.9893\n",
      "Epoch 204/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13298.7441 - val_loss: 12120.1494\n",
      "Epoch 205/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13263.6221 - val_loss: 12148.9619\n",
      "Epoch 206/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13596.4482 - val_loss: 12123.9902\n",
      "Epoch 207/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13358.7129 - val_loss: 12205.1914\n",
      "Epoch 208/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13531.8750 - val_loss: 12218.7500\n",
      "Epoch 209/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13449.4648 - val_loss: 12328.5303\n",
      "Epoch 210/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13364.4795 - val_loss: 12257.3047\n",
      "Epoch 211/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13122.8623 - val_loss: 12159.5527\n",
      "Epoch 212/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13555.0068 - val_loss: 12254.4551\n",
      "Epoch 213/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13440.0322 - val_loss: 12311.4473\n",
      "Epoch 214/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13328.4287 - val_loss: 12203.7217\n",
      "Epoch 215/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13373.1104 - val_loss: 12258.1191\n",
      "Epoch 216/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13276.2109 - val_loss: 12209.8428\n",
      "Epoch 217/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13529.9736 - val_loss: 12070.9131\n",
      "Epoch 218/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13547.8262 - val_loss: 12211.8682\n",
      "Epoch 219/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13422.3896 - val_loss: 12163.4414\n",
      "Epoch 220/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13360.1934 - val_loss: 12164.2158\n",
      "Epoch 221/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13599.7832 - val_loss: 12160.7217\n",
      "Epoch 222/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13287.3770 - val_loss: 12016.7139\n",
      "Epoch 223/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13314.5762 - val_loss: 12064.7529\n",
      "Epoch 224/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13423.1748 - val_loss: 12034.7471\n",
      "Epoch 225/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13711.1572 - val_loss: 12161.3213\n",
      "Epoch 226/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13315.6006 - val_loss: 12351.3926\n",
      "Epoch 227/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13656.9932 - val_loss: 12219.8486\n",
      "Epoch 228/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13482.1768 - val_loss: 12067.7588\n",
      "Epoch 229/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13440.6230 - val_loss: 12056.9531\n",
      "Epoch 230/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13245.0635 - val_loss: 12126.6484\n",
      "Epoch 231/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13437.6650 - val_loss: 12076.7910\n",
      "Epoch 232/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13403.5039 - val_loss: 12042.1904\n",
      "Epoch 233/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13330.2139 - val_loss: 12142.0449\n",
      "Epoch 234/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13153.5078 - val_loss: 12183.6680\n",
      "Epoch 235/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13047.5381 - val_loss: 12130.4238\n",
      "Epoch 236/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13219.0977 - val_loss: 12079.7148\n",
      "Epoch 237/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13435.7754 - val_loss: 12098.1973\n",
      "Epoch 238/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13412.1709 - val_loss: 12010.6416\n",
      "Epoch 239/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13293.5596 - val_loss: 11995.2510\n",
      "Epoch 240/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13260.1484 - val_loss: 12172.6250\n",
      "Epoch 241/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13209.2930 - val_loss: 11983.1172\n",
      "Epoch 242/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13522.8701 - val_loss: 12171.7871\n",
      "Epoch 243/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13305.0547 - val_loss: 12013.9082\n",
      "Epoch 244/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13374.4268 - val_loss: 12351.4844\n",
      "Epoch 245/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13266.1758 - val_loss: 12211.1494\n",
      "Epoch 246/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13526.6133 - val_loss: 12061.3828\n",
      "Epoch 247/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13262.7705 - val_loss: 12070.5957\n",
      "Epoch 248/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13465.3037 - val_loss: 12063.2227\n",
      "Epoch 249/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13453.8379 - val_loss: 12088.2314\n",
      "Epoch 250/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13231.3799 - val_loss: 11972.2559\n",
      "Epoch 251/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13204.1934 - val_loss: 12156.7100\n",
      "Epoch 252/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13277.6104 - val_loss: 12001.7061\n",
      "Epoch 253/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13416.5576 - val_loss: 12035.0459\n",
      "Epoch 254/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13224.1631 - val_loss: 12148.1592\n",
      "Epoch 255/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13421.7900 - val_loss: 12048.8203\n",
      "Epoch 256/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13372.1045 - val_loss: 12034.2275\n",
      "Epoch 257/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13311.0947 - val_loss: 12081.2559\n",
      "Epoch 258/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13523.4941 - val_loss: 11977.7363\n",
      "Epoch 259/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13157.3359 - val_loss: 12097.0664\n",
      "Epoch 260/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13365.6094 - val_loss: 12236.1826\n",
      "Epoch 261/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13265.2207 - val_loss: 12082.6719\n",
      "Epoch 262/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13435.4082 - val_loss: 12037.9883\n",
      "Epoch 263/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13376.1836 - val_loss: 12089.4941\n",
      "Epoch 264/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13416.9014 - val_loss: 12061.5420\n",
      "Epoch 265/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13253.9082 - val_loss: 12089.8848\n",
      "Epoch 266/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13425.9268 - val_loss: 12142.0420\n",
      "Epoch 267/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13122.9844 - val_loss: 12101.4170\n",
      "Epoch 268/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13463.1055 - val_loss: 12229.6855\n",
      "Epoch 269/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13505.0264 - val_loss: 12007.7285\n",
      "Epoch 270/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13566.8428 - val_loss: 12003.6055\n",
      "Epoch 271/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13053.4668 - val_loss: 12147.5391\n",
      "Epoch 272/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13243.5732 - val_loss: 11968.0439\n",
      "Epoch 273/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13341.1416 - val_loss: 12099.7197\n",
      "Epoch 274/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13380.1084 - val_loss: 11995.9541\n",
      "Epoch 275/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13420.3301 - val_loss: 11991.7305\n",
      "Epoch 276/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13356.1641 - val_loss: 11967.8525\n",
      "Epoch 277/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13233.1699 - val_loss: 11977.9619\n",
      "Epoch 278/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13039.2656 - val_loss: 11963.0400\n",
      "Epoch 279/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13376.3584 - val_loss: 12062.9297\n",
      "Epoch 280/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13258.0449 - val_loss: 11901.0410\n",
      "Epoch 281/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13524.0410 - val_loss: 11967.1523\n",
      "Epoch 282/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13170.0137 - val_loss: 11927.7471\n",
      "Epoch 283/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13086.1523 - val_loss: 11957.1182\n",
      "Epoch 284/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13467.0068 - val_loss: 12037.3643\n",
      "Epoch 285/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13272.2021 - val_loss: 12043.6992\n",
      "Epoch 286/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13339.6953 - val_loss: 12075.7939\n",
      "Epoch 287/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13208.7549 - val_loss: 11942.1133\n",
      "Epoch 288/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13534.9863 - val_loss: 11895.5039\n",
      "Epoch 289/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13300.9424 - val_loss: 11921.9785\n",
      "Epoch 290/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13484.4355 - val_loss: 11974.3516\n",
      "Epoch 291/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13387.2676 - val_loss: 11945.1182\n",
      "Epoch 292/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13323.3643 - val_loss: 12053.6650\n",
      "Epoch 293/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13197.5244 - val_loss: 12161.3066\n",
      "Epoch 294/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13263.7236 - val_loss: 11883.1357\n",
      "Epoch 295/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13435.8232 - val_loss: 11935.9346\n",
      "Epoch 296/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13215.0879 - val_loss: 11947.6387\n",
      "Epoch 297/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13268.2988 - val_loss: 11926.1025\n",
      "Epoch 298/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13310.2207 - val_loss: 11857.2598\n",
      "Epoch 299/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13159.5420 - val_loss: 11901.4775\n",
      "Epoch 300/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13289.8613 - val_loss: 12016.8818\n",
      "Epoch 301/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13063.9932 - val_loss: 12124.5498\n",
      "Epoch 302/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13304.6523 - val_loss: 12062.3486\n",
      "Epoch 303/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13328.1641 - val_loss: 11874.4268\n",
      "Epoch 304/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13360.2402 - val_loss: 11971.2158\n",
      "Epoch 305/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13203.2422 - val_loss: 12110.1348\n",
      "Epoch 306/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13279.0332 - val_loss: 12012.1260\n",
      "Epoch 307/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13291.6367 - val_loss: 12043.2275\n",
      "Epoch 308/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13167.0967 - val_loss: 11968.8984\n",
      "Epoch 309/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13520.1924 - val_loss: 11891.8350\n",
      "Epoch 310/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13446.8730 - val_loss: 11919.4502\n",
      "Epoch 311/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13193.6709 - val_loss: 11840.5273\n",
      "Epoch 312/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13364.1895 - val_loss: 11970.7852\n",
      "Epoch 313/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13406.9102 - val_loss: 11867.8818\n",
      "Epoch 314/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13173.3975 - val_loss: 11842.9531\n",
      "Epoch 315/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13255.0459 - val_loss: 11961.9727\n",
      "Epoch 316/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13340.6230 - val_loss: 12013.3887\n",
      "Epoch 317/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13496.4424 - val_loss: 11818.3965\n",
      "Epoch 318/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13407.3086 - val_loss: 12113.1182\n",
      "Epoch 319/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13102.9551 - val_loss: 11905.4883\n",
      "Epoch 320/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13297.1348 - val_loss: 11908.3135\n",
      "Epoch 321/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13226.7656 - val_loss: 12056.5039\n",
      "Epoch 322/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13031.7334 - val_loss: 11975.8330\n",
      "Epoch 323/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13244.4971 - val_loss: 12117.0059\n",
      "Epoch 324/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13100.7207 - val_loss: 12020.6865\n",
      "Epoch 325/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13195.4775 - val_loss: 12096.5322\n",
      "Epoch 326/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13187.2246 - val_loss: 12089.0771\n",
      "Epoch 327/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12992.5156 - val_loss: 11928.4141\n",
      "Epoch 328/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13267.6787 - val_loss: 11944.2959\n",
      "Epoch 329/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13284.4707 - val_loss: 12027.7041\n",
      "Epoch 330/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13032.0225 - val_loss: 11824.4961\n",
      "Epoch 331/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13228.3721 - val_loss: 11894.4531\n",
      "Epoch 332/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13367.4863 - val_loss: 12007.4092\n",
      "Epoch 333/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13225.1982 - val_loss: 11945.2158\n",
      "Epoch 334/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13370.9258 - val_loss: 11955.8936\n",
      "Epoch 335/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13437.2002 - val_loss: 12017.5957\n",
      "Epoch 336/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13311.8711 - val_loss: 11969.4756\n",
      "Epoch 337/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13248.6260 - val_loss: 12031.0078\n",
      "Epoch 338/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13330.5039 - val_loss: 12071.7217\n",
      "Epoch 339/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13124.5967 - val_loss: 12000.0215\n",
      "Epoch 340/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13393.2881 - val_loss: 12064.9844\n",
      "Epoch 341/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12997.4697 - val_loss: 11907.8896\n",
      "Epoch 342/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12927.1787 - val_loss: 11798.8584\n",
      "Epoch 343/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13168.3828 - val_loss: 11899.1006\n",
      "Epoch 344/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13451.0684 - val_loss: 11913.0430\n",
      "Epoch 345/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13141.9570 - val_loss: 11824.1367\n",
      "Epoch 346/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13353.5693 - val_loss: 11873.2197\n",
      "Epoch 347/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13128.6465 - val_loss: 11939.9365\n",
      "Epoch 348/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13251.8242 - val_loss: 12052.7178\n",
      "Epoch 349/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13100.5596 - val_loss: 11827.3223\n",
      "Epoch 350/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13356.8994 - val_loss: 11873.0684\n",
      "Epoch 351/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13226.6143 - val_loss: 11970.2422\n",
      "Epoch 352/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13374.0596 - val_loss: 11975.4863\n",
      "Epoch 353/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13271.3145 - val_loss: 11936.0156\n",
      "Epoch 354/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13275.0762 - val_loss: 12050.1289\n",
      "Epoch 355/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13303.2529 - val_loss: 11971.2480\n",
      "Epoch 356/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13213.5059 - val_loss: 11985.5176\n",
      "Epoch 357/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13256.8711 - val_loss: 11823.1924\n",
      "Epoch 358/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13284.3896 - val_loss: 11978.5254\n",
      "Epoch 359/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13198.5146 - val_loss: 11844.3711\n",
      "Epoch 360/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13371.0439 - val_loss: 11863.2344\n",
      "Epoch 361/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13108.7891 - val_loss: 12278.8926\n",
      "Epoch 362/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13085.2080 - val_loss: 11866.9658\n",
      "Epoch 363/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13165.9189 - val_loss: 11945.2471\n",
      "Epoch 364/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13309.2363 - val_loss: 12047.4717\n",
      "Epoch 365/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13113.4092 - val_loss: 11893.2041\n",
      "Epoch 366/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13224.3066 - val_loss: 12003.8701\n",
      "Epoch 367/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13378.8857 - val_loss: 11869.0771\n",
      "Epoch 368/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13234.0098 - val_loss: 11928.9600\n",
      "Epoch 369/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13447.2295 - val_loss: 11822.1514\n",
      "Epoch 370/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13143.8652 - val_loss: 11954.9092\n",
      "Epoch 371/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13322.7344 - val_loss: 12189.9727\n",
      "Epoch 372/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13312.6455 - val_loss: 12039.4189\n",
      "Epoch 373/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13290.3105 - val_loss: 11784.6562\n",
      "Epoch 374/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13426.5449 - val_loss: 11875.5381\n",
      "Epoch 375/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13094.7461 - val_loss: 11907.0664\n",
      "Epoch 376/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12834.4287 - val_loss: 11797.8262\n",
      "Epoch 377/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13163.0811 - val_loss: 11972.0928\n",
      "Epoch 378/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13317.6348 - val_loss: 11843.9502\n",
      "Epoch 379/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13218.8525 - val_loss: 12031.9727\n",
      "Epoch 380/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13354.2178 - val_loss: 12223.5850\n",
      "Epoch 381/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13334.5918 - val_loss: 11901.4014\n",
      "Epoch 382/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13272.2500 - val_loss: 11785.4209\n",
      "Epoch 383/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13247.0615 - val_loss: 11970.2959\n",
      "Epoch 384/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12811.1680 - val_loss: 11923.9375\n",
      "Epoch 385/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13055.7100 - val_loss: 11965.7881\n",
      "Epoch 386/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13171.9736 - val_loss: 11957.1025\n",
      "Epoch 387/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12972.9688 - val_loss: 11853.8027\n",
      "Epoch 388/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13237.8340 - val_loss: 11934.9961\n",
      "Epoch 389/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13172.7979 - val_loss: 11853.1416\n",
      "Epoch 390/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13201.8008 - val_loss: 11979.2344\n",
      "Epoch 391/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13481.3555 - val_loss: 11847.2061\n",
      "Epoch 392/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13106.9316 - val_loss: 12036.2822\n",
      "Epoch 393/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13191.0361 - val_loss: 11926.8135\n",
      "Epoch 394/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12993.9033 - val_loss: 11918.2930\n",
      "Epoch 395/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13319.1445 - val_loss: 11861.2471\n",
      "Epoch 396/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13053.1592 - val_loss: 11847.9355\n",
      "Epoch 397/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12867.4688 - val_loss: 12096.9307\n",
      "Epoch 398/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12892.2158 - val_loss: 11846.3975\n",
      "Epoch 399/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13306.7871 - val_loss: 11719.6064\n",
      "Epoch 400/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13422.5615 - val_loss: 11759.8711\n",
      "Epoch 401/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13152.7402 - val_loss: 11886.7383\n",
      "Epoch 402/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13488.7480 - val_loss: 11913.4756\n",
      "Epoch 403/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13076.3311 - val_loss: 11851.3408\n",
      "Epoch 404/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13131.0352 - val_loss: 11833.0811\n",
      "Epoch 405/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12791.7168 - val_loss: 11775.0635\n",
      "Epoch 406/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13312.5918 - val_loss: 11854.6221\n",
      "Epoch 407/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13221.0674 - val_loss: 11863.7871\n",
      "Epoch 408/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13057.5137 - val_loss: 11751.8389\n",
      "Epoch 409/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13052.1318 - val_loss: 11903.6826\n",
      "Epoch 410/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13361.3516 - val_loss: 11900.0430\n",
      "Epoch 411/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13142.5508 - val_loss: 11980.1982\n",
      "Epoch 412/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13198.1465 - val_loss: 12071.9502\n",
      "Epoch 413/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13061.5381 - val_loss: 11953.8213\n",
      "Epoch 414/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13041.0059 - val_loss: 11921.7041\n",
      "Epoch 415/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13148.7793 - val_loss: 11856.3721\n",
      "Epoch 416/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13254.7627 - val_loss: 11824.3779\n",
      "Epoch 417/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13421.7422 - val_loss: 11847.2646\n",
      "Epoch 418/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13156.1846 - val_loss: 11720.0811\n",
      "Epoch 419/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13441.3457 - val_loss: 11819.6504\n",
      "Epoch 420/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13261.6719 - val_loss: 11859.9883\n",
      "Epoch 421/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13383.5400 - val_loss: 11732.2119\n",
      "Epoch 422/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13045.3535 - val_loss: 11942.3184\n",
      "Epoch 423/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13290.3760 - val_loss: 11896.7334\n",
      "Epoch 424/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13084.7891 - val_loss: 11768.0654\n",
      "Epoch 425/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13357.5068 - val_loss: 12005.5605\n",
      "Epoch 426/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12999.1064 - val_loss: 11878.1963\n",
      "Epoch 427/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13184.0938 - val_loss: 11934.8457\n",
      "Epoch 428/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13303.3877 - val_loss: 12037.4756\n",
      "Epoch 429/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13163.5977 - val_loss: 11964.0439\n",
      "Epoch 430/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13103.1436 - val_loss: 12012.7344\n",
      "Epoch 431/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13194.7373 - val_loss: 11919.6738\n",
      "Epoch 432/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13190.5576 - val_loss: 11980.5977\n",
      "Epoch 433/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13214.3115 - val_loss: 11868.7559\n",
      "Epoch 434/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13202.8184 - val_loss: 11922.1172\n",
      "Epoch 435/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13212.3174 - val_loss: 12155.1504\n",
      "Epoch 436/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13378.5938 - val_loss: 11948.6465\n",
      "Epoch 437/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13327.0400 - val_loss: 11939.7246\n",
      "Epoch 438/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13201.3965 - val_loss: 11922.3428\n",
      "Epoch 439/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13086.9258 - val_loss: 11923.2949\n",
      "Epoch 440/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13387.1758 - val_loss: 12014.5938\n",
      "Epoch 441/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13072.2158 - val_loss: 12106.7178\n",
      "Epoch 442/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13172.9775 - val_loss: 12082.3877\n",
      "Epoch 443/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13087.7480 - val_loss: 12076.0273\n",
      "Epoch 444/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13209.4971 - val_loss: 11952.7754\n",
      "Epoch 445/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13180.0029 - val_loss: 11902.3467\n",
      "Epoch 446/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13203.9561 - val_loss: 11990.3662\n",
      "Epoch 447/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13087.9434 - val_loss: 11949.0391\n",
      "Epoch 448/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13232.1074 - val_loss: 11827.6885\n",
      "Epoch 449/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13063.7559 - val_loss: 12042.7754\n",
      "Epoch 450/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12830.9756 - val_loss: 11923.1055\n",
      "Epoch 451/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12970.3633 - val_loss: 11838.6260\n",
      "Epoch 452/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12849.8545 - val_loss: 12051.6104\n",
      "Epoch 453/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13371.4756 - val_loss: 11868.6836\n",
      "Epoch 454/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13265.1162 - val_loss: 11872.4014\n",
      "Epoch 455/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13197.9004 - val_loss: 11805.3408\n",
      "Epoch 456/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12998.6709 - val_loss: 11895.5127\n",
      "Epoch 457/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13204.9570 - val_loss: 11862.1484\n",
      "Epoch 458/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13102.3438 - val_loss: 11862.1631\n",
      "Epoch 459/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13096.6494 - val_loss: 11843.0410\n",
      "Epoch 460/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13177.5801 - val_loss: 12086.9863\n",
      "Epoch 461/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13293.1113 - val_loss: 11784.6865\n",
      "Epoch 462/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13054.0693 - val_loss: 12006.9629\n",
      "Epoch 463/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13074.8916 - val_loss: 12045.1289\n",
      "Epoch 464/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13281.6963 - val_loss: 11832.4443\n",
      "Epoch 465/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13002.2559 - val_loss: 11808.6123\n",
      "Epoch 466/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12985.5986 - val_loss: 11978.3760\n",
      "Epoch 467/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13105.0820 - val_loss: 11884.1738\n",
      "Epoch 468/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13426.5234 - val_loss: 11748.5713\n",
      "Epoch 469/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12986.3428 - val_loss: 11804.0254\n",
      "Epoch 470/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13262.4941 - val_loss: 11818.0234\n",
      "Epoch 471/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13187.3916 - val_loss: 11740.2656\n",
      "Epoch 472/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13309.3105 - val_loss: 11891.7998\n",
      "Epoch 473/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13325.9482 - val_loss: 11717.1309\n",
      "Epoch 474/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13061.5264 - val_loss: 11819.6592\n",
      "Epoch 475/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13275.8398 - val_loss: 11845.3799\n",
      "Epoch 476/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13304.6494 - val_loss: 12020.0283\n",
      "Epoch 477/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13163.6113 - val_loss: 11817.0137\n",
      "Epoch 478/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13104.5049 - val_loss: 12079.0225\n",
      "Epoch 479/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12987.5488 - val_loss: 11757.2529\n",
      "Epoch 480/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13157.6719 - val_loss: 11713.1855\n",
      "Epoch 481/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13299.1465 - val_loss: 11750.4570\n",
      "Epoch 482/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13248.7373 - val_loss: 11995.4316\n",
      "Epoch 483/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13372.6797 - val_loss: 11997.3467\n",
      "Epoch 484/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13030.3330 - val_loss: 11956.0771\n",
      "Epoch 485/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13107.1475 - val_loss: 11890.4580\n",
      "Epoch 486/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13271.0176 - val_loss: 11814.7520\n",
      "Epoch 487/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13138.2549 - val_loss: 11820.8232\n",
      "Epoch 488/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13036.7100 - val_loss: 11851.9395\n",
      "Epoch 489/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13226.2197 - val_loss: 11914.0449\n",
      "Epoch 490/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13194.4355 - val_loss: 11771.0664\n",
      "Epoch 491/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13072.0781 - val_loss: 12014.9043\n",
      "Epoch 492/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13229.4971 - val_loss: 11836.7324\n",
      "Epoch 493/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13277.2881 - val_loss: 11746.7256\n",
      "Epoch 494/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13284.8867 - val_loss: 12036.9346\n",
      "Epoch 495/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13027.1621 - val_loss: 12100.8916\n",
      "Epoch 496/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13206.5459 - val_loss: 12139.8760\n",
      "Epoch 497/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13216.6055 - val_loss: 11879.5693\n",
      "Epoch 498/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13085.3418 - val_loss: 11860.6230\n",
      "Epoch 499/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13054.5615 - val_loss: 11727.1924\n",
      "Epoch 500/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13222.3281 - val_loss: 11908.6533\n",
      "Epoch 501/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13166.7471 - val_loss: 11938.9326\n",
      "Epoch 502/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13367.8496 - val_loss: 11972.9727\n",
      "Epoch 503/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13323.1387 - val_loss: 11905.2891\n",
      "Epoch 504/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13250.0986 - val_loss: 11849.3555\n",
      "Epoch 505/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13277.9326 - val_loss: 11920.5332\n",
      "Epoch 506/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13048.1777 - val_loss: 11838.2295\n",
      "Epoch 507/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12990.0576 - val_loss: 11810.7686\n",
      "Epoch 508/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13249.3984 - val_loss: 11754.1260\n",
      "Epoch 509/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13193.9678 - val_loss: 11915.3721\n",
      "Epoch 510/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13125.5967 - val_loss: 11949.8047\n",
      "Epoch 511/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13216.1279 - val_loss: 11980.5078\n",
      "Epoch 512/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13130.8535 - val_loss: 11934.5957\n",
      "Epoch 513/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13119.8057 - val_loss: 11917.9355\n",
      "Epoch 514/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13035.8096 - val_loss: 11743.5918\n",
      "Epoch 515/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13072.3281 - val_loss: 11841.4766\n",
      "Epoch 516/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13117.7812 - val_loss: 11801.3574\n",
      "Epoch 517/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12987.0352 - val_loss: 11856.8945\n",
      "Epoch 518/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13029.6113 - val_loss: 11831.0195\n",
      "Epoch 519/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13224.7061 - val_loss: 12023.8174\n",
      "Epoch 520/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13216.7471 - val_loss: 11971.0840\n",
      "Epoch 521/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13141.6895 - val_loss: 11889.5303\n",
      "Epoch 522/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13349.0293 - val_loss: 11944.8516\n",
      "Epoch 523/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13170.5283 - val_loss: 11970.9209\n",
      "Epoch 524/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12973.6416 - val_loss: 11917.2236\n",
      "Epoch 525/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13194.7695 - val_loss: 11833.5703\n",
      "Epoch 526/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13204.6367 - val_loss: 11921.6865\n",
      "Epoch 527/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13238.6777 - val_loss: 11839.7637\n",
      "Epoch 528/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13149.9482 - val_loss: 11840.7773\n",
      "Epoch 529/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13119.9336 - val_loss: 11894.5078\n",
      "Epoch 530/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13215.4229 - val_loss: 11987.5605\n",
      "Epoch 531/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13134.1338 - val_loss: 11869.1396\n",
      "Epoch 532/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13294.1279 - val_loss: 11914.7354\n",
      "Epoch 533/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13353.4131 - val_loss: 12021.3193\n",
      "Epoch 534/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13212.6143 - val_loss: 11733.1895\n",
      "Epoch 535/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13393.6846 - val_loss: 11889.5742\n",
      "Epoch 536/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13218.8643 - val_loss: 11826.8174\n",
      "Epoch 537/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12887.3359 - val_loss: 11817.5195\n",
      "Epoch 538/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13078.2881 - val_loss: 11862.4756\n",
      "Epoch 539/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12929.5459 - val_loss: 11901.3984\n",
      "Epoch 540/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13359.5195 - val_loss: 11883.0049\n",
      "Epoch 541/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13180.0508 - val_loss: 11714.9932\n",
      "Epoch 542/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13189.6777 - val_loss: 11653.0986\n",
      "Epoch 543/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13386.2373 - val_loss: 11787.5557\n",
      "Epoch 544/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13269.8564 - val_loss: 11882.9912\n",
      "Epoch 545/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13117.3203 - val_loss: 11870.2969\n",
      "Epoch 546/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12950.5391 - val_loss: 11861.3408\n",
      "Epoch 547/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13132.5518 - val_loss: 11735.8789\n",
      "Epoch 548/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13185.9619 - val_loss: 11912.7637\n",
      "Epoch 549/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12980.8604 - val_loss: 11758.2119\n",
      "Epoch 550/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13133.7637 - val_loss: 11864.1562\n",
      "Epoch 551/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13071.2070 - val_loss: 11753.0977\n",
      "Epoch 552/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12978.0811 - val_loss: 11809.4873\n",
      "Epoch 553/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13089.5908 - val_loss: 11702.5723\n",
      "Epoch 554/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13135.2744 - val_loss: 11755.3936\n",
      "Epoch 555/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13326.3096 - val_loss: 11890.8711\n",
      "Epoch 556/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13307.1357 - val_loss: 11999.3545\n",
      "Epoch 557/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13090.4658 - val_loss: 11942.8096\n",
      "Epoch 558/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13193.5205 - val_loss: 11801.8916\n",
      "Epoch 559/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13119.1709 - val_loss: 12001.7842\n",
      "Epoch 560/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13138.6182 - val_loss: 11744.8564\n",
      "Epoch 561/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13074.7070 - val_loss: 12063.5469\n",
      "Epoch 562/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13082.5000 - val_loss: 11886.1553\n",
      "Epoch 563/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13101.8311 - val_loss: 12083.0186\n",
      "Epoch 564/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13268.6719 - val_loss: 11720.9434\n",
      "Epoch 565/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12925.7930 - val_loss: 11879.1104\n",
      "Epoch 566/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13006.4746 - val_loss: 11778.2744\n",
      "Epoch 567/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13290.5244 - val_loss: 11859.6279\n",
      "Epoch 568/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13276.1162 - val_loss: 11836.4053\n",
      "Epoch 569/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12949.8086 - val_loss: 11927.0498\n",
      "Epoch 570/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13092.8525 - val_loss: 12007.1133\n",
      "Epoch 571/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13064.8232 - val_loss: 11803.1875\n",
      "Epoch 572/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13187.1768 - val_loss: 11927.7334\n",
      "Epoch 573/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13204.7861 - val_loss: 11758.5566\n",
      "Epoch 574/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13265.0459 - val_loss: 11985.1455\n",
      "Epoch 575/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13183.7539 - val_loss: 11798.3037\n",
      "Epoch 576/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12989.1914 - val_loss: 11941.6562\n",
      "Epoch 577/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13091.0303 - val_loss: 11907.8184\n",
      "Epoch 578/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13049.9385 - val_loss: 11839.5654\n",
      "Epoch 579/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13279.5000 - val_loss: 11795.1797\n",
      "Epoch 580/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13053.6641 - val_loss: 11835.3486\n",
      "Epoch 581/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13129.5957 - val_loss: 11807.5830\n",
      "Epoch 582/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13083.8291 - val_loss: 11814.3477\n",
      "Epoch 583/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13164.1768 - val_loss: 11890.8350\n",
      "Epoch 584/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13099.9688 - val_loss: 11881.2158\n",
      "Epoch 585/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13074.7979 - val_loss: 11738.6904\n",
      "Epoch 586/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13306.5596 - val_loss: 11740.2227\n",
      "Epoch 587/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13445.9443 - val_loss: 11863.9482\n",
      "Epoch 588/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13240.5254 - val_loss: 11773.0166\n",
      "Epoch 589/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13287.6758 - val_loss: 11909.4766\n",
      "Epoch 590/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13397.7334 - val_loss: 11983.5977\n",
      "Epoch 591/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13291.0674 - val_loss: 11829.4424\n",
      "Epoch 592/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13179.1387 - val_loss: 12237.2217\n",
      "Epoch 593/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13133.7744 - val_loss: 12146.7148\n",
      "Epoch 594/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13117.3311 - val_loss: 11992.7617\n",
      "Epoch 595/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13227.6260 - val_loss: 11932.5039\n",
      "Epoch 596/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12895.3984 - val_loss: 11941.4180\n",
      "Epoch 597/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12922.7969 - val_loss: 11803.9697\n",
      "Epoch 598/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13023.6211 - val_loss: 11869.1436\n",
      "Epoch 599/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12890.7031 - val_loss: 12003.4482\n",
      "Epoch 600/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13283.7070 - val_loss: 12152.8809\n",
      "Epoch 601/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13148.4395 - val_loss: 11738.0547\n",
      "Epoch 602/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12986.1084 - val_loss: 11925.0479\n",
      "Epoch 603/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13213.5938 - val_loss: 12087.7686\n",
      "Epoch 604/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13176.5889 - val_loss: 11986.3164\n",
      "Epoch 605/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13093.0527 - val_loss: 11782.7158\n",
      "Epoch 606/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13124.5977 - val_loss: 11944.3945\n",
      "Epoch 607/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13330.9219 - val_loss: 12203.6240\n",
      "Epoch 608/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13325.1348 - val_loss: 11877.7607\n",
      "Epoch 609/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13178.7559 - val_loss: 11891.4541\n",
      "Epoch 610/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13120.4795 - val_loss: 11963.3818\n",
      "Epoch 611/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13277.7021 - val_loss: 11872.5850\n",
      "Epoch 612/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13340.3828 - val_loss: 11835.2334\n",
      "Epoch 613/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13143.4092 - val_loss: 11994.7207\n",
      "Epoch 614/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13031.2891 - val_loss: 11749.2227\n",
      "Epoch 615/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13123.5156 - val_loss: 11868.7910\n",
      "Epoch 616/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13208.2207 - val_loss: 11976.5029\n",
      "Epoch 617/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13347.9316 - val_loss: 12004.5342\n",
      "Epoch 618/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13218.6318 - val_loss: 11749.8330\n",
      "Epoch 619/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13036.7119 - val_loss: 11826.6895\n",
      "Epoch 620/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13357.4277 - val_loss: 11790.8691\n",
      "Epoch 621/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13381.0361 - val_loss: 11734.0127\n",
      "Epoch 622/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13119.2900 - val_loss: 11846.4648\n",
      "Epoch 623/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13135.6104 - val_loss: 11933.9844\n",
      "Epoch 624/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13048.9307 - val_loss: 11813.8438\n",
      "Epoch 625/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13280.1729 - val_loss: 12026.1797\n",
      "Epoch 626/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13116.4658 - val_loss: 11771.9346\n",
      "Epoch 627/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13071.5498 - val_loss: 11716.0205\n",
      "Epoch 628/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13105.7285 - val_loss: 11838.1680\n",
      "Epoch 629/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13004.4629 - val_loss: 11809.2578\n",
      "Epoch 630/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13252.8867 - val_loss: 11786.3193\n",
      "Epoch 631/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13253.2588 - val_loss: 11802.4326\n",
      "Epoch 632/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12987.2900 - val_loss: 11841.1348\n",
      "Epoch 633/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13036.2959 - val_loss: 11925.8877\n",
      "Epoch 634/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13335.2822 - val_loss: 11805.2725\n",
      "Epoch 635/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13103.6016 - val_loss: 11756.2109\n",
      "Epoch 636/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13264.8467 - val_loss: 11969.0088\n",
      "Epoch 637/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13039.4854 - val_loss: 11961.1221\n",
      "Epoch 638/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13017.5283 - val_loss: 11759.7559\n",
      "Epoch 639/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13062.1846 - val_loss: 11811.4766\n",
      "Epoch 640/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13248.8652 - val_loss: 11854.9268\n",
      "Epoch 641/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13297.2344 - val_loss: 11853.2773\n",
      "Epoch 642/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13274.7861 - val_loss: 11961.1045\n",
      "Epoch 643/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13161.5010 - val_loss: 11889.9238\n",
      "Epoch 644/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12947.8760 - val_loss: 11943.6455\n",
      "Epoch 645/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13209.2598 - val_loss: 11715.4834\n",
      "Epoch 646/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12850.4756 - val_loss: 11907.7959\n",
      "Epoch 647/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13003.6084 - val_loss: 11948.7559\n",
      "Epoch 648/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13416.3311 - val_loss: 12003.1504\n",
      "Epoch 649/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13050.3320 - val_loss: 11895.5508\n",
      "Epoch 650/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13068.6855 - val_loss: 12024.2998\n",
      "Epoch 651/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13068.5654 - val_loss: 11894.1455\n",
      "Epoch 652/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12992.8701 - val_loss: 11714.3584\n",
      "Epoch 653/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13156.5010 - val_loss: 11834.4336\n",
      "Epoch 654/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13034.0967 - val_loss: 11859.9023\n",
      "Epoch 655/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13106.0488 - val_loss: 11932.6299\n",
      "Epoch 656/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13066.8496 - val_loss: 11969.6953\n",
      "Epoch 657/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13181.8555 - val_loss: 11739.8105\n",
      "Epoch 658/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13306.5684 - val_loss: 11956.3545\n",
      "Epoch 659/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13113.7236 - val_loss: 11732.1348\n",
      "Epoch 660/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13371.5664 - val_loss: 11816.0137\n",
      "Epoch 661/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13074.5537 - val_loss: 11818.7988\n",
      "Epoch 662/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12979.2500 - val_loss: 11931.6230\n",
      "Epoch 663/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13074.4570 - val_loss: 11763.3984\n",
      "Epoch 664/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13115.7109 - val_loss: 11844.9990\n",
      "Epoch 665/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13357.7129 - val_loss: 12003.2383\n",
      "Epoch 666/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13186.2891 - val_loss: 11836.3447\n",
      "Epoch 667/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13020.3438 - val_loss: 11774.7188\n",
      "Epoch 668/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13153.7881 - val_loss: 11702.8682\n",
      "Epoch 669/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13151.0410 - val_loss: 11645.5938\n",
      "Epoch 670/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13038.3408 - val_loss: 11823.1006\n",
      "Epoch 671/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12976.2090 - val_loss: 11872.8984\n",
      "Epoch 672/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13232.4189 - val_loss: 11888.9033\n",
      "Epoch 673/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13132.8779 - val_loss: 11871.7754\n",
      "Epoch 674/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13134.6113 - val_loss: 11977.8584\n",
      "Epoch 675/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13263.6875 - val_loss: 11896.4434\n",
      "Epoch 676/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13229.6211 - val_loss: 11915.2607\n",
      "Epoch 677/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13091.8564 - val_loss: 11731.2432\n",
      "Epoch 678/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13323.5938 - val_loss: 11990.8193\n",
      "Epoch 679/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13030.2510 - val_loss: 11808.0605\n",
      "Epoch 680/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13281.5703 - val_loss: 11750.6729\n",
      "Epoch 681/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13311.4717 - val_loss: 11797.3340\n",
      "Epoch 682/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13003.0615 - val_loss: 11921.2471\n",
      "Epoch 683/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13047.7383 - val_loss: 11894.0010\n",
      "Epoch 684/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12975.4541 - val_loss: 11841.9570\n",
      "Epoch 685/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13051.6621 - val_loss: 11869.6963\n",
      "Epoch 686/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13305.6455 - val_loss: 11816.8896\n",
      "Epoch 687/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13124.9141 - val_loss: 11807.2109\n",
      "Epoch 688/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12965.4678 - val_loss: 11813.4385\n",
      "Epoch 689/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13077.8926 - val_loss: 11710.5469\n",
      "Epoch 690/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13080.3848 - val_loss: 11753.6338\n",
      "Epoch 691/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12854.7197 - val_loss: 11735.5439\n",
      "Epoch 692/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13044.4648 - val_loss: 11789.4941\n",
      "Epoch 693/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13114.8047 - val_loss: 11819.9189\n",
      "Epoch 694/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13112.8438 - val_loss: 11879.8086\n",
      "Epoch 695/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13047.1064 - val_loss: 11905.5566\n",
      "Epoch 696/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13106.5029 - val_loss: 11862.8213\n",
      "Epoch 697/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13306.7520 - val_loss: 11800.2109\n",
      "Epoch 698/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13237.8555 - val_loss: 11750.5605\n",
      "Epoch 699/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13177.9102 - val_loss: 11918.8154\n",
      "Epoch 700/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13145.2041 - val_loss: 11969.7939\n",
      "Epoch 701/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13016.0127 - val_loss: 11870.0332\n",
      "Epoch 702/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13205.0479 - val_loss: 11754.7520\n",
      "Epoch 703/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13038.1895 - val_loss: 11883.8193\n",
      "Epoch 704/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13281.4863 - val_loss: 11823.7158\n",
      "Epoch 705/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13209.1172 - val_loss: 11887.1484\n",
      "Epoch 706/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13091.1904 - val_loss: 11924.8076\n",
      "Epoch 707/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13292.2520 - val_loss: 12029.7178\n",
      "Epoch 708/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13150.4668 - val_loss: 11872.5566\n",
      "Epoch 709/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12999.3457 - val_loss: 11671.7422\n",
      "Epoch 710/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13030.9102 - val_loss: 11666.4639\n",
      "Epoch 711/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13097.6758 - val_loss: 11854.9609\n",
      "Epoch 712/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13212.3428 - val_loss: 11820.8174\n",
      "Epoch 713/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13159.0029 - val_loss: 12015.9521\n",
      "Epoch 714/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12984.2119 - val_loss: 11960.5254\n",
      "Epoch 715/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13196.6709 - val_loss: 11724.9365\n",
      "Epoch 716/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13190.7598 - val_loss: 11829.2256\n",
      "Epoch 717/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13187.5488 - val_loss: 11875.4297\n",
      "Epoch 718/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13061.4072 - val_loss: 12020.1133\n",
      "Epoch 719/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13120.3096 - val_loss: 11822.7256\n",
      "Epoch 720/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13034.8291 - val_loss: 11847.9209\n",
      "Epoch 721/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13361.4150 - val_loss: 11909.6113\n",
      "Epoch 722/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12987.0986 - val_loss: 11883.6172\n",
      "Epoch 723/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13315.3164 - val_loss: 11780.7803\n",
      "Epoch 724/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13121.1582 - val_loss: 11835.1855\n",
      "Epoch 725/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12999.4443 - val_loss: 11705.4609\n",
      "Epoch 726/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13287.7637 - val_loss: 11756.2832\n",
      "Epoch 727/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13150.2686 - val_loss: 11833.7852\n",
      "Epoch 728/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13306.9424 - val_loss: 12045.7979\n",
      "Epoch 729/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13297.9795 - val_loss: 11750.5557\n",
      "Epoch 730/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13090.6943 - val_loss: 11908.2539\n",
      "Epoch 731/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13004.4355 - val_loss: 11882.3848\n",
      "Epoch 732/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13119.9717 - val_loss: 11912.8770\n",
      "Epoch 733/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13124.0918 - val_loss: 11659.9473\n",
      "Epoch 734/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13314.1904 - val_loss: 11904.0205\n",
      "Epoch 735/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13207.2500 - val_loss: 11815.2295\n",
      "Epoch 736/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13016.4170 - val_loss: 11789.4209\n",
      "Epoch 737/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13019.0010 - val_loss: 11869.5400\n",
      "Epoch 738/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13077.0195 - val_loss: 11943.8662\n",
      "Epoch 739/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13244.3887 - val_loss: 11658.5332\n",
      "Epoch 740/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13143.8477 - val_loss: 11784.5742\n",
      "Epoch 741/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12770.0742 - val_loss: 11928.5322\n",
      "Epoch 742/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12925.5459 - val_loss: 11841.3340\n",
      "Epoch 743/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13043.3643 - val_loss: 11768.0654\n",
      "Epoch 744/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13049.6699 - val_loss: 11805.4912\n",
      "Epoch 745/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13068.6484 - val_loss: 11814.9160\n",
      "Epoch 746/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13248.2227 - val_loss: 11757.9775\n",
      "Epoch 747/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13102.2461 - val_loss: 11765.3779\n",
      "Epoch 748/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13267.0215 - val_loss: 11818.5381\n",
      "Epoch 749/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13321.5039 - val_loss: 11920.6660\n",
      "Epoch 750/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13293.0625 - val_loss: 11736.9824\n",
      "Epoch 751/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13006.5020 - val_loss: 11930.3242\n",
      "Epoch 752/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13237.2656 - val_loss: 11719.6279\n",
      "Epoch 753/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13307.6484 - val_loss: 11921.3652\n",
      "Epoch 754/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13211.9092 - val_loss: 11923.4365\n",
      "Epoch 755/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13081.4121 - val_loss: 11681.0527\n",
      "Epoch 756/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13309.0898 - val_loss: 11947.4707\n",
      "Epoch 757/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13132.7305 - val_loss: 11698.3408\n",
      "Epoch 758/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13178.7861 - val_loss: 11780.8291\n",
      "Epoch 759/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13044.4844 - val_loss: 12030.8203\n",
      "Epoch 760/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12688.8018 - val_loss: 11854.2500\n",
      "Epoch 761/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13184.5186 - val_loss: 11772.3223\n",
      "Epoch 762/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13171.8398 - val_loss: 11734.1914\n",
      "Epoch 763/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13186.4668 - val_loss: 12031.4600\n",
      "Epoch 764/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13188.8545 - val_loss: 11920.4014\n",
      "Epoch 765/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13012.4492 - val_loss: 11941.6250\n",
      "Epoch 766/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13039.0488 - val_loss: 11785.4404\n",
      "Epoch 767/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13362.1562 - val_loss: 11751.3555\n",
      "Epoch 768/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13061.5508 - val_loss: 11825.4287\n",
      "Epoch 769/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12948.0957 - val_loss: 11839.1699\n",
      "Epoch 770/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13190.2939 - val_loss: 11813.0137\n",
      "Epoch 771/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13264.9961 - val_loss: 11800.2344\n",
      "Epoch 772/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12944.4277 - val_loss: 11977.9355\n",
      "Epoch 773/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13158.0283 - val_loss: 12021.2744\n",
      "Epoch 774/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13129.6006 - val_loss: 11785.3379\n",
      "Epoch 775/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13020.2051 - val_loss: 11914.6816\n",
      "Epoch 776/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13047.4268 - val_loss: 11992.6064\n",
      "Epoch 777/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13221.3418 - val_loss: 11852.3506\n",
      "Epoch 778/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13209.0264 - val_loss: 11918.5996\n",
      "Epoch 779/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13148.4902 - val_loss: 12047.1230\n",
      "Epoch 780/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12990.1611 - val_loss: 11936.6260\n",
      "Epoch 781/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13087.3594 - val_loss: 12000.4922\n",
      "Epoch 782/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13087.7363 - val_loss: 11876.0986\n",
      "Epoch 783/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13246.8252 - val_loss: 11747.8105\n",
      "Epoch 784/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12839.2344 - val_loss: 12020.0537\n",
      "Epoch 785/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13146.7969 - val_loss: 11746.0293\n",
      "Epoch 786/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12902.5752 - val_loss: 11875.2695\n",
      "Epoch 787/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13402.0488 - val_loss: 11963.1035\n",
      "Epoch 788/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12804.6406 - val_loss: 11809.2129\n",
      "Epoch 789/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12996.4287 - val_loss: 11873.3818\n",
      "Epoch 790/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13282.9873 - val_loss: 11725.5850\n",
      "Epoch 791/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12949.4238 - val_loss: 11909.8164\n",
      "Epoch 792/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13006.8857 - val_loss: 11846.6250\n",
      "Epoch 793/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13090.8232 - val_loss: 11945.1367\n",
      "Epoch 794/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12948.5088 - val_loss: 11891.5186\n",
      "Epoch 795/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13194.0078 - val_loss: 11937.9658\n",
      "Epoch 796/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13242.1738 - val_loss: 11960.5225\n",
      "Epoch 797/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13092.4131 - val_loss: 11988.9229\n",
      "Epoch 798/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13152.5996 - val_loss: 11919.3174\n",
      "Epoch 799/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12967.7422 - val_loss: 11685.3691\n",
      "Epoch 800/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13142.0205 - val_loss: 11860.5654\n",
      "Epoch 801/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13097.9805 - val_loss: 11810.3916\n",
      "Epoch 802/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13012.0391 - val_loss: 11849.4736\n",
      "Epoch 803/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13086.8125 - val_loss: 11958.7207\n",
      "Epoch 804/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13410.7783 - val_loss: 11785.2822\n",
      "Epoch 805/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13182.5293 - val_loss: 11765.6084\n",
      "Epoch 806/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12950.7334 - val_loss: 11889.1436\n",
      "Epoch 807/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13209.0039 - val_loss: 12043.7402\n",
      "Epoch 808/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13026.8857 - val_loss: 11820.2568\n",
      "Epoch 809/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13239.6279 - val_loss: 11733.6523\n",
      "Epoch 810/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13242.3984 - val_loss: 11831.8232\n",
      "Epoch 811/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13030.3818 - val_loss: 11956.0967\n",
      "Epoch 812/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12973.8447 - val_loss: 11815.0615\n",
      "Epoch 813/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12933.2646 - val_loss: 11809.1748\n",
      "Epoch 814/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13120.5850 - val_loss: 11879.2539\n",
      "Epoch 815/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13118.0459 - val_loss: 11707.6191\n",
      "Epoch 816/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12996.0684 - val_loss: 11780.2832\n",
      "Epoch 817/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13047.2744 - val_loss: 11889.7178\n",
      "Epoch 818/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13275.9229 - val_loss: 11878.9648\n",
      "Epoch 819/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13004.0469 - val_loss: 11812.5479\n",
      "Epoch 820/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13065.7236 - val_loss: 11918.0127\n",
      "Epoch 821/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13191.7256 - val_loss: 11893.4023\n",
      "Epoch 822/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13387.9453 - val_loss: 11838.0684\n",
      "Epoch 823/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13063.8115 - val_loss: 11831.6240\n",
      "Epoch 824/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13099.4600 - val_loss: 11825.1758\n",
      "Epoch 825/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13353.8252 - val_loss: 11898.9453\n",
      "Epoch 826/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12987.1621 - val_loss: 11999.7910\n",
      "Epoch 827/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13163.5557 - val_loss: 12060.3232\n",
      "Epoch 828/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13073.0459 - val_loss: 11896.6094\n",
      "Epoch 829/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13171.5801 - val_loss: 11816.8125\n",
      "Epoch 830/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13222.4707 - val_loss: 11820.5078\n",
      "Epoch 831/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12991.9531 - val_loss: 11840.2012\n",
      "Epoch 832/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13064.5488 - val_loss: 11801.3389\n",
      "Epoch 833/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13125.0605 - val_loss: 11870.5371\n",
      "Epoch 834/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12979.9492 - val_loss: 11867.8965\n",
      "Epoch 835/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12930.0479 - val_loss: 11816.7314\n",
      "Epoch 836/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12987.9805 - val_loss: 11723.1543\n",
      "Epoch 837/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13085.4922 - val_loss: 11821.8428\n",
      "Epoch 838/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12998.3506 - val_loss: 11717.7793\n",
      "Epoch 839/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13274.9424 - val_loss: 11846.7090\n",
      "Epoch 840/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13154.5117 - val_loss: 11852.6895\n",
      "Epoch 841/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13272.2217 - val_loss: 11922.4785\n",
      "Epoch 842/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13009.7246 - val_loss: 11762.1973\n",
      "Epoch 843/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13171.6025 - val_loss: 11853.6816\n",
      "Epoch 844/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13066.3486 - val_loss: 11876.5557\n",
      "Epoch 845/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13093.0625 - val_loss: 11746.2139\n",
      "Epoch 846/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13133.2275 - val_loss: 11985.4404\n",
      "Epoch 847/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12941.7637 - val_loss: 11739.6865\n",
      "Epoch 848/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12916.0127 - val_loss: 11902.0293\n",
      "Epoch 849/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13129.6357 - val_loss: 11918.5762\n",
      "Epoch 850/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13141.3379 - val_loss: 11943.5146\n",
      "Epoch 851/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12918.4023 - val_loss: 11829.4902\n",
      "Epoch 852/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13045.5596 - val_loss: 11936.8496\n",
      "Epoch 853/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13230.8730 - val_loss: 11792.8916\n",
      "Epoch 854/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12943.0166 - val_loss: 11806.8232\n",
      "Epoch 855/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13155.8867 - val_loss: 11688.2891\n",
      "Epoch 856/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13164.1455 - val_loss: 11922.1250\n",
      "Epoch 857/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13099.0156 - val_loss: 11846.9014\n",
      "Epoch 858/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13138.4111 - val_loss: 11744.9521\n",
      "Epoch 859/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13398.7744 - val_loss: 11845.9756\n",
      "Epoch 860/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13058.1729 - val_loss: 11910.7617\n",
      "Epoch 861/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12910.3975 - val_loss: 11667.8281\n",
      "Epoch 862/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13071.3740 - val_loss: 11926.1338\n",
      "Epoch 863/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13184.6797 - val_loss: 11726.8359\n",
      "Epoch 864/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13065.0322 - val_loss: 11971.8291\n",
      "Epoch 865/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13269.1436 - val_loss: 11876.2754\n",
      "Epoch 866/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12876.3457 - val_loss: 11750.3438\n",
      "Epoch 867/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13388.8486 - val_loss: 11972.4395\n",
      "Epoch 868/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13000.7471 - val_loss: 11979.1289\n",
      "Epoch 869/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12984.6699 - val_loss: 11809.8232\n",
      "Epoch 870/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13168.0723 - val_loss: 11823.4453\n",
      "Epoch 871/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13127.9365 - val_loss: 11844.3340\n",
      "Epoch 872/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12935.7031 - val_loss: 12035.3467\n",
      "Epoch 873/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12941.6572 - val_loss: 11865.5811\n",
      "Epoch 874/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13319.9355 - val_loss: 11919.7021\n",
      "Epoch 875/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13226.9521 - val_loss: 11800.8525\n",
      "Epoch 876/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12970.9414 - val_loss: 11832.8027\n",
      "Epoch 877/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13199.9326 - val_loss: 11910.7266\n",
      "Epoch 878/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13170.3330 - val_loss: 11873.8486\n",
      "Epoch 879/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13090.9297 - val_loss: 12067.2812\n",
      "Epoch 880/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13373.0713 - val_loss: 11797.0352\n",
      "Epoch 881/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12971.4707 - val_loss: 11931.9756\n",
      "Epoch 882/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13285.2139 - val_loss: 12074.5059\n",
      "Epoch 883/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13223.9980 - val_loss: 11883.1035\n",
      "Epoch 884/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13198.2988 - val_loss: 11774.2393\n",
      "Epoch 885/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13090.0225 - val_loss: 11708.0459\n",
      "Epoch 886/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13066.7949 - val_loss: 11940.2871\n",
      "Epoch 887/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13047.8750 - val_loss: 12035.6523\n",
      "Epoch 888/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12958.5576 - val_loss: 11857.8555\n",
      "Epoch 889/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13129.9434 - val_loss: 11888.6943\n",
      "Epoch 890/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13117.9043 - val_loss: 11864.5078\n",
      "Epoch 891/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13161.1836 - val_loss: 11990.5723\n",
      "Epoch 892/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13145.4053 - val_loss: 11846.1260\n",
      "Epoch 893/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13144.4941 - val_loss: 11977.2471\n",
      "Epoch 894/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13032.8691 - val_loss: 11866.2598\n",
      "Epoch 895/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13205.8379 - val_loss: 11836.2803\n",
      "Epoch 896/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13072.8896 - val_loss: 11719.7520\n",
      "Epoch 897/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13137.2744 - val_loss: 11874.6387\n",
      "Epoch 898/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13021.9111 - val_loss: 11871.0049\n",
      "Epoch 899/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13279.7666 - val_loss: 11958.5566\n",
      "Epoch 900/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12949.8652 - val_loss: 11723.4658\n",
      "Epoch 901/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12993.0352 - val_loss: 11984.9746\n",
      "Epoch 902/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12935.4170 - val_loss: 11873.6289\n",
      "Epoch 903/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12981.0156 - val_loss: 11993.3467\n",
      "Epoch 904/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12918.1826 - val_loss: 11847.8369\n",
      "Epoch 905/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12915.8770 - val_loss: 11734.3691\n",
      "Epoch 906/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12861.3691 - val_loss: 11704.6787\n",
      "Epoch 907/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13233.3320 - val_loss: 11972.2217\n",
      "Epoch 908/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13091.4219 - val_loss: 11747.0850\n",
      "Epoch 909/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13159.6562 - val_loss: 11779.7812\n",
      "Epoch 910/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12853.6270 - val_loss: 11769.9756\n",
      "Epoch 911/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13164.7539 - val_loss: 11689.9922\n",
      "Epoch 912/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12909.1064 - val_loss: 11763.1221\n",
      "Epoch 913/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13066.2412 - val_loss: 11769.6865\n",
      "Epoch 914/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13139.6572 - val_loss: 11828.4922\n",
      "Epoch 915/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13169.2705 - val_loss: 11685.9541\n",
      "Epoch 916/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13078.7695 - val_loss: 11769.8916\n",
      "Epoch 917/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13230.7217 - val_loss: 11779.6025\n",
      "Epoch 918/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13300.7197 - val_loss: 11821.4434\n",
      "Epoch 919/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13149.1318 - val_loss: 11823.4453\n",
      "Epoch 920/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13038.3125 - val_loss: 11817.1230\n",
      "Epoch 921/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12939.9619 - val_loss: 11844.1211\n",
      "Epoch 922/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13078.2285 - val_loss: 11719.9287\n",
      "Epoch 923/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13120.0518 - val_loss: 12103.4941\n",
      "Epoch 924/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13045.7402 - val_loss: 11825.7061\n",
      "Epoch 925/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13020.1455 - val_loss: 11951.1738\n",
      "Epoch 926/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13102.3740 - val_loss: 11891.9053\n",
      "Epoch 927/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13215.5059 - val_loss: 11965.1914\n",
      "Epoch 928/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13009.1904 - val_loss: 11777.3682\n",
      "Epoch 929/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13121.4697 - val_loss: 11833.7764\n",
      "Epoch 930/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12963.2256 - val_loss: 11681.8105\n",
      "Epoch 931/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12948.9717 - val_loss: 11879.9336\n",
      "Epoch 932/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13051.6602 - val_loss: 11824.7900\n",
      "Epoch 933/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13242.9639 - val_loss: 11837.4932\n",
      "Epoch 934/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13127.6650 - val_loss: 12056.9229\n",
      "Epoch 935/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13139.2998 - val_loss: 11703.0527\n",
      "Epoch 936/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13017.6934 - val_loss: 11842.4258\n",
      "Epoch 937/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13003.9590 - val_loss: 11836.7334\n",
      "Epoch 938/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13196.8770 - val_loss: 11790.5146\n",
      "Epoch 939/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12897.6201 - val_loss: 11907.5107\n",
      "Epoch 940/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13043.1982 - val_loss: 11969.6680\n",
      "Epoch 941/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13051.7568 - val_loss: 11792.3955\n",
      "Epoch 942/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13064.9443 - val_loss: 11799.9395\n",
      "Epoch 943/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12944.9229 - val_loss: 11904.9336\n",
      "Epoch 944/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12998.4570 - val_loss: 11836.4648\n",
      "Epoch 945/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12706.8594 - val_loss: 11844.7100\n",
      "Epoch 946/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13372.3057 - val_loss: 11800.2100\n",
      "Epoch 947/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13195.0820 - val_loss: 11881.1279\n",
      "Epoch 948/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12935.0166 - val_loss: 11880.6045\n",
      "Epoch 949/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12935.7930 - val_loss: 12011.2217\n",
      "Epoch 950/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13189.8965 - val_loss: 11880.9453\n",
      "Epoch 951/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13099.3564 - val_loss: 12250.6152\n",
      "Epoch 952/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12932.1992 - val_loss: 11829.3252\n",
      "Epoch 953/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13164.0879 - val_loss: 11873.6045\n",
      "Epoch 954/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13153.0898 - val_loss: 11773.4688\n",
      "Epoch 955/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13006.3750 - val_loss: 11796.8613\n",
      "Epoch 956/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13108.0996 - val_loss: 11758.8789\n",
      "Epoch 957/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13024.4229 - val_loss: 12007.8906\n",
      "Epoch 958/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12985.2383 - val_loss: 11936.0762\n",
      "Epoch 959/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13090.5557 - val_loss: 11947.1943\n",
      "Epoch 960/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13169.6650 - val_loss: 12080.8613\n",
      "Epoch 961/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13222.9941 - val_loss: 11899.7754\n",
      "Epoch 962/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12993.3330 - val_loss: 12034.8438\n",
      "Epoch 963/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13182.3574 - val_loss: 11799.7559\n",
      "Epoch 964/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13034.4336 - val_loss: 11793.7441\n",
      "Epoch 965/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13032.4346 - val_loss: 11832.6797\n",
      "Epoch 966/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12912.3340 - val_loss: 11874.5850\n",
      "Epoch 967/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12880.8096 - val_loss: 11739.0459\n",
      "Epoch 968/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13138.7588 - val_loss: 11973.8066\n",
      "Epoch 969/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13226.4512 - val_loss: 12032.4951\n",
      "Epoch 970/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13115.6416 - val_loss: 11936.3877\n",
      "Epoch 971/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13176.2646 - val_loss: 11866.8643\n",
      "Epoch 972/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13254.4307 - val_loss: 11967.9639\n",
      "Epoch 973/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13039.5195 - val_loss: 11763.3682\n",
      "Epoch 974/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13276.2324 - val_loss: 11798.5352\n",
      "Epoch 975/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13241.7275 - val_loss: 11997.7500\n",
      "Epoch 976/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13059.2891 - val_loss: 11857.5889\n",
      "Epoch 977/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13245.1953 - val_loss: 11949.2188\n",
      "Epoch 978/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12900.7939 - val_loss: 11735.7598\n",
      "Epoch 979/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13094.0400 - val_loss: 11749.5273\n",
      "Epoch 980/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13110.5107 - val_loss: 11804.8809\n",
      "Epoch 981/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13039.0850 - val_loss: 11949.8486\n",
      "Epoch 982/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13344.7852 - val_loss: 11975.3213\n",
      "Epoch 983/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13226.0537 - val_loss: 11786.9766\n",
      "Epoch 984/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13127.1670 - val_loss: 11854.3154\n",
      "Epoch 985/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12996.3604 - val_loss: 11915.3643\n",
      "Epoch 986/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12918.7832 - val_loss: 12018.4111\n",
      "Epoch 987/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13167.3887 - val_loss: 11863.4531\n",
      "Epoch 988/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12894.6084 - val_loss: 11953.3232\n",
      "Epoch 989/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13077.7168 - val_loss: 12095.0303\n",
      "Epoch 990/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13088.0078 - val_loss: 11793.4912\n",
      "Epoch 991/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13265.4785 - val_loss: 11932.3301\n",
      "Epoch 992/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13169.5488 - val_loss: 11879.6172\n",
      "Epoch 993/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13003.1426 - val_loss: 11954.5645\n",
      "Epoch 994/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13025.3623 - val_loss: 12007.4922\n",
      "Epoch 995/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13168.0352 - val_loss: 11901.5684\n",
      "Epoch 996/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13321.4492 - val_loss: 11773.5879\n",
      "Epoch 997/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13132.1670 - val_loss: 11790.0439\n",
      "Epoch 998/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13359.4004 - val_loss: 11816.8428\n",
      "Epoch 999/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13139.5801 - val_loss: 11886.2090\n",
      "Epoch 1000/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13103.0498 - val_loss: 12088.7617\n",
      "Epoch 1001/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13273.9072 - val_loss: 11937.2939\n",
      "Epoch 1002/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13086.7305 - val_loss: 11985.0498\n",
      "Epoch 1003/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13018.1777 - val_loss: 11860.7969\n",
      "Epoch 1004/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13102.9395 - val_loss: 11910.4355\n",
      "Epoch 1005/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13012.0459 - val_loss: 11799.9209\n",
      "Epoch 1006/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13242.5557 - val_loss: 11835.0176\n",
      "Epoch 1007/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13058.6055 - val_loss: 11754.5049\n",
      "Epoch 1008/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13125.3740 - val_loss: 11781.4062\n",
      "Epoch 1009/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13046.9199 - val_loss: 11904.1143\n",
      "Epoch 1010/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13151.8945 - val_loss: 11903.3154\n",
      "Epoch 1011/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13133.5645 - val_loss: 11760.3574\n",
      "Epoch 1012/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13008.9668 - val_loss: 11747.5859\n",
      "Epoch 1013/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12986.1992 - val_loss: 11733.9385\n",
      "Epoch 1014/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13305.1250 - val_loss: 11715.6250\n",
      "Epoch 1015/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12996.7734 - val_loss: 11914.5381\n",
      "Epoch 1016/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13041.7275 - val_loss: 11795.5967\n",
      "Epoch 1017/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12844.9600 - val_loss: 11786.1123\n",
      "Epoch 1018/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13169.5986 - val_loss: 12087.2656\n",
      "Epoch 1019/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12988.3428 - val_loss: 11631.4346\n",
      "Epoch 1020/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13253.1797 - val_loss: 11877.5293\n",
      "Epoch 1021/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13252.5547 - val_loss: 11852.0234\n",
      "Epoch 1022/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13158.7207 - val_loss: 11814.4102\n",
      "Epoch 1023/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13199.6348 - val_loss: 11844.6924\n",
      "Epoch 1024/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12827.8428 - val_loss: 11889.6162\n",
      "Epoch 1025/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13033.6631 - val_loss: 12008.1445\n",
      "Epoch 1026/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13097.3838 - val_loss: 11964.5596\n",
      "Epoch 1027/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13037.6055 - val_loss: 11937.7021\n",
      "Epoch 1028/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12892.9004 - val_loss: 11730.0088\n",
      "Epoch 1029/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13056.2373 - val_loss: 11828.0332\n",
      "Epoch 1030/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12997.4580 - val_loss: 12030.7930\n",
      "Epoch 1031/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13155.8291 - val_loss: 11943.7168\n",
      "Epoch 1032/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13238.6787 - val_loss: 12064.6113\n",
      "Epoch 1033/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13129.9023 - val_loss: 11875.7080\n",
      "Epoch 1034/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13230.9189 - val_loss: 11807.8662\n",
      "Epoch 1035/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13124.4854 - val_loss: 11979.1885\n",
      "Epoch 1036/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13083.8896 - val_loss: 11763.0918\n",
      "Epoch 1037/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12918.2959 - val_loss: 11820.1787\n",
      "Epoch 1038/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13051.6250 - val_loss: 11850.7812\n",
      "Epoch 1039/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13030.1074 - val_loss: 11875.9082\n",
      "Epoch 1040/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13132.7744 - val_loss: 11975.2354\n",
      "Epoch 1041/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12892.5371 - val_loss: 11870.5801\n",
      "Epoch 1042/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13134.0557 - val_loss: 11834.0938\n",
      "Epoch 1043/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13101.5801 - val_loss: 11735.0176\n",
      "Epoch 1044/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13023.9326 - val_loss: 11793.8096\n",
      "Epoch 1045/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13065.6143 - val_loss: 12033.5039\n",
      "Epoch 1046/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13005.0732 - val_loss: 11854.5273\n",
      "Epoch 1047/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12965.9746 - val_loss: 11889.7207\n",
      "Epoch 1048/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13109.3379 - val_loss: 11803.4990\n",
      "Epoch 1049/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13315.2393 - val_loss: 11891.2461\n",
      "Epoch 1050/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12845.0967 - val_loss: 11760.2969\n",
      "Epoch 1051/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12928.6494 - val_loss: 11758.7100\n",
      "Epoch 1052/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13064.7217 - val_loss: 11834.9678\n",
      "Epoch 1053/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13137.3760 - val_loss: 11962.6875\n",
      "Epoch 1054/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12910.3486 - val_loss: 11777.3945\n",
      "Epoch 1055/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12959.7373 - val_loss: 11870.4512\n",
      "Epoch 1056/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13145.7988 - val_loss: 11684.4072\n",
      "Epoch 1057/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13136.0703 - val_loss: 11729.1963\n",
      "Epoch 1058/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13263.8252 - val_loss: 11884.7061\n",
      "Epoch 1059/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13137.5117 - val_loss: 11891.7676\n",
      "Epoch 1060/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12910.9688 - val_loss: 11839.2607\n",
      "Epoch 1061/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12950.9170 - val_loss: 11977.4697\n",
      "Epoch 1062/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13114.2939 - val_loss: 11975.9648\n",
      "Epoch 1063/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13036.6123 - val_loss: 11772.9619\n",
      "Epoch 1064/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13048.0703 - val_loss: 11723.1035\n",
      "Epoch 1065/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13116.1582 - val_loss: 11852.2129\n",
      "Epoch 1066/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12989.1377 - val_loss: 11810.1768\n",
      "Epoch 1067/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13062.5869 - val_loss: 11806.0527\n",
      "Epoch 1068/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12911.3008 - val_loss: 11900.9385\n",
      "Epoch 1069/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13007.7314 - val_loss: 11914.5439\n",
      "Epoch 1070/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12952.5928 - val_loss: 11815.9717\n",
      "Epoch 1071/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13111.9102 - val_loss: 11910.9707\n",
      "Epoch 1072/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13045.1240 - val_loss: 11744.9746\n",
      "Epoch 1073/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13118.9082 - val_loss: 11884.2461\n",
      "Epoch 1074/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13178.2500 - val_loss: 11869.7197\n",
      "Epoch 1075/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12928.2031 - val_loss: 11722.3779\n",
      "Epoch 1076/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12950.0762 - val_loss: 11882.9404\n",
      "Epoch 1077/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13077.2588 - val_loss: 11880.5615\n",
      "Epoch 1078/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13149.7520 - val_loss: 11876.7744\n",
      "Epoch 1079/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13130.5137 - val_loss: 11880.0137\n",
      "Epoch 1080/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13272.4951 - val_loss: 11874.5840\n",
      "Epoch 1081/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13195.7021 - val_loss: 11824.7969\n",
      "Epoch 1082/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13269.3223 - val_loss: 11776.3047\n",
      "Epoch 1083/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13225.5840 - val_loss: 11782.4668\n",
      "Epoch 1084/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12948.9375 - val_loss: 11975.0684\n",
      "Epoch 1085/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13007.5176 - val_loss: 11865.7812\n",
      "Epoch 1086/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13240.9424 - val_loss: 11959.3711\n",
      "Epoch 1087/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12798.4502 - val_loss: 11758.4385\n",
      "Epoch 1088/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12939.5146 - val_loss: 11806.8691\n",
      "Epoch 1089/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13186.6162 - val_loss: 11915.0986\n",
      "Epoch 1090/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13043.7422 - val_loss: 11930.6436\n",
      "Epoch 1091/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13169.8809 - val_loss: 12066.1357\n",
      "Epoch 1092/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13053.5205 - val_loss: 11791.0977\n",
      "Epoch 1093/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12999.8340 - val_loss: 11728.7744\n",
      "Epoch 1094/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13021.3203 - val_loss: 12031.7969\n",
      "Epoch 1095/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13114.6201 - val_loss: 11909.3564\n",
      "Epoch 1096/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13118.8848 - val_loss: 11941.8994\n",
      "Epoch 1097/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12998.1455 - val_loss: 11891.4473\n",
      "Epoch 1098/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13004.7725 - val_loss: 11809.2803\n",
      "Epoch 1099/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12924.3125 - val_loss: 11716.3457\n",
      "Epoch 1100/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13025.6172 - val_loss: 11809.4619\n",
      "Epoch 1101/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12920.0332 - val_loss: 11799.0059\n",
      "Epoch 1102/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12957.9238 - val_loss: 11949.5898\n",
      "Epoch 1103/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13136.2725 - val_loss: 11760.5381\n",
      "Epoch 1104/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12962.7412 - val_loss: 12067.9258\n",
      "Epoch 1105/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12990.4209 - val_loss: 11757.2529\n",
      "Epoch 1106/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13134.6582 - val_loss: 11756.6377\n",
      "Epoch 1107/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12832.4531 - val_loss: 11792.1846\n",
      "Epoch 1108/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12973.7100 - val_loss: 11854.3135\n",
      "Epoch 1109/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13079.5537 - val_loss: 11947.4775\n",
      "Epoch 1110/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13088.6797 - val_loss: 11882.9854\n",
      "Epoch 1111/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12946.9844 - val_loss: 11731.3730\n",
      "Epoch 1112/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13213.2021 - val_loss: 11818.4697\n",
      "Epoch 1113/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13121.5859 - val_loss: 11711.8203\n",
      "Epoch 1114/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13412.3535 - val_loss: 12002.2422\n",
      "Epoch 1115/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12950.1670 - val_loss: 11831.1758\n",
      "Epoch 1116/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12906.8857 - val_loss: 12062.5264\n",
      "Epoch 1117/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13036.3311 - val_loss: 12120.4268\n",
      "Epoch 1118/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13159.2129 - val_loss: 11709.7793\n",
      "Epoch 1119/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13105.8086 - val_loss: 11854.2461\n",
      "Epoch 1120/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12866.6504 - val_loss: 12004.4365\n",
      "Epoch 1121/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13041.3965 - val_loss: 11807.0400\n",
      "Epoch 1122/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12948.4795 - val_loss: 11820.9922\n",
      "Epoch 1123/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12961.6748 - val_loss: 11953.8203\n",
      "Epoch 1124/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12997.2949 - val_loss: 11936.0791\n",
      "Epoch 1125/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12899.0273 - val_loss: 11836.5293\n",
      "Epoch 1126/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13196.8633 - val_loss: 11819.3291\n",
      "Epoch 1127/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13058.4521 - val_loss: 11832.5566\n",
      "Epoch 1128/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13117.7793 - val_loss: 11819.4668\n",
      "Epoch 1129/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12952.7715 - val_loss: 12077.3096\n",
      "Epoch 1130/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13024.1299 - val_loss: 11827.4277\n",
      "Epoch 1131/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13176.2217 - val_loss: 11965.8193\n",
      "Epoch 1132/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13140.1621 - val_loss: 11892.8037\n",
      "Epoch 1133/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12962.9512 - val_loss: 11837.5898\n",
      "Epoch 1134/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13096.1641 - val_loss: 11896.5166\n",
      "Epoch 1135/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13077.4424 - val_loss: 11907.1494\n",
      "Epoch 1136/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13221.3740 - val_loss: 11993.6660\n",
      "Epoch 1137/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13067.2686 - val_loss: 11890.5830\n",
      "Epoch 1138/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13292.1641 - val_loss: 11907.4580\n",
      "Epoch 1139/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13094.8125 - val_loss: 11979.0605\n",
      "Epoch 1140/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12868.4141 - val_loss: 11784.2617\n",
      "Epoch 1141/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13014.3037 - val_loss: 11906.5986\n",
      "Epoch 1142/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12977.5830 - val_loss: 11940.1250\n",
      "Epoch 1143/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12888.7051 - val_loss: 11853.6396\n",
      "Epoch 1144/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13025.2646 - val_loss: 11699.1895\n",
      "Epoch 1145/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13204.0127 - val_loss: 11843.5439\n",
      "Epoch 1146/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13182.0635 - val_loss: 11865.5234\n",
      "Epoch 1147/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13205.6660 - val_loss: 11903.4824\n",
      "Epoch 1148/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13229.2148 - val_loss: 12175.7988\n",
      "Epoch 1149/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12888.4424 - val_loss: 11890.2803\n",
      "Epoch 1150/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13194.8789 - val_loss: 11719.0762\n",
      "Epoch 1151/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13048.8633 - val_loss: 11720.0859\n",
      "Epoch 1152/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13201.1064 - val_loss: 11732.5312\n",
      "Epoch 1153/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13088.8018 - val_loss: 11814.9170\n",
      "Epoch 1154/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13066.0254 - val_loss: 11676.7178\n",
      "Epoch 1155/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13000.8682 - val_loss: 11723.7432\n",
      "Epoch 1156/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12830.0527 - val_loss: 11950.2988\n",
      "Epoch 1157/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12871.3945 - val_loss: 11788.7236\n",
      "Epoch 1158/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12976.1641 - val_loss: 11741.9395\n",
      "Epoch 1159/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12936.2871 - val_loss: 12002.8320\n",
      "Epoch 1160/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13062.4268 - val_loss: 11790.5156\n",
      "Epoch 1161/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13024.9385 - val_loss: 11912.4189\n",
      "Epoch 1162/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12978.4014 - val_loss: 11953.8574\n",
      "Epoch 1163/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13085.9688 - val_loss: 11892.2070\n",
      "Epoch 1164/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13107.0430 - val_loss: 11747.8965\n",
      "Epoch 1165/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13100.8545 - val_loss: 11901.7451\n",
      "Epoch 1166/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13011.1152 - val_loss: 11921.3359\n",
      "Epoch 1167/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13128.7910 - val_loss: 11834.2139\n",
      "Epoch 1168/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12928.6943 - val_loss: 12087.2539\n",
      "Epoch 1169/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12926.5391 - val_loss: 11815.1709\n",
      "Epoch 1170/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12999.1826 - val_loss: 12080.3418\n",
      "Epoch 1171/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13139.7979 - val_loss: 11928.0430\n",
      "Epoch 1172/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13038.2793 - val_loss: 11875.3320\n",
      "Epoch 1173/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12986.5195 - val_loss: 11949.7881\n",
      "Epoch 1174/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13100.8398 - val_loss: 11782.5977\n",
      "Epoch 1175/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12741.1748 - val_loss: 11947.0674\n",
      "Epoch 1176/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13086.0576 - val_loss: 12133.2744\n",
      "Epoch 1177/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13167.3877 - val_loss: 11922.3486\n",
      "Epoch 1178/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13159.8379 - val_loss: 11817.6572\n",
      "Epoch 1179/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13003.5957 - val_loss: 11767.1074\n",
      "Epoch 1180/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13258.2451 - val_loss: 12014.3848\n",
      "Epoch 1181/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12725.6895 - val_loss: 11695.5830\n",
      "Epoch 1182/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12877.0430 - val_loss: 11767.1865\n",
      "Epoch 1183/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13012.6865 - val_loss: 11905.7773\n",
      "Epoch 1184/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13088.8984 - val_loss: 11796.2822\n",
      "Epoch 1185/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13053.1885 - val_loss: 11824.6719\n",
      "Epoch 1186/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12988.1807 - val_loss: 11950.5312\n",
      "Epoch 1187/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13043.5771 - val_loss: 11827.9619\n",
      "Epoch 1188/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12898.3838 - val_loss: 11857.2109\n",
      "Epoch 1189/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13169.1494 - val_loss: 11830.6953\n",
      "Epoch 1190/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12940.9668 - val_loss: 11904.5830\n",
      "Epoch 1191/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12982.4170 - val_loss: 11939.4102\n",
      "Epoch 1192/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 13297.4580 - val_loss: 11750.0049\n",
      "Epoch 1193/1200\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 12983.9854 - val_loss: 11859.2178\n",
      "Epoch 1194/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13093.6016 - val_loss: 11849.2881\n",
      "Epoch 1195/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12926.3770 - val_loss: 11920.1309\n",
      "Epoch 1196/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13132.8818 - val_loss: 11889.0957\n",
      "Epoch 1197/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13059.2334 - val_loss: 11884.1572\n",
      "Epoch 1198/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13108.1895 - val_loss: 11938.2832\n",
      "Epoch 1199/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 13070.3467 - val_loss: 12126.5908\n",
      "Epoch 1200/1200\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 12949.1377 - val_loss: 11899.5098\n",
      "INFO:tensorflow:Assets written to: c:\\programowanie\\ml_streamlit\\models\\bmw3\\assets\n",
      "Epoch 1/1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\proso\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\data_adapter.py:1699: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 1s 5ms/step - loss: 46850.2617 - val_loss: 48050.8516\n",
      "Epoch 2/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 46695.9609 - val_loss: 47599.0703\n",
      "Epoch 3/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 45335.9180 - val_loss: 44846.4023\n",
      "Epoch 4/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 40629.7852 - val_loss: 37960.6680\n",
      "Epoch 5/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 31492.6152 - val_loss: 25588.7969\n",
      "Epoch 6/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 19148.0957 - val_loss: 13276.0117\n",
      "Epoch 7/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 13189.9307 - val_loss: 11339.9639\n",
      "Epoch 8/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 12211.1250 - val_loss: 10811.0879\n",
      "Epoch 9/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 11559.4893 - val_loss: 10482.8252\n",
      "Epoch 10/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 11581.9277 - val_loss: 10279.8418\n",
      "Epoch 11/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 11364.7490 - val_loss: 10145.5312\n",
      "Epoch 12/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 11171.9414 - val_loss: 10065.1270\n",
      "Epoch 13/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 11079.5566 - val_loss: 10003.6533\n",
      "Epoch 14/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10973.7363 - val_loss: 9940.0723\n",
      "Epoch 15/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10964.1406 - val_loss: 9930.0254\n",
      "Epoch 16/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10962.7148 - val_loss: 9869.1074\n",
      "Epoch 17/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 11009.0762 - val_loss: 9850.3877\n",
      "Epoch 18/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10914.9893 - val_loss: 9872.9717\n",
      "Epoch 19/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10961.5166 - val_loss: 9860.5469\n",
      "Epoch 20/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10765.0293 - val_loss: 9777.2510\n",
      "Epoch 21/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10878.8848 - val_loss: 9811.6328\n",
      "Epoch 22/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10814.0869 - val_loss: 9745.2041\n",
      "Epoch 23/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 10676.0449 - val_loss: 9822.6182\n",
      "Epoch 24/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10838.8213 - val_loss: 9703.4775\n",
      "Epoch 25/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10670.8672 - val_loss: 9686.4463\n",
      "Epoch 26/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10803.8018 - val_loss: 9663.7021\n",
      "Epoch 27/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10749.4346 - val_loss: 9758.6758\n",
      "Epoch 28/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10741.5234 - val_loss: 9687.7246\n",
      "Epoch 29/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10641.7100 - val_loss: 9675.0029\n",
      "Epoch 30/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10591.4414 - val_loss: 9602.5420\n",
      "Epoch 31/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10653.3809 - val_loss: 9615.4043\n",
      "Epoch 32/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10661.8799 - val_loss: 9543.6504\n",
      "Epoch 33/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10630.2129 - val_loss: 9600.9033\n",
      "Epoch 34/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10507.0898 - val_loss: 9545.8506\n",
      "Epoch 35/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10549.0791 - val_loss: 9592.9648\n",
      "Epoch 36/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10621.4658 - val_loss: 9557.1572\n",
      "Epoch 37/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10549.0127 - val_loss: 9448.6973\n",
      "Epoch 38/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10387.6816 - val_loss: 9434.9873\n",
      "Epoch 39/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10432.4443 - val_loss: 9530.3057\n",
      "Epoch 40/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10540.1797 - val_loss: 9448.9912\n",
      "Epoch 41/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10460.0850 - val_loss: 9388.2949\n",
      "Epoch 42/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10418.9023 - val_loss: 9347.8779\n",
      "Epoch 43/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10306.8809 - val_loss: 9396.3281\n",
      "Epoch 44/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10444.9131 - val_loss: 9318.9990\n",
      "Epoch 45/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10240.0127 - val_loss: 9345.9727\n",
      "Epoch 46/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10358.0645 - val_loss: 9294.3945\n",
      "Epoch 47/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10372.1309 - val_loss: 9291.1650\n",
      "Epoch 48/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10268.0283 - val_loss: 9293.6094\n",
      "Epoch 49/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10266.9736 - val_loss: 9283.3809\n",
      "Epoch 50/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10272.7900 - val_loss: 9312.3516\n",
      "Epoch 51/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10340.1973 - val_loss: 9224.1797\n",
      "Epoch 52/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10323.8926 - val_loss: 9230.8320\n",
      "Epoch 53/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10306.5508 - val_loss: 9199.4951\n",
      "Epoch 54/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10146.0791 - val_loss: 9246.1426\n",
      "Epoch 55/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10264.5674 - val_loss: 9195.1777\n",
      "Epoch 56/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10112.5049 - val_loss: 9162.4756\n",
      "Epoch 57/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10159.4121 - val_loss: 9156.6436\n",
      "Epoch 58/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10240.3291 - val_loss: 9125.5547\n",
      "Epoch 59/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 10198.9229 - val_loss: 9121.4736\n",
      "Epoch 60/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10146.6201 - val_loss: 9084.5410\n",
      "Epoch 61/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10318.6592 - val_loss: 9122.7998\n",
      "Epoch 62/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10101.7988 - val_loss: 9068.8730\n",
      "Epoch 63/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10105.3652 - val_loss: 9090.2500\n",
      "Epoch 64/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10077.4229 - val_loss: 9056.6289\n",
      "Epoch 65/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10112.2754 - val_loss: 9044.1816\n",
      "Epoch 66/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10079.7090 - val_loss: 9036.4912\n",
      "Epoch 67/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10132.3350 - val_loss: 9020.8066\n",
      "Epoch 68/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 10078.6367 - val_loss: 9010.0703\n",
      "Epoch 69/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10089.4482 - val_loss: 9025.2822\n",
      "Epoch 70/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10125.7480 - val_loss: 9037.1094\n",
      "Epoch 71/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10018.1768 - val_loss: 9076.5303\n",
      "Epoch 72/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10041.3320 - val_loss: 8990.7275\n",
      "Epoch 73/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9996.7686 - val_loss: 8967.8447\n",
      "Epoch 74/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9961.9277 - val_loss: 8945.7998\n",
      "Epoch 75/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9962.2900 - val_loss: 8979.3594\n",
      "Epoch 76/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9943.0371 - val_loss: 8969.0654\n",
      "Epoch 77/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9971.5518 - val_loss: 8950.4277\n",
      "Epoch 78/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10090.7969 - val_loss: 8965.4727\n",
      "Epoch 79/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10036.5703 - val_loss: 8934.8525\n",
      "Epoch 80/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10038.1963 - val_loss: 8925.2197\n",
      "Epoch 81/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9817.6396 - val_loss: 8909.5225\n",
      "Epoch 82/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10005.7988 - val_loss: 8930.9482\n",
      "Epoch 83/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9937.5732 - val_loss: 8882.9600\n",
      "Epoch 84/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9802.3320 - val_loss: 8865.6035\n",
      "Epoch 85/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9955.8555 - val_loss: 8876.2910\n",
      "Epoch 86/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9851.8350 - val_loss: 8878.0518\n",
      "Epoch 87/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9985.8408 - val_loss: 8891.6973\n",
      "Epoch 88/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9926.4072 - val_loss: 8895.0439\n",
      "Epoch 89/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9993.5361 - val_loss: 8824.1572\n",
      "Epoch 90/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10008.4072 - val_loss: 8815.6660\n",
      "Epoch 91/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9871.4697 - val_loss: 8828.0869\n",
      "Epoch 92/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9973.5850 - val_loss: 8819.2500\n",
      "Epoch 93/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9851.6846 - val_loss: 8819.4375\n",
      "Epoch 94/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9939.5361 - val_loss: 8804.6348\n",
      "Epoch 95/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10008.7266 - val_loss: 8798.5684\n",
      "Epoch 96/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9883.0986 - val_loss: 8801.2197\n",
      "Epoch 97/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9867.0186 - val_loss: 8769.2129\n",
      "Epoch 98/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9853.9219 - val_loss: 8767.4785\n",
      "Epoch 99/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9856.2832 - val_loss: 8798.2900\n",
      "Epoch 100/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9876.5049 - val_loss: 8791.3174\n",
      "Epoch 101/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9809.1973 - val_loss: 8802.9873\n",
      "Epoch 102/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9819.5654 - val_loss: 8831.2129\n",
      "Epoch 103/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9830.7334 - val_loss: 8785.1348\n",
      "Epoch 104/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9847.6309 - val_loss: 8771.7148\n",
      "Epoch 105/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9890.4795 - val_loss: 8733.7148\n",
      "Epoch 106/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9844.2793 - val_loss: 8740.9912\n",
      "Epoch 107/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9779.4844 - val_loss: 8716.0664\n",
      "Epoch 108/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9828.9395 - val_loss: 8711.4932\n",
      "Epoch 109/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9622.2012 - val_loss: 8740.7432\n",
      "Epoch 110/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9736.2041 - val_loss: 8694.9170\n",
      "Epoch 111/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9796.1719 - val_loss: 8689.2783\n",
      "Epoch 112/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9713.0801 - val_loss: 8729.4404\n",
      "Epoch 113/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9792.1084 - val_loss: 8695.5957\n",
      "Epoch 114/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9748.4883 - val_loss: 8664.9727\n",
      "Epoch 115/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9660.0908 - val_loss: 8716.8623\n",
      "Epoch 116/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9819.3086 - val_loss: 8656.9121\n",
      "Epoch 117/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9737.0781 - val_loss: 8681.5176\n",
      "Epoch 118/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9783.1943 - val_loss: 8662.3076\n",
      "Epoch 119/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9731.2031 - val_loss: 8660.8721\n",
      "Epoch 120/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9614.2891 - val_loss: 8627.1895\n",
      "Epoch 121/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9878.2588 - val_loss: 8670.6582\n",
      "Epoch 122/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9624.9326 - val_loss: 8612.9961\n",
      "Epoch 123/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9762.2305 - val_loss: 8622.5771\n",
      "Epoch 124/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9607.7861 - val_loss: 8632.5059\n",
      "Epoch 125/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9692.1729 - val_loss: 8592.0547\n",
      "Epoch 126/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9649.3389 - val_loss: 8598.8125\n",
      "Epoch 127/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9666.8926 - val_loss: 8593.2764\n",
      "Epoch 128/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9601.8730 - val_loss: 8655.2793\n",
      "Epoch 129/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9675.5781 - val_loss: 8609.2510\n",
      "Epoch 130/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9712.0166 - val_loss: 8614.8740\n",
      "Epoch 131/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9497.9307 - val_loss: 8595.6406\n",
      "Epoch 132/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9784.1973 - val_loss: 8628.7998\n",
      "Epoch 133/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9574.1465 - val_loss: 8595.9453\n",
      "Epoch 134/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9653.4150 - val_loss: 8556.3379\n",
      "Epoch 135/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9713.9795 - val_loss: 8547.6025\n",
      "Epoch 136/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9618.0771 - val_loss: 8553.7559\n",
      "Epoch 137/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9712.1387 - val_loss: 8534.0557\n",
      "Epoch 138/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9665.2139 - val_loss: 8528.7412\n",
      "Epoch 139/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9690.5537 - val_loss: 8537.3242\n",
      "Epoch 140/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9507.3037 - val_loss: 8539.4697\n",
      "Epoch 141/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9599.3408 - val_loss: 8513.5674\n",
      "Epoch 142/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9561.8574 - val_loss: 8590.5615\n",
      "Epoch 143/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9610.3691 - val_loss: 8510.0713\n",
      "Epoch 144/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9575.9453 - val_loss: 8501.9004\n",
      "Epoch 145/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9588.9512 - val_loss: 8514.4639\n",
      "Epoch 146/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9453.3711 - val_loss: 8535.5518\n",
      "Epoch 147/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9489.8232 - val_loss: 8525.7129\n",
      "Epoch 148/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9510.4971 - val_loss: 8480.2314\n",
      "Epoch 149/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9700.3350 - val_loss: 8487.3438\n",
      "Epoch 150/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9522.2520 - val_loss: 8572.1885\n",
      "Epoch 151/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9637.4355 - val_loss: 8492.4678\n",
      "Epoch 152/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9502.4609 - val_loss: 8473.9600\n",
      "Epoch 153/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9632.3926 - val_loss: 8468.3857\n",
      "Epoch 154/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9384.0996 - val_loss: 8498.7012\n",
      "Epoch 155/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9568.5586 - val_loss: 8483.6396\n",
      "Epoch 156/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9493.0186 - val_loss: 8467.7422\n",
      "Epoch 157/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9598.2324 - val_loss: 8462.1621\n",
      "Epoch 158/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9569.9062 - val_loss: 8440.9766\n",
      "Epoch 159/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9504.7148 - val_loss: 8445.8408\n",
      "Epoch 160/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9590.7256 - val_loss: 8517.4551\n",
      "Epoch 161/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9579.1514 - val_loss: 8472.7871\n",
      "Epoch 162/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9544.7422 - val_loss: 8438.6934\n",
      "Epoch 163/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9413.6152 - val_loss: 8450.3701\n",
      "Epoch 164/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9613.2334 - val_loss: 8435.1934\n",
      "Epoch 165/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9416.0469 - val_loss: 8424.1523\n",
      "Epoch 166/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9435.0400 - val_loss: 8440.0156\n",
      "Epoch 167/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9392.3691 - val_loss: 8443.4727\n",
      "Epoch 168/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9510.8418 - val_loss: 8467.6719\n",
      "Epoch 169/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9436.1270 - val_loss: 8452.0273\n",
      "Epoch 170/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9400.2002 - val_loss: 8453.1836\n",
      "Epoch 171/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9493.0664 - val_loss: 8430.2314\n",
      "Epoch 172/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9432.3662 - val_loss: 8487.5322\n",
      "Epoch 173/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9460.5869 - val_loss: 8488.5684\n",
      "Epoch 174/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9416.0332 - val_loss: 8447.5557\n",
      "Epoch 175/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9358.1074 - val_loss: 8404.0293\n",
      "Epoch 176/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9434.5840 - val_loss: 8420.2861\n",
      "Epoch 177/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9370.9336 - val_loss: 8402.5811\n",
      "Epoch 178/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9510.0283 - val_loss: 8404.3721\n",
      "Epoch 179/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9470.8506 - val_loss: 8400.6953\n",
      "Epoch 180/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9398.9131 - val_loss: 8397.1992\n",
      "Epoch 181/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9468.6787 - val_loss: 8387.8145\n",
      "Epoch 182/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9370.0078 - val_loss: 8389.3281\n",
      "Epoch 183/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9328.3848 - val_loss: 8403.3447\n",
      "Epoch 184/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9502.7939 - val_loss: 8420.5029\n",
      "Epoch 185/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9405.9375 - val_loss: 8382.7920\n",
      "Epoch 186/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9473.1680 - val_loss: 8395.1582\n",
      "Epoch 187/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9218.2715 - val_loss: 8393.1680\n",
      "Epoch 188/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9590.0342 - val_loss: 8394.2686\n",
      "Epoch 189/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9372.8633 - val_loss: 8387.1113\n",
      "Epoch 190/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9545.0264 - val_loss: 8388.4053\n",
      "Epoch 191/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9428.0771 - val_loss: 8366.3428\n",
      "Epoch 192/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9368.9424 - val_loss: 8381.3428\n",
      "Epoch 193/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9333.5762 - val_loss: 8371.8369\n",
      "Epoch 194/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9371.5029 - val_loss: 8370.5801\n",
      "Epoch 195/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9388.8691 - val_loss: 8361.7598\n",
      "Epoch 196/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9390.2080 - val_loss: 8377.2227\n",
      "Epoch 197/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9293.6260 - val_loss: 8391.4775\n",
      "Epoch 198/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9274.9219 - val_loss: 8370.5811\n",
      "Epoch 199/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9206.4277 - val_loss: 8350.8203\n",
      "Epoch 200/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9505.9590 - val_loss: 8360.2480\n",
      "Epoch 201/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9450.0518 - val_loss: 8351.7646\n",
      "Epoch 202/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9314.8848 - val_loss: 8377.5850\n",
      "Epoch 203/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9297.4863 - val_loss: 8351.9180\n",
      "Epoch 204/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9325.9736 - val_loss: 8343.5205\n",
      "Epoch 205/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9201.5898 - val_loss: 8367.4658\n",
      "Epoch 206/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9188.8389 - val_loss: 8333.2568\n",
      "Epoch 207/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9477.1973 - val_loss: 8404.9258\n",
      "Epoch 208/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9394.1748 - val_loss: 8377.4453\n",
      "Epoch 209/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9279.7783 - val_loss: 8336.2305\n",
      "Epoch 210/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9493.2373 - val_loss: 8341.5723\n",
      "Epoch 211/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9464.3955 - val_loss: 8325.2734\n",
      "Epoch 212/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9269.9932 - val_loss: 8354.2041\n",
      "Epoch 213/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9414.7295 - val_loss: 8335.2324\n",
      "Epoch 214/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9406.0830 - val_loss: 8345.6875\n",
      "Epoch 215/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9426.3008 - val_loss: 8348.8418\n",
      "Epoch 216/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9451.6025 - val_loss: 8361.2178\n",
      "Epoch 217/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9432.4863 - val_loss: 8336.8936\n",
      "Epoch 218/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9158.7529 - val_loss: 8337.6738\n",
      "Epoch 219/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9281.5576 - val_loss: 8347.4160\n",
      "Epoch 220/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9252.6504 - val_loss: 8355.0059\n",
      "Epoch 221/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9268.2422 - val_loss: 8333.0791\n",
      "Epoch 222/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9277.1641 - val_loss: 8325.3896\n",
      "Epoch 223/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9229.5830 - val_loss: 8305.1055\n",
      "Epoch 224/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9199.2939 - val_loss: 8318.5723\n",
      "Epoch 225/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9459.6016 - val_loss: 8310.5693\n",
      "Epoch 226/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9186.4346 - val_loss: 8325.8730\n",
      "Epoch 227/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9272.8154 - val_loss: 8318.8711\n",
      "Epoch 228/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9343.6270 - val_loss: 8312.6738\n",
      "Epoch 229/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9313.4297 - val_loss: 8308.0088\n",
      "Epoch 230/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9285.5830 - val_loss: 8330.5273\n",
      "Epoch 231/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9369.3740 - val_loss: 8303.4131\n",
      "Epoch 232/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9286.6689 - val_loss: 8336.5635\n",
      "Epoch 233/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9382.8506 - val_loss: 8292.5781\n",
      "Epoch 234/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9120.5635 - val_loss: 8341.2539\n",
      "Epoch 235/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9307.1406 - val_loss: 8320.6221\n",
      "Epoch 236/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9247.8496 - val_loss: 8297.7627\n",
      "Epoch 237/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9427.3047 - val_loss: 8286.9111\n",
      "Epoch 238/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 9226.9883 - val_loss: 8275.9883\n",
      "Epoch 239/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9191.9131 - val_loss: 8272.2871\n",
      "Epoch 240/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9200.6699 - val_loss: 8290.8408\n",
      "Epoch 241/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9077.6172 - val_loss: 8276.5498\n",
      "Epoch 242/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9062.5693 - val_loss: 8262.3291\n",
      "Epoch 243/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9276.5742 - val_loss: 8285.3750\n",
      "Epoch 244/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9172.9746 - val_loss: 8296.6816\n",
      "Epoch 245/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9069.2432 - val_loss: 8279.1113\n",
      "Epoch 246/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9121.4863 - val_loss: 8278.0615\n",
      "Epoch 247/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9028.0391 - val_loss: 8309.9639\n",
      "Epoch 248/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9246.8516 - val_loss: 8285.6475\n",
      "Epoch 249/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9283.3096 - val_loss: 8265.6182\n",
      "Epoch 250/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9245.1855 - val_loss: 8249.3125\n",
      "Epoch 251/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9166.7002 - val_loss: 8240.6738\n",
      "Epoch 252/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9218.4795 - val_loss: 8259.3047\n",
      "Epoch 253/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9227.2402 - val_loss: 8271.9170\n",
      "Epoch 254/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9294.0820 - val_loss: 8259.2725\n",
      "Epoch 255/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9179.5713 - val_loss: 8261.1377\n",
      "Epoch 256/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9133.2998 - val_loss: 8245.2129\n",
      "Epoch 257/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9296.8086 - val_loss: 8236.8848\n",
      "Epoch 258/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9177.3916 - val_loss: 8257.3115\n",
      "Epoch 259/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9240.8486 - val_loss: 8255.6533\n",
      "Epoch 260/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 9276.7520 - val_loss: 8233.6016\n",
      "Epoch 261/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9169.1582 - val_loss: 8234.7207\n",
      "Epoch 262/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9098.0166 - val_loss: 8226.3115\n",
      "Epoch 263/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9051.0371 - val_loss: 8218.0127\n",
      "Epoch 264/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9157.4922 - val_loss: 8213.5752\n",
      "Epoch 265/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 9129.6816 - val_loss: 8243.7822\n",
      "Epoch 266/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9218.9189 - val_loss: 8223.5576\n",
      "Epoch 267/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9134.7588 - val_loss: 8239.6807\n",
      "Epoch 268/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9216.1611 - val_loss: 8223.4336\n",
      "Epoch 269/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9213.3057 - val_loss: 8225.0547\n",
      "Epoch 270/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9111.1416 - val_loss: 8206.4453\n",
      "Epoch 271/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9197.4355 - val_loss: 8200.0332\n",
      "Epoch 272/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 9223.1992 - val_loss: 8203.6240\n",
      "Epoch 273/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8966.8213 - val_loss: 8228.1650\n",
      "Epoch 274/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9125.9824 - val_loss: 8200.6172\n",
      "Epoch 275/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9097.7930 - val_loss: 8214.9424\n",
      "Epoch 276/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9154.3359 - val_loss: 8248.9795\n",
      "Epoch 277/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9161.4590 - val_loss: 8195.0527\n",
      "Epoch 278/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9241.5635 - val_loss: 8197.7686\n",
      "Epoch 279/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9228.2197 - val_loss: 8182.6133\n",
      "Epoch 280/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9207.0645 - val_loss: 8223.7617\n",
      "Epoch 281/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9065.4609 - val_loss: 8219.4707\n",
      "Epoch 282/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9072.2002 - val_loss: 8170.2256\n",
      "Epoch 283/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9115.7158 - val_loss: 8200.2861\n",
      "Epoch 284/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9029.4697 - val_loss: 8210.5293\n",
      "Epoch 285/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9206.2354 - val_loss: 8192.2988\n",
      "Epoch 286/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9236.6836 - val_loss: 8168.8750\n",
      "Epoch 287/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9193.4043 - val_loss: 8191.5410\n",
      "Epoch 288/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9028.5977 - val_loss: 8168.1235\n",
      "Epoch 289/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9079.3555 - val_loss: 8176.4741\n",
      "Epoch 290/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9099.9873 - val_loss: 8172.6206\n",
      "Epoch 291/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9024.8691 - val_loss: 8194.4639\n",
      "Epoch 292/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9208.8174 - val_loss: 8259.7598\n",
      "Epoch 293/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9058.4785 - val_loss: 8193.1084\n",
      "Epoch 294/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9144.4688 - val_loss: 8189.3228\n",
      "Epoch 295/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9022.0527 - val_loss: 8147.6123\n",
      "Epoch 296/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9089.8633 - val_loss: 8170.1050\n",
      "Epoch 297/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9253.1328 - val_loss: 8244.6250\n",
      "Epoch 298/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9031.1963 - val_loss: 8159.4473\n",
      "Epoch 299/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9131.6904 - val_loss: 8173.1060\n",
      "Epoch 300/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9026.2148 - val_loss: 8164.2534\n",
      "Epoch 301/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9069.3330 - val_loss: 8163.1919\n",
      "Epoch 302/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9091.9512 - val_loss: 8147.8608\n",
      "Epoch 303/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9164.7256 - val_loss: 8148.9165\n",
      "Epoch 304/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9065.2598 - val_loss: 8188.3804\n",
      "Epoch 305/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 9199.2207 - val_loss: 8177.3091\n",
      "Epoch 306/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8878.7012 - val_loss: 8177.1084\n",
      "Epoch 307/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9177.8057 - val_loss: 8144.9619\n",
      "Epoch 308/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9147.6660 - val_loss: 8162.5146\n",
      "Epoch 309/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9128.2344 - val_loss: 8167.7588\n",
      "Epoch 310/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9172.3818 - val_loss: 8164.2246\n",
      "Epoch 311/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9078.9883 - val_loss: 8149.5444\n",
      "Epoch 312/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 9078.0000 - val_loss: 8141.1772\n",
      "Epoch 313/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9072.1211 - val_loss: 8150.9062\n",
      "Epoch 314/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9048.0586 - val_loss: 8134.7544\n",
      "Epoch 315/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9186.6309 - val_loss: 8137.1743\n",
      "Epoch 316/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9089.2432 - val_loss: 8144.0601\n",
      "Epoch 317/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9131.8994 - val_loss: 8116.1084\n",
      "Epoch 318/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8973.1455 - val_loss: 8128.4229\n",
      "Epoch 319/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9078.8193 - val_loss: 8119.1641\n",
      "Epoch 320/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8961.3174 - val_loss: 8093.8701\n",
      "Epoch 321/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8963.9795 - val_loss: 8117.2607\n",
      "Epoch 322/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8973.4834 - val_loss: 8148.5806\n",
      "Epoch 323/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9070.0850 - val_loss: 8158.8701\n",
      "Epoch 324/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9174.7549 - val_loss: 8182.2319\n",
      "Epoch 325/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9097.7451 - val_loss: 8167.4453\n",
      "Epoch 326/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9001.0498 - val_loss: 8125.9351\n",
      "Epoch 327/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9056.8730 - val_loss: 8145.8657\n",
      "Epoch 328/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8999.2988 - val_loss: 8113.9639\n",
      "Epoch 329/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8931.6816 - val_loss: 8110.9028\n",
      "Epoch 330/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9082.7490 - val_loss: 8128.5601\n",
      "Epoch 331/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9048.7891 - val_loss: 8139.8535\n",
      "Epoch 332/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9016.0166 - val_loss: 8118.3950\n",
      "Epoch 333/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8996.7275 - val_loss: 8086.8774\n",
      "Epoch 334/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8994.1230 - val_loss: 8112.2456\n",
      "Epoch 335/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9042.5352 - val_loss: 8114.4565\n",
      "Epoch 336/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9097.7217 - val_loss: 8123.0981\n",
      "Epoch 337/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9066.8359 - val_loss: 8197.4170\n",
      "Epoch 338/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9149.0254 - val_loss: 8094.1143\n",
      "Epoch 339/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 9016.5010 - val_loss: 8079.5762\n",
      "Epoch 340/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9002.8086 - val_loss: 8081.6826\n",
      "Epoch 341/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8973.8818 - val_loss: 8119.5249\n",
      "Epoch 342/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9146.0605 - val_loss: 8121.8765\n",
      "Epoch 343/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8893.9727 - val_loss: 8132.7949\n",
      "Epoch 344/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8941.2217 - val_loss: 8165.3843\n",
      "Epoch 345/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8850.6240 - val_loss: 8129.3369\n",
      "Epoch 346/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9047.1162 - val_loss: 8142.9404\n",
      "Epoch 347/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8957.3555 - val_loss: 8116.1987\n",
      "Epoch 348/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8972.7197 - val_loss: 8104.0527\n",
      "Epoch 349/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8866.6826 - val_loss: 8150.6001\n",
      "Epoch 350/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9145.7617 - val_loss: 8153.0732\n",
      "Epoch 351/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9193.1045 - val_loss: 8171.6226\n",
      "Epoch 352/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9131.0684 - val_loss: 8124.3545\n",
      "Epoch 353/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9042.4971 - val_loss: 8110.5679\n",
      "Epoch 354/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9106.9600 - val_loss: 8112.2515\n",
      "Epoch 355/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8905.6543 - val_loss: 8110.2144\n",
      "Epoch 356/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8886.6191 - val_loss: 8128.7495\n",
      "Epoch 357/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8875.4170 - val_loss: 8132.7524\n",
      "Epoch 358/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8964.3828 - val_loss: 8146.7734\n",
      "Epoch 359/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8905.4014 - val_loss: 8131.8516\n",
      "Epoch 360/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8980.9893 - val_loss: 8086.9019\n",
      "Epoch 361/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8774.6133 - val_loss: 8098.3193\n",
      "Epoch 362/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8943.8828 - val_loss: 8077.3477\n",
      "Epoch 363/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8981.5654 - val_loss: 8103.1616\n",
      "Epoch 364/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9034.9980 - val_loss: 8150.4712\n",
      "Epoch 365/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 9140.7656 - val_loss: 8063.1587\n",
      "Epoch 366/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9005.7715 - val_loss: 8087.1792\n",
      "Epoch 367/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8921.8887 - val_loss: 8071.0669\n",
      "Epoch 368/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8947.9971 - val_loss: 8068.1660\n",
      "Epoch 369/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8971.3594 - val_loss: 8044.0298\n",
      "Epoch 370/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8887.4199 - val_loss: 8062.6196\n",
      "Epoch 371/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8855.2930 - val_loss: 8068.4121\n",
      "Epoch 372/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8883.6230 - val_loss: 8067.7070\n",
      "Epoch 373/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8938.5830 - val_loss: 8076.6074\n",
      "Epoch 374/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8965.3594 - val_loss: 8131.0957\n",
      "Epoch 375/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8883.6094 - val_loss: 8168.9258\n",
      "Epoch 376/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8900.1104 - val_loss: 8128.0444\n",
      "Epoch 377/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9036.0098 - val_loss: 8113.5781\n",
      "Epoch 378/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8966.0654 - val_loss: 8155.2227\n",
      "Epoch 379/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8999.9521 - val_loss: 8140.4482\n",
      "Epoch 380/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8845.2852 - val_loss: 8146.1606\n",
      "Epoch 381/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 9002.6914 - val_loss: 8143.9619\n",
      "Epoch 382/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8982.7256 - val_loss: 8177.8101\n",
      "Epoch 383/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8960.2910 - val_loss: 8115.7812\n",
      "Epoch 384/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8885.3809 - val_loss: 8132.1875\n",
      "Epoch 385/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8907.9531 - val_loss: 8112.0400\n",
      "Epoch 386/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8828.2842 - val_loss: 8068.0225\n",
      "Epoch 387/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9066.9873 - val_loss: 8060.0537\n",
      "Epoch 388/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8970.8496 - val_loss: 8054.8599\n",
      "Epoch 389/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8759.6230 - val_loss: 8061.9287\n",
      "Epoch 390/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8928.9785 - val_loss: 8043.9028\n",
      "Epoch 391/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8762.4375 - val_loss: 8106.7544\n",
      "Epoch 392/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8950.8203 - val_loss: 8030.4526\n",
      "Epoch 393/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9115.5518 - val_loss: 8056.4072\n",
      "Epoch 394/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8993.4053 - val_loss: 8078.0010\n",
      "Epoch 395/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8918.6875 - val_loss: 8045.7495\n",
      "Epoch 396/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8892.9414 - val_loss: 8047.9136\n",
      "Epoch 397/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9049.2256 - val_loss: 8039.5928\n",
      "Epoch 398/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8909.0361 - val_loss: 8057.8589\n",
      "Epoch 399/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9010.1143 - val_loss: 8042.4980\n",
      "Epoch 400/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8909.5693 - val_loss: 8048.5186\n",
      "Epoch 401/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8864.9941 - val_loss: 8023.6001\n",
      "Epoch 402/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8806.6807 - val_loss: 8042.1895\n",
      "Epoch 403/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8932.8506 - val_loss: 8060.3867\n",
      "Epoch 404/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8877.5771 - val_loss: 8058.7256\n",
      "Epoch 405/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8996.5303 - val_loss: 8025.8198\n",
      "Epoch 406/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8900.9873 - val_loss: 8027.9331\n",
      "Epoch 407/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8929.3447 - val_loss: 8032.9937\n",
      "Epoch 408/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8852.9023 - val_loss: 8079.5063\n",
      "Epoch 409/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8886.8877 - val_loss: 8030.1245\n",
      "Epoch 410/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8945.9365 - val_loss: 8126.6353\n",
      "Epoch 411/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8853.0557 - val_loss: 8092.7505\n",
      "Epoch 412/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8993.3213 - val_loss: 8063.3877\n",
      "Epoch 413/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8899.9580 - val_loss: 8097.5713\n",
      "Epoch 414/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8835.1504 - val_loss: 8093.0762\n",
      "Epoch 415/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9003.7100 - val_loss: 8072.3091\n",
      "Epoch 416/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8788.8672 - val_loss: 8104.0688\n",
      "Epoch 417/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9043.9463 - val_loss: 8060.9722\n",
      "Epoch 418/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8841.1162 - val_loss: 8024.3403\n",
      "Epoch 419/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9015.7578 - val_loss: 8020.2476\n",
      "Epoch 420/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8900.9248 - val_loss: 8030.3813\n",
      "Epoch 421/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8823.2441 - val_loss: 8032.8657\n",
      "Epoch 422/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8929.3076 - val_loss: 8029.7021\n",
      "Epoch 423/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8810.5098 - val_loss: 8011.3906\n",
      "Epoch 424/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8800.1660 - val_loss: 8037.3115\n",
      "Epoch 425/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8720.4922 - val_loss: 8016.9814\n",
      "Epoch 426/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8843.1670 - val_loss: 8055.3848\n",
      "Epoch 427/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8906.9951 - val_loss: 8052.9678\n",
      "Epoch 428/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9031.3789 - val_loss: 8044.1411\n",
      "Epoch 429/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8766.6572 - val_loss: 8041.5928\n",
      "Epoch 430/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8996.5010 - val_loss: 8035.1411\n",
      "Epoch 431/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8898.7812 - val_loss: 8054.0649\n",
      "Epoch 432/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8838.5000 - val_loss: 8042.3062\n",
      "Epoch 433/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8720.7881 - val_loss: 8073.5566\n",
      "Epoch 434/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8795.8223 - val_loss: 8090.0508\n",
      "Epoch 435/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8942.4795 - val_loss: 8046.7915\n",
      "Epoch 436/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8798.7402 - val_loss: 8032.8013\n",
      "Epoch 437/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8692.2119 - val_loss: 8066.1235\n",
      "Epoch 438/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8962.8643 - val_loss: 8085.5889\n",
      "Epoch 439/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8881.8926 - val_loss: 8033.5845\n",
      "Epoch 440/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8773.2949 - val_loss: 8034.5889\n",
      "Epoch 441/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8858.8525 - val_loss: 7991.4009\n",
      "Epoch 442/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8850.2363 - val_loss: 7983.7637\n",
      "Epoch 443/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8872.9883 - val_loss: 7977.4658\n",
      "Epoch 444/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8784.2803 - val_loss: 8051.1699\n",
      "Epoch 445/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8926.7402 - val_loss: 8072.2373\n",
      "Epoch 446/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8771.8096 - val_loss: 8016.2021\n",
      "Epoch 447/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8726.4434 - val_loss: 8041.8535\n",
      "Epoch 448/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8900.6963 - val_loss: 8020.0259\n",
      "Epoch 449/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8929.6602 - val_loss: 8013.2349\n",
      "Epoch 450/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8843.9219 - val_loss: 8010.5010\n",
      "Epoch 451/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8823.6455 - val_loss: 8020.2310\n",
      "Epoch 452/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8768.1445 - val_loss: 7988.5039\n",
      "Epoch 453/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8763.2861 - val_loss: 8029.7637\n",
      "Epoch 454/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8648.7939 - val_loss: 8022.6050\n",
      "Epoch 455/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8856.2998 - val_loss: 8014.4126\n",
      "Epoch 456/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8940.3994 - val_loss: 7996.1001\n",
      "Epoch 457/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8840.8887 - val_loss: 8025.3013\n",
      "Epoch 458/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8809.4385 - val_loss: 7998.7700\n",
      "Epoch 459/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8847.4531 - val_loss: 8018.3682\n",
      "Epoch 460/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8943.3027 - val_loss: 8016.2534\n",
      "Epoch 461/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8933.9854 - val_loss: 8017.2588\n",
      "Epoch 462/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8854.0449 - val_loss: 8023.6250\n",
      "Epoch 463/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8949.1699 - val_loss: 7983.0176\n",
      "Epoch 464/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8829.7852 - val_loss: 7980.5410\n",
      "Epoch 465/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8904.6523 - val_loss: 8007.8198\n",
      "Epoch 466/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8862.4775 - val_loss: 8032.2002\n",
      "Epoch 467/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8889.2744 - val_loss: 7993.8740\n",
      "Epoch 468/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8924.6924 - val_loss: 7970.2822\n",
      "Epoch 469/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8958.4951 - val_loss: 7989.2915\n",
      "Epoch 470/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8949.7549 - val_loss: 8016.2998\n",
      "Epoch 471/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8751.6318 - val_loss: 7999.1465\n",
      "Epoch 472/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8880.5518 - val_loss: 8044.8804\n",
      "Epoch 473/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8880.1553 - val_loss: 7993.9473\n",
      "Epoch 474/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8811.3633 - val_loss: 7972.2393\n",
      "Epoch 475/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8967.4131 - val_loss: 7972.2803\n",
      "Epoch 476/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8827.3486 - val_loss: 7976.7412\n",
      "Epoch 477/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8861.2520 - val_loss: 7967.9482\n",
      "Epoch 478/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8875.4014 - val_loss: 7950.6714\n",
      "Epoch 479/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8882.3174 - val_loss: 7969.0132\n",
      "Epoch 480/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8656.0410 - val_loss: 7984.8730\n",
      "Epoch 481/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8937.0459 - val_loss: 8003.6577\n",
      "Epoch 482/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8888.7969 - val_loss: 7953.2949\n",
      "Epoch 483/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8774.5010 - val_loss: 7986.8013\n",
      "Epoch 484/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8703.0645 - val_loss: 7950.6885\n",
      "Epoch 485/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8885.0244 - val_loss: 7990.1270\n",
      "Epoch 486/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8714.5674 - val_loss: 7960.7339\n",
      "Epoch 487/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8849.2188 - val_loss: 7966.2578\n",
      "Epoch 488/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8921.2090 - val_loss: 7946.3682\n",
      "Epoch 489/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8990.1543 - val_loss: 7996.1235\n",
      "Epoch 490/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8812.3613 - val_loss: 7949.8257\n",
      "Epoch 491/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8831.9580 - val_loss: 7932.1104\n",
      "Epoch 492/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8641.8047 - val_loss: 7937.5889\n",
      "Epoch 493/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8936.2373 - val_loss: 7985.9761\n",
      "Epoch 494/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8904.0547 - val_loss: 7965.8218\n",
      "Epoch 495/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8821.6367 - val_loss: 7944.6733\n",
      "Epoch 496/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8902.1699 - val_loss: 7945.8662\n",
      "Epoch 497/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8879.2773 - val_loss: 7925.3135\n",
      "Epoch 498/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8611.1494 - val_loss: 7936.4795\n",
      "Epoch 499/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8938.0605 - val_loss: 7971.7754\n",
      "Epoch 500/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8750.0693 - val_loss: 7978.3340\n",
      "Epoch 501/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8806.1055 - val_loss: 7949.8062\n",
      "Epoch 502/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8865.6387 - val_loss: 7889.8691\n",
      "Epoch 503/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8788.7578 - val_loss: 7887.5493\n",
      "Epoch 504/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8826.6582 - val_loss: 7900.4062\n",
      "Epoch 505/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8718.4873 - val_loss: 7977.6826\n",
      "Epoch 506/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8807.2236 - val_loss: 7936.7700\n",
      "Epoch 507/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8919.8818 - val_loss: 7936.3711\n",
      "Epoch 508/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8681.4160 - val_loss: 7911.5630\n",
      "Epoch 509/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8777.3975 - val_loss: 8026.4775\n",
      "Epoch 510/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8876.6455 - val_loss: 7967.3286\n",
      "Epoch 511/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8893.8496 - val_loss: 7933.0908\n",
      "Epoch 512/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8879.9365 - val_loss: 7917.2515\n",
      "Epoch 513/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8831.3438 - val_loss: 7922.7012\n",
      "Epoch 514/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8819.1143 - val_loss: 7941.4731\n",
      "Epoch 515/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8713.8770 - val_loss: 7896.6206\n",
      "Epoch 516/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8880.4111 - val_loss: 7913.8774\n",
      "Epoch 517/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8837.6406 - val_loss: 7900.7266\n",
      "Epoch 518/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8722.4229 - val_loss: 7925.0703\n",
      "Epoch 519/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8715.1338 - val_loss: 7932.0786\n",
      "Epoch 520/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8827.7227 - val_loss: 7935.3032\n",
      "Epoch 521/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8771.3486 - val_loss: 7908.5640\n",
      "Epoch 522/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8626.9844 - val_loss: 7923.0771\n",
      "Epoch 523/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8771.3438 - val_loss: 7910.8916\n",
      "Epoch 524/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8745.7139 - val_loss: 7923.5176\n",
      "Epoch 525/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8595.9287 - val_loss: 7910.6270\n",
      "Epoch 526/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8700.9229 - val_loss: 7896.4609\n",
      "Epoch 527/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8824.0361 - val_loss: 7902.6338\n",
      "Epoch 528/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8795.0449 - val_loss: 7884.9712\n",
      "Epoch 529/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8842.7246 - val_loss: 7902.1714\n",
      "Epoch 530/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8741.2432 - val_loss: 7905.0537\n",
      "Epoch 531/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8916.3076 - val_loss: 7903.0391\n",
      "Epoch 532/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8641.2432 - val_loss: 7906.4307\n",
      "Epoch 533/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8797.6865 - val_loss: 7895.4414\n",
      "Epoch 534/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8732.6309 - val_loss: 7888.7720\n",
      "Epoch 535/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8688.5049 - val_loss: 7931.5981\n",
      "Epoch 536/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8733.1660 - val_loss: 7885.3462\n",
      "Epoch 537/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8611.5615 - val_loss: 7867.2729\n",
      "Epoch 538/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8835.7197 - val_loss: 7860.6802\n",
      "Epoch 539/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8955.1973 - val_loss: 7871.5786\n",
      "Epoch 540/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8892.3691 - val_loss: 7878.2505\n",
      "Epoch 541/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8661.1699 - val_loss: 7901.6133\n",
      "Epoch 542/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8669.0322 - val_loss: 7877.1616\n",
      "Epoch 543/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8683.1719 - val_loss: 7907.9863\n",
      "Epoch 544/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8858.8486 - val_loss: 7905.9287\n",
      "Epoch 545/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8759.5801 - val_loss: 7847.4492\n",
      "Epoch 546/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8840.0039 - val_loss: 7880.2998\n",
      "Epoch 547/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8782.8350 - val_loss: 7904.1040\n",
      "Epoch 548/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8697.5576 - val_loss: 7873.9434\n",
      "Epoch 549/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8688.6162 - val_loss: 7885.9980\n",
      "Epoch 550/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8830.8164 - val_loss: 7871.2637\n",
      "Epoch 551/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8853.9629 - val_loss: 7911.5596\n",
      "Epoch 552/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8837.3281 - val_loss: 7899.0967\n",
      "Epoch 553/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8834.2256 - val_loss: 7877.2651\n",
      "Epoch 554/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8722.3838 - val_loss: 7860.3228\n",
      "Epoch 555/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8656.2070 - val_loss: 7861.7227\n",
      "Epoch 556/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8929.1846 - val_loss: 7877.0967\n",
      "Epoch 557/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8807.7100 - val_loss: 7903.2319\n",
      "Epoch 558/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8630.1152 - val_loss: 7883.4565\n",
      "Epoch 559/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8724.4209 - val_loss: 7868.7988\n",
      "Epoch 560/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8637.3838 - val_loss: 7846.1133\n",
      "Epoch 561/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8709.1426 - val_loss: 7881.2505\n",
      "Epoch 562/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8730.0732 - val_loss: 7859.8359\n",
      "Epoch 563/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8733.4707 - val_loss: 7874.5508\n",
      "Epoch 564/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8759.4092 - val_loss: 7857.2598\n",
      "Epoch 565/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8697.9111 - val_loss: 7843.4980\n",
      "Epoch 566/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8828.5508 - val_loss: 7893.7559\n",
      "Epoch 567/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8734.5010 - val_loss: 7861.3794\n",
      "Epoch 568/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8705.2588 - val_loss: 7892.1196\n",
      "Epoch 569/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8659.5049 - val_loss: 7902.4204\n",
      "Epoch 570/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8504.8936 - val_loss: 7887.0156\n",
      "Epoch 571/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8872.9766 - val_loss: 7860.3247\n",
      "Epoch 572/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8808.2881 - val_loss: 7832.0298\n",
      "Epoch 573/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8652.8311 - val_loss: 7850.0308\n",
      "Epoch 574/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8733.4727 - val_loss: 7861.2178\n",
      "Epoch 575/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8773.0820 - val_loss: 7844.5298\n",
      "Epoch 576/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8840.2021 - val_loss: 7855.7363\n",
      "Epoch 577/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8707.3379 - val_loss: 7824.6167\n",
      "Epoch 578/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8546.5771 - val_loss: 7840.7568\n",
      "Epoch 579/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8627.0000 - val_loss: 7859.2441\n",
      "Epoch 580/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8631.5996 - val_loss: 7851.2300\n",
      "Epoch 581/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8677.9121 - val_loss: 7835.5742\n",
      "Epoch 582/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8597.0000 - val_loss: 7853.7085\n",
      "Epoch 583/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8590.8408 - val_loss: 7873.7188\n",
      "Epoch 584/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8782.7334 - val_loss: 7828.7451\n",
      "Epoch 585/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8799.1992 - val_loss: 7834.1616\n",
      "Epoch 586/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8771.2471 - val_loss: 7833.2441\n",
      "Epoch 587/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8718.1387 - val_loss: 7824.0410\n",
      "Epoch 588/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8722.8760 - val_loss: 7823.0537\n",
      "Epoch 589/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8785.2061 - val_loss: 7814.0112\n",
      "Epoch 590/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8674.3447 - val_loss: 7811.4639\n",
      "Epoch 591/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8757.0068 - val_loss: 7820.2905\n",
      "Epoch 592/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8649.2119 - val_loss: 7851.1763\n",
      "Epoch 593/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8772.4971 - val_loss: 7853.6826\n",
      "Epoch 594/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8733.1699 - val_loss: 7808.1558\n",
      "Epoch 595/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8675.7188 - val_loss: 7808.1514\n",
      "Epoch 596/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8678.0674 - val_loss: 7828.3740\n",
      "Epoch 597/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8651.0352 - val_loss: 7829.0742\n",
      "Epoch 598/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8594.6963 - val_loss: 7830.8384\n",
      "Epoch 599/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8655.5791 - val_loss: 7867.0640\n",
      "Epoch 600/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8574.6074 - val_loss: 7818.3979\n",
      "Epoch 601/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8636.3486 - val_loss: 7830.6523\n",
      "Epoch 602/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8742.2021 - val_loss: 7814.0547\n",
      "Epoch 603/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8621.3896 - val_loss: 7785.0981\n",
      "Epoch 604/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8655.2354 - val_loss: 7789.6411\n",
      "Epoch 605/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8608.9893 - val_loss: 7809.2339\n",
      "Epoch 606/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8585.1797 - val_loss: 7802.3145\n",
      "Epoch 607/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8674.3779 - val_loss: 7819.0112\n",
      "Epoch 608/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8742.9111 - val_loss: 7811.5640\n",
      "Epoch 609/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8644.9707 - val_loss: 7797.7349\n",
      "Epoch 610/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8805.2422 - val_loss: 7834.5845\n",
      "Epoch 611/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8708.1240 - val_loss: 7789.4175\n",
      "Epoch 612/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8704.4531 - val_loss: 7826.5381\n",
      "Epoch 613/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8720.6152 - val_loss: 7830.2773\n",
      "Epoch 614/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8731.3037 - val_loss: 7899.6724\n",
      "Epoch 615/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8719.1904 - val_loss: 7852.8848\n",
      "Epoch 616/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8611.4824 - val_loss: 7812.9648\n",
      "Epoch 617/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8723.2080 - val_loss: 7844.6548\n",
      "Epoch 618/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8532.8604 - val_loss: 7765.4121\n",
      "Epoch 619/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8711.6143 - val_loss: 7784.4175\n",
      "Epoch 620/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8692.3584 - val_loss: 7777.3442\n",
      "Epoch 621/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8791.6055 - val_loss: 7793.4473\n",
      "Epoch 622/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8535.3096 - val_loss: 7830.0229\n",
      "Epoch 623/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8610.7695 - val_loss: 7797.5464\n",
      "Epoch 624/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8657.0713 - val_loss: 7819.1245\n",
      "Epoch 625/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8576.9316 - val_loss: 7789.1992\n",
      "Epoch 626/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8593.3799 - val_loss: 7795.0278\n",
      "Epoch 627/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8585.9717 - val_loss: 7794.1587\n",
      "Epoch 628/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8755.2432 - val_loss: 7799.0415\n",
      "Epoch 629/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8689.5039 - val_loss: 7780.3809\n",
      "Epoch 630/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8507.5586 - val_loss: 7802.7163\n",
      "Epoch 631/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8669.3398 - val_loss: 7823.2173\n",
      "Epoch 632/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8712.5078 - val_loss: 7817.4761\n",
      "Epoch 633/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8604.9229 - val_loss: 7767.2358\n",
      "Epoch 634/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8582.4551 - val_loss: 7802.2227\n",
      "Epoch 635/1200\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 8713.9297 - val_loss: 7768.4834\n",
      "Epoch 636/1200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 8626.1748 - val_loss: 7780.0415\n",
      "Epoch 637/1200\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 8797.2031 - val_loss: 7784.0474\n",
      "Epoch 638/1200\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 8605.3359 - val_loss: 7801.1621\n",
      "Epoch 639/1200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 8734.1299 - val_loss: 7769.1216\n",
      "Epoch 640/1200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 8693.5195 - val_loss: 7764.7959\n",
      "Epoch 641/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8579.6367 - val_loss: 7797.8711\n",
      "Epoch 642/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8558.4717 - val_loss: 7769.1890\n",
      "Epoch 643/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8568.0420 - val_loss: 7757.2876\n",
      "Epoch 644/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8668.2793 - val_loss: 7780.0811\n",
      "Epoch 645/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8559.7295 - val_loss: 7764.3701\n",
      "Epoch 646/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8631.4014 - val_loss: 7748.7021\n",
      "Epoch 647/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8589.2842 - val_loss: 7780.5122\n",
      "Epoch 648/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8615.4980 - val_loss: 7761.8379\n",
      "Epoch 649/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8553.7314 - val_loss: 7778.9844\n",
      "Epoch 650/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8603.2988 - val_loss: 7741.7871\n",
      "Epoch 651/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8674.0430 - val_loss: 7773.2036\n",
      "Epoch 652/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8550.3857 - val_loss: 7748.3105\n",
      "Epoch 653/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8551.9814 - val_loss: 7753.0107\n",
      "Epoch 654/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8556.5137 - val_loss: 7748.4390\n",
      "Epoch 655/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8639.6406 - val_loss: 7756.1587\n",
      "Epoch 656/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8660.9805 - val_loss: 7809.5918\n",
      "Epoch 657/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8549.4482 - val_loss: 7744.2158\n",
      "Epoch 658/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8582.8330 - val_loss: 7752.9829\n",
      "Epoch 659/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8615.0107 - val_loss: 7756.3662\n",
      "Epoch 660/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8574.5029 - val_loss: 7762.6436\n",
      "Epoch 661/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8620.2295 - val_loss: 7811.7207\n",
      "Epoch 662/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8661.2178 - val_loss: 7821.0122\n",
      "Epoch 663/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8678.9404 - val_loss: 7752.0396\n",
      "Epoch 664/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8589.3877 - val_loss: 7735.3223\n",
      "Epoch 665/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8799.7695 - val_loss: 7798.7886\n",
      "Epoch 666/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8492.5957 - val_loss: 7775.4478\n",
      "Epoch 667/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8589.6182 - val_loss: 7771.7148\n",
      "Epoch 668/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8637.7012 - val_loss: 7768.0073\n",
      "Epoch 669/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8699.7236 - val_loss: 7748.0996\n",
      "Epoch 670/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8725.4346 - val_loss: 7769.1626\n",
      "Epoch 671/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8480.4434 - val_loss: 7763.6348\n",
      "Epoch 672/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8793.2314 - val_loss: 7800.6909\n",
      "Epoch 673/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8621.3271 - val_loss: 7763.4102\n",
      "Epoch 674/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8611.1396 - val_loss: 7746.3135\n",
      "Epoch 675/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8698.6543 - val_loss: 7762.0898\n",
      "Epoch 676/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8555.9453 - val_loss: 7816.3823\n",
      "Epoch 677/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8565.2969 - val_loss: 7735.9448\n",
      "Epoch 678/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8516.1338 - val_loss: 7719.1333\n",
      "Epoch 679/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8612.0840 - val_loss: 7731.7964\n",
      "Epoch 680/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8674.8203 - val_loss: 7750.5981\n",
      "Epoch 681/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8665.9131 - val_loss: 7738.5137\n",
      "Epoch 682/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8615.8262 - val_loss: 7801.0879\n",
      "Epoch 683/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8521.6592 - val_loss: 7765.1338\n",
      "Epoch 684/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8661.3955 - val_loss: 7728.6421\n",
      "Epoch 685/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8594.4951 - val_loss: 7735.8999\n",
      "Epoch 686/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8668.0449 - val_loss: 7766.6016\n",
      "Epoch 687/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8516.2500 - val_loss: 7736.9492\n",
      "Epoch 688/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8586.6289 - val_loss: 7770.1108\n",
      "Epoch 689/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8761.5508 - val_loss: 7779.8096\n",
      "Epoch 690/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8528.7080 - val_loss: 7770.1455\n",
      "Epoch 691/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8463.4082 - val_loss: 7754.4233\n",
      "Epoch 692/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8582.3516 - val_loss: 7762.8613\n",
      "Epoch 693/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8426.2432 - val_loss: 7767.6777\n",
      "Epoch 694/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8678.2324 - val_loss: 7750.9585\n",
      "Epoch 695/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8615.2979 - val_loss: 7799.1206\n",
      "Epoch 696/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8686.7021 - val_loss: 7794.6846\n",
      "Epoch 697/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8544.5137 - val_loss: 7756.8647\n",
      "Epoch 698/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8567.3916 - val_loss: 7770.6748\n",
      "Epoch 699/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8547.9141 - val_loss: 7760.6426\n",
      "Epoch 700/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8508.5869 - val_loss: 7739.3223\n",
      "Epoch 701/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8545.0771 - val_loss: 7739.4678\n",
      "Epoch 702/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8538.5098 - val_loss: 7703.8252\n",
      "Epoch 703/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8619.5850 - val_loss: 7731.8032\n",
      "Epoch 704/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8643.4443 - val_loss: 7755.9785\n",
      "Epoch 705/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8586.8857 - val_loss: 7748.2075\n",
      "Epoch 706/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8566.7793 - val_loss: 7739.3418\n",
      "Epoch 707/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8532.9170 - val_loss: 7756.1411\n",
      "Epoch 708/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8494.6680 - val_loss: 7846.4619\n",
      "Epoch 709/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8569.8555 - val_loss: 7776.6631\n",
      "Epoch 710/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8576.4189 - val_loss: 7722.8604\n",
      "Epoch 711/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8693.0459 - val_loss: 7749.4707\n",
      "Epoch 712/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8630.9775 - val_loss: 7716.3096\n",
      "Epoch 713/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8700.8770 - val_loss: 7723.2085\n",
      "Epoch 714/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8542.1572 - val_loss: 7722.3076\n",
      "Epoch 715/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8643.6758 - val_loss: 7719.2393\n",
      "Epoch 716/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8463.8145 - val_loss: 7738.9292\n",
      "Epoch 717/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8645.8672 - val_loss: 7762.0913\n",
      "Epoch 718/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8720.6611 - val_loss: 7736.5693\n",
      "Epoch 719/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8407.0020 - val_loss: 7774.2241\n",
      "Epoch 720/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8691.7646 - val_loss: 7735.0469\n",
      "Epoch 721/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8712.7080 - val_loss: 7726.8037\n",
      "Epoch 722/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8603.9658 - val_loss: 7711.3843\n",
      "Epoch 723/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8544.1846 - val_loss: 7766.0332\n",
      "Epoch 724/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8575.3652 - val_loss: 7714.8853\n",
      "Epoch 725/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8528.1494 - val_loss: 7743.1206\n",
      "Epoch 726/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8645.7139 - val_loss: 7735.6431\n",
      "Epoch 727/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8504.8477 - val_loss: 7761.7485\n",
      "Epoch 728/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8439.6729 - val_loss: 7758.0532\n",
      "Epoch 729/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8597.2529 - val_loss: 7755.3281\n",
      "Epoch 730/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8515.1982 - val_loss: 7760.8408\n",
      "Epoch 731/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8582.5576 - val_loss: 7737.2036\n",
      "Epoch 732/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8694.5996 - val_loss: 7754.4102\n",
      "Epoch 733/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8540.3066 - val_loss: 7802.4351\n",
      "Epoch 734/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8515.9473 - val_loss: 7723.8203\n",
      "Epoch 735/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8472.3682 - val_loss: 7780.6992\n",
      "Epoch 736/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8586.9385 - val_loss: 7794.9565\n",
      "Epoch 737/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8538.1494 - val_loss: 7746.3042\n",
      "Epoch 738/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8484.6895 - val_loss: 7744.4722\n",
      "Epoch 739/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8598.5166 - val_loss: 7749.7339\n",
      "Epoch 740/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8435.1572 - val_loss: 7752.0464\n",
      "Epoch 741/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8449.5127 - val_loss: 7739.8335\n",
      "Epoch 742/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8378.4297 - val_loss: 7748.3237\n",
      "Epoch 743/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8523.0430 - val_loss: 7770.1411\n",
      "Epoch 744/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8568.1152 - val_loss: 7738.1030\n",
      "Epoch 745/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8534.2363 - val_loss: 7727.5601\n",
      "Epoch 746/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8535.2471 - val_loss: 7741.5239\n",
      "Epoch 747/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8528.7832 - val_loss: 7768.8379\n",
      "Epoch 748/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8564.6094 - val_loss: 7707.4204\n",
      "Epoch 749/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8606.4824 - val_loss: 7690.7637\n",
      "Epoch 750/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8496.1562 - val_loss: 7720.4512\n",
      "Epoch 751/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8600.5098 - val_loss: 7743.2344\n",
      "Epoch 752/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8445.5303 - val_loss: 7701.0654\n",
      "Epoch 753/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8632.3672 - val_loss: 7696.3135\n",
      "Epoch 754/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8528.6299 - val_loss: 7752.1367\n",
      "Epoch 755/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8551.8896 - val_loss: 7736.3936\n",
      "Epoch 756/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8535.7168 - val_loss: 7720.2065\n",
      "Epoch 757/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8471.0410 - val_loss: 7745.1855\n",
      "Epoch 758/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8408.0654 - val_loss: 7735.8369\n",
      "Epoch 759/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8718.3369 - val_loss: 7743.3145\n",
      "Epoch 760/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8494.6787 - val_loss: 7733.4771\n",
      "Epoch 761/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8502.1426 - val_loss: 7737.4033\n",
      "Epoch 762/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8487.8965 - val_loss: 7710.1499\n",
      "Epoch 763/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8484.1855 - val_loss: 7721.0547\n",
      "Epoch 764/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8347.7100 - val_loss: 7730.7456\n",
      "Epoch 765/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8698.9121 - val_loss: 7696.3374\n",
      "Epoch 766/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8616.5518 - val_loss: 7725.2900\n",
      "Epoch 767/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8458.8818 - val_loss: 7739.7012\n",
      "Epoch 768/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8566.0469 - val_loss: 7773.5244\n",
      "Epoch 769/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8415.6729 - val_loss: 7769.5601\n",
      "Epoch 770/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8388.9277 - val_loss: 7808.5879\n",
      "Epoch 771/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8586.4951 - val_loss: 7704.9341\n",
      "Epoch 772/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8534.9023 - val_loss: 7709.0278\n",
      "Epoch 773/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8456.8496 - val_loss: 7728.1973\n",
      "Epoch 774/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8577.9023 - val_loss: 7703.2520\n",
      "Epoch 775/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8591.0801 - val_loss: 7699.2896\n",
      "Epoch 776/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8431.7979 - val_loss: 7696.9224\n",
      "Epoch 777/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8556.6797 - val_loss: 7732.7368\n",
      "Epoch 778/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8453.3672 - val_loss: 7715.0249\n",
      "Epoch 779/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8549.9678 - val_loss: 7748.0034\n",
      "Epoch 780/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8479.5566 - val_loss: 7703.9727\n",
      "Epoch 781/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8453.0713 - val_loss: 7710.4443\n",
      "Epoch 782/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8522.8203 - val_loss: 7707.2954\n",
      "Epoch 783/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8440.4434 - val_loss: 7705.6675\n",
      "Epoch 784/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8529.0107 - val_loss: 7712.1997\n",
      "Epoch 785/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8573.1934 - val_loss: 7751.5308\n",
      "Epoch 786/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8464.0225 - val_loss: 7726.7598\n",
      "Epoch 787/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8417.2617 - val_loss: 7712.6494\n",
      "Epoch 788/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8626.1123 - val_loss: 7746.2163\n",
      "Epoch 789/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8390.8232 - val_loss: 7710.4336\n",
      "Epoch 790/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8404.7568 - val_loss: 7735.9336\n",
      "Epoch 791/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8501.6367 - val_loss: 7707.6387\n",
      "Epoch 792/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8596.9805 - val_loss: 7730.9233\n",
      "Epoch 793/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8543.9795 - val_loss: 7734.2612\n",
      "Epoch 794/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8554.3682 - val_loss: 7742.1323\n",
      "Epoch 795/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8533.4482 - val_loss: 7798.5464\n",
      "Epoch 796/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8538.5293 - val_loss: 7707.3696\n",
      "Epoch 797/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8729.1348 - val_loss: 7700.4751\n",
      "Epoch 798/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8492.2451 - val_loss: 7692.9824\n",
      "Epoch 799/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8420.9424 - val_loss: 7718.9702\n",
      "Epoch 800/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8469.6865 - val_loss: 7727.5322\n",
      "Epoch 801/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8478.3535 - val_loss: 7705.5557\n",
      "Epoch 802/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8511.6543 - val_loss: 7738.0220\n",
      "Epoch 803/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8579.0752 - val_loss: 7706.5312\n",
      "Epoch 804/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8502.9092 - val_loss: 7717.1201\n",
      "Epoch 805/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8406.3828 - val_loss: 7686.3145\n",
      "Epoch 806/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8580.9746 - val_loss: 7697.0718\n",
      "Epoch 807/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8551.3145 - val_loss: 7684.0347\n",
      "Epoch 808/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8493.8232 - val_loss: 7732.3394\n",
      "Epoch 809/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8487.3594 - val_loss: 7701.8159\n",
      "Epoch 810/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8367.3408 - val_loss: 7688.8135\n",
      "Epoch 811/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8646.2070 - val_loss: 7688.5400\n",
      "Epoch 812/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8526.3350 - val_loss: 7705.8286\n",
      "Epoch 813/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8590.7793 - val_loss: 7677.6948\n",
      "Epoch 814/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8543.8252 - val_loss: 7681.9375\n",
      "Epoch 815/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8443.8311 - val_loss: 7685.8984\n",
      "Epoch 816/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8498.5859 - val_loss: 7674.7637\n",
      "Epoch 817/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8470.6201 - val_loss: 7670.0986\n",
      "Epoch 818/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8451.6885 - val_loss: 7708.7173\n",
      "Epoch 819/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8384.9336 - val_loss: 7692.4595\n",
      "Epoch 820/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8497.9775 - val_loss: 7710.8350\n",
      "Epoch 821/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8362.0762 - val_loss: 7773.1958\n",
      "Epoch 822/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8446.0635 - val_loss: 7685.7588\n",
      "Epoch 823/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8591.3428 - val_loss: 7673.6709\n",
      "Epoch 824/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8514.4980 - val_loss: 7682.8472\n",
      "Epoch 825/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8492.1670 - val_loss: 7667.4814\n",
      "Epoch 826/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8587.6240 - val_loss: 7665.2661\n",
      "Epoch 827/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8452.0986 - val_loss: 7681.4512\n",
      "Epoch 828/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8453.9287 - val_loss: 7712.9238\n",
      "Epoch 829/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8333.0889 - val_loss: 7784.7002\n",
      "Epoch 830/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8484.9639 - val_loss: 7720.2173\n",
      "Epoch 831/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8408.4082 - val_loss: 7679.2476\n",
      "Epoch 832/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8469.3701 - val_loss: 7730.6924\n",
      "Epoch 833/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8547.8994 - val_loss: 7706.4888\n",
      "Epoch 834/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8530.4238 - val_loss: 7675.5771\n",
      "Epoch 835/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8416.0547 - val_loss: 7739.4346\n",
      "Epoch 836/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8500.4580 - val_loss: 7708.8276\n",
      "Epoch 837/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8596.3965 - val_loss: 7660.9326\n",
      "Epoch 838/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8560.4785 - val_loss: 7682.0288\n",
      "Epoch 839/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8529.4023 - val_loss: 7730.6157\n",
      "Epoch 840/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8530.0469 - val_loss: 7691.6455\n",
      "Epoch 841/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8490.4043 - val_loss: 7706.2700\n",
      "Epoch 842/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8467.7891 - val_loss: 7704.6880\n",
      "Epoch 843/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8363.0781 - val_loss: 7666.6431\n",
      "Epoch 844/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8601.7617 - val_loss: 7711.4111\n",
      "Epoch 845/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8349.9570 - val_loss: 7662.9087\n",
      "Epoch 846/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8468.7266 - val_loss: 7688.2598\n",
      "Epoch 847/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8316.9443 - val_loss: 7744.3101\n",
      "Epoch 848/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8529.9971 - val_loss: 7683.6504\n",
      "Epoch 849/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8487.2734 - val_loss: 7667.0786\n",
      "Epoch 850/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8415.4834 - val_loss: 7668.8691\n",
      "Epoch 851/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8432.9180 - val_loss: 7657.8447\n",
      "Epoch 852/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8465.6982 - val_loss: 7736.6177\n",
      "Epoch 853/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8573.8184 - val_loss: 7656.6519\n",
      "Epoch 854/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8497.5000 - val_loss: 7679.0205\n",
      "Epoch 855/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8397.9482 - val_loss: 7664.6880\n",
      "Epoch 856/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8397.5342 - val_loss: 7726.7739\n",
      "Epoch 857/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8503.6641 - val_loss: 7679.1802\n",
      "Epoch 858/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8651.7256 - val_loss: 7682.0596\n",
      "Epoch 859/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8433.0254 - val_loss: 7656.5620\n",
      "Epoch 860/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8454.2158 - val_loss: 7685.0591\n",
      "Epoch 861/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8463.2979 - val_loss: 7680.0542\n",
      "Epoch 862/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8522.5938 - val_loss: 7657.9888\n",
      "Epoch 863/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8516.8320 - val_loss: 7656.2158\n",
      "Epoch 864/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8474.0352 - val_loss: 7731.0903\n",
      "Epoch 865/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8472.4004 - val_loss: 7699.7778\n",
      "Epoch 866/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8416.1865 - val_loss: 7693.4561\n",
      "Epoch 867/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8419.4268 - val_loss: 7671.5933\n",
      "Epoch 868/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8674.6367 - val_loss: 7691.4731\n",
      "Epoch 869/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8393.8584 - val_loss: 7718.2471\n",
      "Epoch 870/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8582.6807 - val_loss: 7678.5771\n",
      "Epoch 871/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8497.5674 - val_loss: 7663.3618\n",
      "Epoch 872/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8434.1592 - val_loss: 7661.4854\n",
      "Epoch 873/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8485.4512 - val_loss: 7674.8545\n",
      "Epoch 874/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8559.7139 - val_loss: 7719.7368\n",
      "Epoch 875/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8470.7344 - val_loss: 7662.0146\n",
      "Epoch 876/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8506.9189 - val_loss: 7666.5742\n",
      "Epoch 877/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8536.9492 - val_loss: 7662.0645\n",
      "Epoch 878/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8478.5713 - val_loss: 7679.3955\n",
      "Epoch 879/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8511.9805 - val_loss: 7681.0195\n",
      "Epoch 880/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8474.5420 - val_loss: 7686.9961\n",
      "Epoch 881/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8345.3564 - val_loss: 7658.8931\n",
      "Epoch 882/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8237.3242 - val_loss: 7788.0566\n",
      "Epoch 883/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8447.9912 - val_loss: 7674.1406\n",
      "Epoch 884/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8367.5898 - val_loss: 7650.4419\n",
      "Epoch 885/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8321.1240 - val_loss: 7688.0479\n",
      "Epoch 886/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8456.1221 - val_loss: 7712.8589\n",
      "Epoch 887/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8510.5781 - val_loss: 7650.8613\n",
      "Epoch 888/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8369.3574 - val_loss: 7644.6226\n",
      "Epoch 889/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8524.5225 - val_loss: 7664.7305\n",
      "Epoch 890/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8554.9443 - val_loss: 7670.6626\n",
      "Epoch 891/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8452.1514 - val_loss: 7674.2168\n",
      "Epoch 892/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8563.2334 - val_loss: 7685.3921\n",
      "Epoch 893/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8561.6865 - val_loss: 7659.7617\n",
      "Epoch 894/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8558.8838 - val_loss: 7654.8296\n",
      "Epoch 895/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8376.4756 - val_loss: 7645.7729\n",
      "Epoch 896/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8531.0527 - val_loss: 7703.8394\n",
      "Epoch 897/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8265.2949 - val_loss: 7683.7231\n",
      "Epoch 898/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8393.3135 - val_loss: 7676.1343\n",
      "Epoch 899/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8303.1758 - val_loss: 7678.1064\n",
      "Epoch 900/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8536.8730 - val_loss: 7643.7466\n",
      "Epoch 901/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8329.1924 - val_loss: 7641.7534\n",
      "Epoch 902/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8322.6992 - val_loss: 7656.8076\n",
      "Epoch 903/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8310.6230 - val_loss: 7702.3564\n",
      "Epoch 904/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8397.9219 - val_loss: 7689.7729\n",
      "Epoch 905/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8450.9639 - val_loss: 7652.3799\n",
      "Epoch 906/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8509.9648 - val_loss: 7661.3550\n",
      "Epoch 907/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8528.4229 - val_loss: 7665.2168\n",
      "Epoch 908/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8411.1133 - val_loss: 7656.3579\n",
      "Epoch 909/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8448.6650 - val_loss: 7665.9575\n",
      "Epoch 910/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8408.7832 - val_loss: 7685.7153\n",
      "Epoch 911/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8515.4385 - val_loss: 7753.8379\n",
      "Epoch 912/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8441.4990 - val_loss: 7689.5688\n",
      "Epoch 913/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8503.7852 - val_loss: 7664.9136\n",
      "Epoch 914/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8438.5146 - val_loss: 7656.4424\n",
      "Epoch 915/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8279.3486 - val_loss: 7682.4907\n",
      "Epoch 916/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8423.3838 - val_loss: 7664.2998\n",
      "Epoch 917/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8424.9062 - val_loss: 7655.7231\n",
      "Epoch 918/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8364.6426 - val_loss: 7655.4746\n",
      "Epoch 919/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8526.6768 - val_loss: 7649.2515\n",
      "Epoch 920/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8336.3789 - val_loss: 7671.4756\n",
      "Epoch 921/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8445.6055 - val_loss: 7664.8599\n",
      "Epoch 922/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8434.3828 - val_loss: 7644.7544\n",
      "Epoch 923/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8340.5000 - val_loss: 7684.7715\n",
      "Epoch 924/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8529.0029 - val_loss: 7661.7812\n",
      "Epoch 925/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8473.8779 - val_loss: 7628.9604\n",
      "Epoch 926/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8596.2207 - val_loss: 7663.5889\n",
      "Epoch 927/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8598.6582 - val_loss: 7690.2910\n",
      "Epoch 928/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8393.5439 - val_loss: 7661.7163\n",
      "Epoch 929/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8432.2363 - val_loss: 7656.8931\n",
      "Epoch 930/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8462.9561 - val_loss: 7694.9570\n",
      "Epoch 931/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8471.0303 - val_loss: 7681.6836\n",
      "Epoch 932/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8434.6230 - val_loss: 7680.5234\n",
      "Epoch 933/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8424.6875 - val_loss: 7657.0708\n",
      "Epoch 934/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8412.8008 - val_loss: 7709.7114\n",
      "Epoch 935/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8422.1807 - val_loss: 7644.8970\n",
      "Epoch 936/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8423.5742 - val_loss: 7642.2358\n",
      "Epoch 937/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8497.5625 - val_loss: 7668.4189\n",
      "Epoch 938/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8469.4053 - val_loss: 7660.4087\n",
      "Epoch 939/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8428.5010 - val_loss: 7644.7837\n",
      "Epoch 940/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8472.9863 - val_loss: 7645.0679\n",
      "Epoch 941/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8521.7920 - val_loss: 7678.9873\n",
      "Epoch 942/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8450.8779 - val_loss: 7657.2192\n",
      "Epoch 943/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8384.1836 - val_loss: 7700.0063\n",
      "Epoch 944/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8519.5332 - val_loss: 7644.9805\n",
      "Epoch 945/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8506.3867 - val_loss: 7659.1797\n",
      "Epoch 946/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8428.9082 - val_loss: 7678.4243\n",
      "Epoch 947/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8383.3799 - val_loss: 7677.2485\n",
      "Epoch 948/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8434.7402 - val_loss: 7717.7988\n",
      "Epoch 949/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8446.9277 - val_loss: 7647.5645\n",
      "Epoch 950/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8491.4551 - val_loss: 7632.7271\n",
      "Epoch 951/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8443.3721 - val_loss: 7667.6660\n",
      "Epoch 952/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8273.2285 - val_loss: 7641.3599\n",
      "Epoch 953/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8329.8672 - val_loss: 7664.4678\n",
      "Epoch 954/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8400.3877 - val_loss: 7638.0835\n",
      "Epoch 955/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8424.1113 - val_loss: 7660.5522\n",
      "Epoch 956/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8444.7441 - val_loss: 7774.7124\n",
      "Epoch 957/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8410.8711 - val_loss: 7653.2412\n",
      "Epoch 958/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8442.8242 - val_loss: 7639.4126\n",
      "Epoch 959/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8423.5996 - val_loss: 7658.6958\n",
      "Epoch 960/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8365.5791 - val_loss: 7643.1235\n",
      "Epoch 961/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8462.0059 - val_loss: 7684.2593\n",
      "Epoch 962/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8358.3291 - val_loss: 7694.5049\n",
      "Epoch 963/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8435.4082 - val_loss: 7674.7002\n",
      "Epoch 964/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8437.0283 - val_loss: 7662.0117\n",
      "Epoch 965/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8437.4053 - val_loss: 7696.5820\n",
      "Epoch 966/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8291.5371 - val_loss: 7645.7412\n",
      "Epoch 967/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8451.9258 - val_loss: 7624.9839\n",
      "Epoch 968/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8468.8213 - val_loss: 7656.0034\n",
      "Epoch 969/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8465.5254 - val_loss: 7642.3857\n",
      "Epoch 970/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8408.9844 - val_loss: 7680.4639\n",
      "Epoch 971/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8473.5566 - val_loss: 7642.7505\n",
      "Epoch 972/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8425.4199 - val_loss: 7649.2246\n",
      "Epoch 973/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8310.7715 - val_loss: 7669.5234\n",
      "Epoch 974/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8355.6572 - val_loss: 7645.3594\n",
      "Epoch 975/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8506.4814 - val_loss: 7714.1030\n",
      "Epoch 976/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8464.4297 - val_loss: 7654.6450\n",
      "Epoch 977/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8256.3750 - val_loss: 7635.1943\n",
      "Epoch 978/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8248.1455 - val_loss: 7641.8047\n",
      "Epoch 979/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8387.5957 - val_loss: 7669.3745\n",
      "Epoch 980/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8410.9463 - val_loss: 7700.4468\n",
      "Epoch 981/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8429.1748 - val_loss: 7655.2549\n",
      "Epoch 982/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8510.6367 - val_loss: 7664.6836\n",
      "Epoch 983/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8336.5986 - val_loss: 7629.7002\n",
      "Epoch 984/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8472.7832 - val_loss: 7711.3823\n",
      "Epoch 985/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8487.9365 - val_loss: 7698.3726\n",
      "Epoch 986/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8483.0371 - val_loss: 7672.6699\n",
      "Epoch 987/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8377.7275 - val_loss: 7672.6304\n",
      "Epoch 988/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8460.2432 - val_loss: 7669.3096\n",
      "Epoch 989/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8321.0215 - val_loss: 7651.3486\n",
      "Epoch 990/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8590.5586 - val_loss: 7671.5288\n",
      "Epoch 991/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8350.3779 - val_loss: 7716.8965\n",
      "Epoch 992/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8430.6504 - val_loss: 7660.4277\n",
      "Epoch 993/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8301.8672 - val_loss: 7676.6084\n",
      "Epoch 994/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8414.5146 - val_loss: 7640.9209\n",
      "Epoch 995/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8473.0840 - val_loss: 7639.9683\n",
      "Epoch 996/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8470.2090 - val_loss: 7717.2236\n",
      "Epoch 997/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8414.8398 - val_loss: 7650.9980\n",
      "Epoch 998/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8444.8789 - val_loss: 7637.0571\n",
      "Epoch 999/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8419.0049 - val_loss: 7664.2666\n",
      "Epoch 1000/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8389.7637 - val_loss: 7652.2319\n",
      "Epoch 1001/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8402.5195 - val_loss: 7640.6934\n",
      "Epoch 1002/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8340.9580 - val_loss: 7663.1748\n",
      "Epoch 1003/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8415.7422 - val_loss: 7629.9780\n",
      "Epoch 1004/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8295.2021 - val_loss: 7635.2856\n",
      "Epoch 1005/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8362.7217 - val_loss: 7660.5000\n",
      "Epoch 1006/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8431.3672 - val_loss: 7649.9912\n",
      "Epoch 1007/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8448.0820 - val_loss: 7664.6235\n",
      "Epoch 1008/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8380.5625 - val_loss: 7676.5522\n",
      "Epoch 1009/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8509.4209 - val_loss: 7660.8369\n",
      "Epoch 1010/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8296.3457 - val_loss: 7654.0278\n",
      "Epoch 1011/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8486.0273 - val_loss: 7669.0063\n",
      "Epoch 1012/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8302.6191 - val_loss: 7655.5474\n",
      "Epoch 1013/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8483.4756 - val_loss: 7677.1157\n",
      "Epoch 1014/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8332.1387 - val_loss: 7649.4541\n",
      "Epoch 1015/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8357.5420 - val_loss: 7651.7866\n",
      "Epoch 1016/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8323.3428 - val_loss: 7690.5366\n",
      "Epoch 1017/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8458.1699 - val_loss: 7643.2979\n",
      "Epoch 1018/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8375.7100 - val_loss: 7725.2163\n",
      "Epoch 1019/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8274.9297 - val_loss: 7776.6772\n",
      "Epoch 1020/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8344.2275 - val_loss: 7696.1372\n",
      "Epoch 1021/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8394.1016 - val_loss: 7655.2227\n",
      "Epoch 1022/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8385.5117 - val_loss: 7737.5610\n",
      "Epoch 1023/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8340.9971 - val_loss: 7663.5337\n",
      "Epoch 1024/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8373.9883 - val_loss: 7634.1528\n",
      "Epoch 1025/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8414.8555 - val_loss: 7674.5391\n",
      "Epoch 1026/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8323.8711 - val_loss: 7647.4922\n",
      "Epoch 1027/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8494.3105 - val_loss: 7641.2710\n",
      "Epoch 1028/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8380.8789 - val_loss: 7675.0005\n",
      "Epoch 1029/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8372.1230 - val_loss: 7718.1089\n",
      "Epoch 1030/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8379.8193 - val_loss: 7673.7480\n",
      "Epoch 1031/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8433.9795 - val_loss: 7645.8877\n",
      "Epoch 1032/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8493.9951 - val_loss: 7651.1138\n",
      "Epoch 1033/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8301.3926 - val_loss: 7679.7070\n",
      "Epoch 1034/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8316.9307 - val_loss: 7663.2886\n",
      "Epoch 1035/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8408.1025 - val_loss: 7648.7549\n",
      "Epoch 1036/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8426.2627 - val_loss: 7694.9980\n",
      "Epoch 1037/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8544.6816 - val_loss: 7647.6924\n",
      "Epoch 1038/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8474.8145 - val_loss: 7635.1450\n",
      "Epoch 1039/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8399.4873 - val_loss: 7659.6514\n",
      "Epoch 1040/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8440.5674 - val_loss: 7659.2261\n",
      "Epoch 1041/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8510.6807 - val_loss: 7688.3188\n",
      "Epoch 1042/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8374.0654 - val_loss: 7654.9399\n",
      "Epoch 1043/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8372.8535 - val_loss: 7656.7217\n",
      "Epoch 1044/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8488.7578 - val_loss: 7635.8271\n",
      "Epoch 1045/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8321.6914 - val_loss: 7619.4487\n",
      "Epoch 1046/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8447.4307 - val_loss: 7635.9595\n",
      "Epoch 1047/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8466.4658 - val_loss: 7651.7954\n",
      "Epoch 1048/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8285.9082 - val_loss: 7635.8359\n",
      "Epoch 1049/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8406.5068 - val_loss: 7645.3340\n",
      "Epoch 1050/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8457.6211 - val_loss: 7654.4678\n",
      "Epoch 1051/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8532.7783 - val_loss: 7646.5059\n",
      "Epoch 1052/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8342.2764 - val_loss: 7633.2412\n",
      "Epoch 1053/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8263.3330 - val_loss: 7634.5747\n",
      "Epoch 1054/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8380.2852 - val_loss: 7646.3032\n",
      "Epoch 1055/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8470.1738 - val_loss: 7631.9243\n",
      "Epoch 1056/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8448.5801 - val_loss: 7639.5698\n",
      "Epoch 1057/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8404.6221 - val_loss: 7644.7397\n",
      "Epoch 1058/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8315.9180 - val_loss: 7623.4951\n",
      "Epoch 1059/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8363.5947 - val_loss: 7661.2676\n",
      "Epoch 1060/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8372.9453 - val_loss: 7624.6973\n",
      "Epoch 1061/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8450.0283 - val_loss: 7693.0078\n",
      "Epoch 1062/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8448.1113 - val_loss: 7634.0000\n",
      "Epoch 1063/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8376.4268 - val_loss: 7625.6416\n",
      "Epoch 1064/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8504.5889 - val_loss: 7638.0166\n",
      "Epoch 1065/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8403.3057 - val_loss: 7682.9380\n",
      "Epoch 1066/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8398.5146 - val_loss: 7619.2607\n",
      "Epoch 1067/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8517.3877 - val_loss: 7649.4624\n",
      "Epoch 1068/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8346.6123 - val_loss: 7635.5488\n",
      "Epoch 1069/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8363.8633 - val_loss: 7630.5449\n",
      "Epoch 1070/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8454.6133 - val_loss: 7612.7969\n",
      "Epoch 1071/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8449.8184 - val_loss: 7640.3657\n",
      "Epoch 1072/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8533.1963 - val_loss: 7621.1187\n",
      "Epoch 1073/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8437.9717 - val_loss: 7620.4028\n",
      "Epoch 1074/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8333.8564 - val_loss: 7631.8838\n",
      "Epoch 1075/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8388.4434 - val_loss: 7633.4946\n",
      "Epoch 1076/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8323.7900 - val_loss: 7653.8462\n",
      "Epoch 1077/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8428.3584 - val_loss: 7662.1968\n",
      "Epoch 1078/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8211.0781 - val_loss: 7639.2734\n",
      "Epoch 1079/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8439.2939 - val_loss: 7669.7666\n",
      "Epoch 1080/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8281.3877 - val_loss: 7681.8564\n",
      "Epoch 1081/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8376.7021 - val_loss: 7652.6108\n",
      "Epoch 1082/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8333.3379 - val_loss: 7648.4385\n",
      "Epoch 1083/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8581.8213 - val_loss: 7640.0254\n",
      "Epoch 1084/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8401.5723 - val_loss: 7647.4893\n",
      "Epoch 1085/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8458.8984 - val_loss: 7637.4956\n",
      "Epoch 1086/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8370.6367 - val_loss: 7662.2817\n",
      "Epoch 1087/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8345.2012 - val_loss: 7646.2964\n",
      "Epoch 1088/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8344.5000 - val_loss: 7650.0176\n",
      "Epoch 1089/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8500.8145 - val_loss: 7653.5449\n",
      "Epoch 1090/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8345.9893 - val_loss: 7637.9355\n",
      "Epoch 1091/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8392.1523 - val_loss: 7630.6436\n",
      "Epoch 1092/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8330.7158 - val_loss: 7641.0811\n",
      "Epoch 1093/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8404.5488 - val_loss: 7632.3750\n",
      "Epoch 1094/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8458.7275 - val_loss: 7645.6489\n",
      "Epoch 1095/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8380.7764 - val_loss: 7639.5557\n",
      "Epoch 1096/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8343.4277 - val_loss: 7621.0137\n",
      "Epoch 1097/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8381.9443 - val_loss: 7639.1411\n",
      "Epoch 1098/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8325.7217 - val_loss: 7664.1772\n",
      "Epoch 1099/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8337.7773 - val_loss: 7680.6064\n",
      "Epoch 1100/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8367.3730 - val_loss: 7709.6050\n",
      "Epoch 1101/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8410.1396 - val_loss: 7691.7979\n",
      "Epoch 1102/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8491.1309 - val_loss: 7648.4194\n",
      "Epoch 1103/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8373.1504 - val_loss: 7694.2085\n",
      "Epoch 1104/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8299.8389 - val_loss: 7705.0308\n",
      "Epoch 1105/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8377.1484 - val_loss: 7681.2134\n",
      "Epoch 1106/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8340.2920 - val_loss: 7622.1953\n",
      "Epoch 1107/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8310.9824 - val_loss: 7660.1924\n",
      "Epoch 1108/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8453.7490 - val_loss: 7662.8398\n",
      "Epoch 1109/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8252.4629 - val_loss: 7653.2153\n",
      "Epoch 1110/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8441.1562 - val_loss: 7648.8843\n",
      "Epoch 1111/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8335.6777 - val_loss: 7639.8770\n",
      "Epoch 1112/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8381.0420 - val_loss: 7611.2095\n",
      "Epoch 1113/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8365.0293 - val_loss: 7614.5791\n",
      "Epoch 1114/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8448.3691 - val_loss: 7632.1030\n",
      "Epoch 1115/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8449.3760 - val_loss: 7629.6265\n",
      "Epoch 1116/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8312.9717 - val_loss: 7641.6099\n",
      "Epoch 1117/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8518.7715 - val_loss: 7643.1543\n",
      "Epoch 1118/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8347.7891 - val_loss: 7636.4795\n",
      "Epoch 1119/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8324.6982 - val_loss: 7637.5059\n",
      "Epoch 1120/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8518.3047 - val_loss: 7634.8218\n",
      "Epoch 1121/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8353.4570 - val_loss: 7626.7529\n",
      "Epoch 1122/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8390.5449 - val_loss: 7612.4580\n",
      "Epoch 1123/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8176.7861 - val_loss: 7709.2363\n",
      "Epoch 1124/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8447.9316 - val_loss: 7625.7207\n",
      "Epoch 1125/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8253.9912 - val_loss: 7639.3721\n",
      "Epoch 1126/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8352.5869 - val_loss: 7646.5322\n",
      "Epoch 1127/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8380.1250 - val_loss: 7670.6890\n",
      "Epoch 1128/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8328.7012 - val_loss: 7632.3188\n",
      "Epoch 1129/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8383.0586 - val_loss: 7632.8154\n",
      "Epoch 1130/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8588.6133 - val_loss: 7641.2900\n",
      "Epoch 1131/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8409.1699 - val_loss: 7599.7886\n",
      "Epoch 1132/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8190.2339 - val_loss: 7629.0547\n",
      "Epoch 1133/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8481.8057 - val_loss: 7624.5898\n",
      "Epoch 1134/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8324.4580 - val_loss: 7611.7319\n",
      "Epoch 1135/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8357.2422 - val_loss: 7625.5332\n",
      "Epoch 1136/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8341.6611 - val_loss: 7627.3223\n",
      "Epoch 1137/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8314.4951 - val_loss: 7618.6499\n",
      "Epoch 1138/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8259.1377 - val_loss: 7600.4272\n",
      "Epoch 1139/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8487.9170 - val_loss: 7610.1084\n",
      "Epoch 1140/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8194.7754 - val_loss: 7597.5010\n",
      "Epoch 1141/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8332.9814 - val_loss: 7638.3843\n",
      "Epoch 1142/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8372.6143 - val_loss: 7634.8701\n",
      "Epoch 1143/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8348.9238 - val_loss: 7594.8228\n",
      "Epoch 1144/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8292.7178 - val_loss: 7590.8848\n",
      "Epoch 1145/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8279.9336 - val_loss: 7687.5508\n",
      "Epoch 1146/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8508.6816 - val_loss: 7606.1934\n",
      "Epoch 1147/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8456.5303 - val_loss: 7592.5537\n",
      "Epoch 1148/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8484.0820 - val_loss: 7604.6382\n",
      "Epoch 1149/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8355.5244 - val_loss: 7633.3569\n",
      "Epoch 1150/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8484.9277 - val_loss: 7646.6455\n",
      "Epoch 1151/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8416.1621 - val_loss: 7618.6011\n",
      "Epoch 1152/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8368.5303 - val_loss: 7616.0229\n",
      "Epoch 1153/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8351.4033 - val_loss: 7636.0112\n",
      "Epoch 1154/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8293.8945 - val_loss: 7605.2207\n",
      "Epoch 1155/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8335.4111 - val_loss: 7641.2661\n",
      "Epoch 1156/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8492.8760 - val_loss: 7625.2778\n",
      "Epoch 1157/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8392.6484 - val_loss: 7647.4951\n",
      "Epoch 1158/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8324.1396 - val_loss: 7646.0874\n",
      "Epoch 1159/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8465.0234 - val_loss: 7647.2017\n",
      "Epoch 1160/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8299.7334 - val_loss: 7637.4165\n",
      "Epoch 1161/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8399.9170 - val_loss: 7619.4092\n",
      "Epoch 1162/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8459.2988 - val_loss: 7673.7432\n",
      "Epoch 1163/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8373.9971 - val_loss: 7620.4258\n",
      "Epoch 1164/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8433.6299 - val_loss: 7636.8472\n",
      "Epoch 1165/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8419.4766 - val_loss: 7723.5859\n",
      "Epoch 1166/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8361.6084 - val_loss: 7621.2598\n",
      "Epoch 1167/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8262.6816 - val_loss: 7632.5293\n",
      "Epoch 1168/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8480.2803 - val_loss: 7618.3491\n",
      "Epoch 1169/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8280.9404 - val_loss: 7664.9287\n",
      "Epoch 1170/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8349.0840 - val_loss: 7613.6133\n",
      "Epoch 1171/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8326.2148 - val_loss: 7612.6826\n",
      "Epoch 1172/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8200.8369 - val_loss: 7604.1963\n",
      "Epoch 1173/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8426.4023 - val_loss: 7648.3911\n",
      "Epoch 1174/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8360.7051 - val_loss: 7679.8164\n",
      "Epoch 1175/1200\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 8393.2734 - val_loss: 7644.2651\n",
      "Epoch 1176/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8355.0859 - val_loss: 7590.7583\n",
      "Epoch 1177/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8423.8154 - val_loss: 7643.6074\n",
      "Epoch 1178/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8304.4775 - val_loss: 7615.2246\n",
      "Epoch 1179/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8428.3984 - val_loss: 7661.3384\n",
      "Epoch 1180/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8454.9590 - val_loss: 7679.1816\n",
      "Epoch 1181/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8353.4316 - val_loss: 7630.9629\n",
      "Epoch 1182/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8424.8555 - val_loss: 7645.2485\n",
      "Epoch 1183/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8356.3301 - val_loss: 7628.9878\n",
      "Epoch 1184/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8459.7930 - val_loss: 7649.6621\n",
      "Epoch 1185/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8386.8965 - val_loss: 7686.1157\n",
      "Epoch 1186/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8439.5791 - val_loss: 7623.7549\n",
      "Epoch 1187/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8343.4111 - val_loss: 7646.6274\n",
      "Epoch 1188/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8235.6729 - val_loss: 7634.4814\n",
      "Epoch 1189/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8368.4951 - val_loss: 7629.3120\n",
      "Epoch 1190/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8443.4268 - val_loss: 7716.0566\n",
      "Epoch 1191/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8441.0469 - val_loss: 7618.3179\n",
      "Epoch 1192/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8354.8711 - val_loss: 7595.4834\n",
      "Epoch 1193/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8312.9365 - val_loss: 7612.9087\n",
      "Epoch 1194/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8269.0576 - val_loss: 7621.8027\n",
      "Epoch 1195/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8341.6729 - val_loss: 7645.0010\n",
      "Epoch 1196/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8406.2393 - val_loss: 7648.7402\n",
      "Epoch 1197/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8514.4834 - val_loss: 7587.9438\n",
      "Epoch 1198/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8405.1816 - val_loss: 7607.3149\n",
      "Epoch 1199/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8379.0176 - val_loss: 7649.6167\n",
      "Epoch 1200/1200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 8260.6924 - val_loss: 7593.9849\n",
      "INFO:tensorflow:Assets written to: c:\\programowanie\\ml_streamlit\\models\\vw_golf\\assets\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_and_compile_model(norm):\n",
    "  model = keras.Sequential([\n",
    "      norm,\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dropout(rate=0.2),\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "  return model\n",
    "\n",
    "\n",
    "\n",
    "csv_names = ['s_class','e_class', 'bmw3','vw_golf']\n",
    "cwd = os.getcwd()\n",
    "\n",
    "\n",
    "\n",
    "for filename in csv_names:\n",
    "    raw_dataset = pd.read_csv(f'{cwd}\\\\csv\\\\{filename}.csv', delimiter= ';')\n",
    "    dataset  = raw_dataset.copy()\n",
    "    dataset.tail()\n",
    "    dataset = dataset.drop([\"fuel_type\"], axis=1)\n",
    "    train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "    test_dataset = dataset.drop(train_dataset.index)\n",
    "    train_features = train_dataset.copy()\n",
    "    test_features = test_dataset.copy()\n",
    "\n",
    "    train_labels = train_features.pop('price')\n",
    "    test_labels = test_features.pop('price')\n",
    "    normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "    normalizer.adapt(np.array(train_features))\n",
    "\n",
    "    model_name = filename\n",
    "    model_name = build_and_compile_model(normalizer)\n",
    "    \n",
    "    history = model_name.fit(\n",
    "        train_features,\n",
    "        train_labels,\n",
    "        validation_split=0.2,\n",
    "        verbose=1, \n",
    "        epochs=1200)\n",
    "    plot_loss(history)\n",
    "    test_results[filename] = model_name.evaluate(test_features, test_labels, verbose=0)\n",
    "    model_name.save(f'{cwd}\\\\models\\\\{filename}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f694ac35d28473f3a8aa6f017a2e040811ced2513288330ac7afcde2b3270885"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
